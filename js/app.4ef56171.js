(function(){var e={4631:function(e,t,s){"use strict";var a=s(66848),i=function(){var e=this,t=e._self._c;return t("div",{staticClass:"container"},[t("b-notification",{directives:[{name:"show",rawName:"v-show",value:this.settings.getDatasizeFlag,expression:"this.settings.getDatasizeFlag"}],staticClass:"mt-2",attrs:{type:"is-warning","has-icon":"","aria-close-label":"Close notification",role:"alert"}},[e._v(" Due to the large size of dataset only 10,000 radom samples from dataset would be used. ")]),t("div",{staticClass:"columns is-multiline",attrs:{id:"app"}},[t("SidebarComponent",{ref:"sidebar",on:{updateFeatures:e.updateFeatureStats}}),t("MainComponent",{ref:"main",attrs:{dataframe:this.settings.df},on:{"check-target":function(t){return e.checkTarget()}}})],1)],1)},n=[],r=function(){var e=this,t=e._self._c;return t("div",{staticClass:"column is-2 has-background-info-light",staticStyle:{height:"100%"}},[e._m(0),t("section",[t("upload-component",{on:{uploaded:e.generateTargetDropdown,"uploaded-file":e.setFile}}),t("div",{staticClass:"column is-12"},[t("b-field",{attrs:{label:"Seed","label-position":"on-border"}},[t("b-input",{attrs:{size:"is-small",placeholder:"Seed",type:"number",min:"0"},model:{value:e.seed,callback:function(t){e.seed=t},expression:"seed"}})],1),t("b-field",{attrs:{label:"Target","label-position":"on-border"}},[t("b-select",{attrs:{expanded:!0,size:"is-small"},on:{input:e.checkmodelTask},model:{value:e.modelTarget,callback:function(t){e.modelTarget=t},expression:"modelTarget"}},e._l(e.columns,(function(s){return t("option",{key:s,domProps:{value:s}},[e._v(" "+e._s(s)+" ")])})),0)],1),t("b-field",{attrs:{label:"Imputation","label-position":"on-border"}},[t("b-select",{attrs:{expanded:!0,size:"is-small"},model:{value:e.imputationOption,callback:function(t){e.imputationOption=t},expression:"imputationOption"}},e._l(e.imputationOptions,(function(s){return t("option",{key:s.id,domProps:{value:s.id}},[e._v(" "+e._s(s.label)+" ")])})),0)],1),t("b-field",{attrs:{label:"Cross Validation","label-position":"on-border"}},[t("b-select",{attrs:{expanded:!0,size:"is-small"},model:{value:e.crossValidationOption,callback:function(t){e.crossValidationOption=t},expression:"crossValidationOption"}},e._l(e.crossValidationOptions,(function(s){return t("option",{key:s.id,domProps:{value:s.id}},[e._v(" "+e._s(s.label)+" ")])})),0)],1),t("b-field",{attrs:{label:"Model","label-position":"on-border"}},[t("b-select",{attrs:{disabled:e.tuneModel,expanded:!0,size:"is-small"},model:{value:e.modelOption,callback:function(t){e.modelOption=t},expression:"modelOption"}},e._l(e.modelOptions,(function(s){return t("option",{key:s.id,domProps:{value:s.id}},[e._v(" "+e._s(s.title)+" ")])})),0),t("b-button",{attrs:{size:"is-small","icon-pack":"fas","icon-left":this.tuneModel?"arrow-left":"cog"},on:{click:e.configureModel}})],1),e.tuneModel?t("section",{staticClass:"mx-1"},e._l(e.modelConfigurations,(function(s,a){return t("b-field",{key:a,attrs:{label:s.label,"label-position":"on-border"}},["select"===s.type?t("b-select",{attrs:{expanded:!0,size:"is-small"},model:{value:s.value,callback:function(t){e.$set(s,"value",t)},expression:"option.value"}},e._l(s.values,(function(s,a){return t("option",{key:a,domProps:{value:s.value}},[e._v(" "+e._s(s.label)+" ")])})),0):"number"===s.type?t("b-input",{attrs:{size:"is-small",type:"number"},model:{value:s.value,callback:function(t){e.$set(s,"value",t)},expression:"option.value"}}):"text"===s.type?t("b-input",{attrs:{size:"is-small",type:"text"},model:{value:s.value,callback:function(t){e.$set(s,"value",t)},expression:"option.value"}}):e._e()],1)})),1):e._e(),t("b-field",[t("b-checkbox",{attrs:{size:"is-small"},model:{value:e.dataScalingBehavior,callback:function(t){e.dataScalingBehavior=t},expression:"dataScalingBehavior"}},[e._v("Standardize by default")])],1),t("b-field",[t("b-checkbox",{attrs:{size:"is-small"},model:{value:e.explainModel,callback:function(t){e.explainModel=t},expression:"explainModel"}},[e._v("Explain the model")])],1),t("b-field",[t("b-checkbox",{attrs:{size:"is-small"},model:{value:e.usePCAs,callback:function(t){e.usePCAs=t},expression:"usePCAs"}},[e._v("Use PC components")])],1),e.usePCAs?t("b-field",{attrs:{label:"Number of Components","label-position":"on-border"}},[t("b-input",{attrs:{size:"is-small",type:"number"},model:{value:e.numberOfComponents,callback:function(t){e.numberOfComponents=t},expression:"numberOfComponents"}})],1):e._e(),t("b-field",[t("b-checkbox",{attrs:{size:"is-small"},model:{value:e.useHPC,callback:function(t){e.useHPC=t},expression:"useHPC"}},[e._v("Use HPC resources")])],1),t("b-field",[t("b-button",{attrs:{size:"is-small","icon-pack":"fas","icon-left":"play",loading:e.training,disabled:!e.dataframe||null==e.modelOption},on:{click:e.train}},[e._v(" train")]),t("button",{staticClass:"button is-small",on:{click:function(t){return e.upload()}}},[e._v("Upload to HPC server")])],1),t("b-loading",{attrs:{"is-full-page":!1},model:{value:e.training,callback:function(t){e.training=t},expression:"training"}})],1)],1)])},o=[function(){var e=this,t=e._self._c;return t("figure",{staticClass:"image is-96x96"},[t("img",{attrs:{src:"/logo.png"}})])}],l=(s(44114),s(43375),s(39225),s(13972),s(99209),s(25714),s(17561),s(66197),function(){var e=this,t=e._self._c;return t("div",{staticClass:"column is-12 has-background-light"},[t("b-field",{staticClass:"file is-success is-fullwidth",class:{"has-name":!!e.file}},[t("b-upload",{staticClass:"file-label",attrs:{accept:".csv,.txt,.xlsx"},model:{value:e.file,callback:function(t){e.file=t},expression:"file"}},[t("a",{staticClass:"button is-success is-small is-fullwidth"},[t("b-icon",{staticClass:"file-icon",attrs:{pack:"fas",icon:"upload"}}),t("span",{staticClass:"file-label"},[e._v(e._s(this.settings.datasetName||"Upload"))])],1)])],1),t("b-field",[t("b-checkbox",{attrs:{size:"is-small"},model:{value:e.header,callback:function(t){e.header=t},expression:"header"}},[e._v("Header")])],1),t("b-field",{attrs:{label:"Separator","label-position":"on-border"}},[t("b-select",{attrs:{expanded:!0,size:"is-small"},model:{value:e.separator,callback:function(t){e.separator=t},expression:"separator"}},e._l(e.separatorOptions,(function(s){return t("option",{key:s.id,domProps:{value:s.id}},[e._v(" "+e._s(s.label)+" ")])})),0)],1),t("b-field",{attrs:{label:"Decimal","label-position":"on-border"}},[t("b-select",{attrs:{expanded:!0,size:"is-small","label-position":"on-border"},model:{value:e.decimal,callback:function(t){e.decimal=t},expression:"decimal"}},e._l(e.decimalOptions,(function(s){return t("option",{key:s.id,domProps:{value:s.id}},[e._v(" "+e._s(s.label)+" ")])})),0)],1),t("b-field",[t("b-select",{attrs:{expanded:!0,size:"is-small"},on:{input:e.handleFileSelect},model:{value:e.sampleDataset,callback:function(t){e.sampleDataset=t},expression:"sampleDataset"}},e._l(e.samplDataOptions,(function(s){return t("option",{key:s.id,domProps:{value:s.name}},[e._v(" "+e._s(s.label)+" ")])})),0)],1)],1)}),c=[];class d{parse(e){throw new Error("Not implemented.")}}var m=s(8344),p=s.n(m);class u extends d{constructor(e){super(),this.separators={0:",",1:".",2:",",3:" "},this.separator=e.separator,this.delimiter=e.delimiter,this.has_header=e.header}parse(e){return new Promise((t=>{p().parse(e,{worker:!1,header:this.has_header,delimiter:this.separators[this.separator],transform:e=>"?"===e||"NA"===e?NaN:e,skipEmptyLines:!0,dynamicTyping:!0,complete:async function(e){t(e.data)}})}))}}s(16573),s(78100),s(77936),s(37467),s(44732),s(79577);class h extends d{parse(e){return new Promise((t=>{var s=new FileReader;s.onload=function(){var e=this.result,s=new Uint8Array(e),a=String.fromCharCode.apply(null,s),i=XLSX.read(a,{type:"binary"}),n=i.SheetNames[0],r=i.Sheets[n];t(XLSX.utils.sheet_to_json(r,{raw:!0}))},s.readAsArrayBuffer(e)}))}}class _ extends d{constructor(e){super(),this.separators={0:",",1:".",2:",",3:" "},this.separator=e.separator,this.delimiter=e.delimiter,this.has_header=e.header}parse(e){return new Promise((t=>{p().parse(e,{worker:!1,header:this.has_header,delimiter:this.separators[this.separator],transform:e=>"?"===e||"NA"===e?NaN:e,skipEmptyLines:!0,dynamicTyping:!0,complete:async function(e){if(1==this.delimiter)for(let t=0;t<e.data.length;t++){const s=e.data[t];for(let a=0;a<s.length;a++)e.data[t][a]=parseFloat(e.data[t][a].replace(/\./g,"").replace(",","."))}t(e.data)}})}))}}class f{static createParser(e,t){switch(e.toLowerCase()){case"csv":return new u(t);case"txt":{let e=new _(t);return e}case"xlsx":return new h;default:throw new Error(`Unsupported file type: ${e}`)}}}var g=s(40084),b=s(69005);const y=(0,b.nY)({id:"cart",state:()=>({counter:1,df:{},id:null,rawData:{},features:[],transformations:[],classTransformations:[],results:[],messages:[],datasetName:"",activeTab:0,dataSizeFlag:!1,resultActiveTab:"",datasetShape:{count:0,columns:0},target:null,isClassification:!0,seed:123}),getters:{items:e=>e.features,getDatasizeFlag:e=>e.dataSizeFlag,getCounter:e=>e.counter,getUID:()=>{let e=Math.random().toString(16).slice(2);return e},getMessages:e=>e.messages.reverse(),getDatasetName:e=>e.datasetName,getDatasetShape:e=>e.datasetShape,getDataset:e=>e.df,getRawData:e=>e.rawData,currentTab:e=>e.activeTab,mergedClasses:e=>e.classTransformations,getSeed:e=>e.seed,getMethodResults:e=>e.results,getResultTab:e=>e.resultActiveTab,outputs:e=>e.results,transformationsList:e=>e.transformations,modelTarget:e=>e.target,classificationTask:e=>e.isClassification},actions:{setSeed(e){this.seed=e},setDatasetName(e){this.datasetName=e},setDatasetShape(e){this.datasetShape=e},resetFeatures(){this.features=[],this.transformations=[],this.classTransformations=[]},resetClassTransformations(){this.classTransformations=[]},resetTransformations(){this.transformations=[]},setDatasizeFlag(e){this.dataSizeFlag=e},resetDataset(){this.datasetName="",this.datasetShape={count:0,columns:0}},increaseCounter(){this.counter++},setDataframe(e){this.df=e},setRawData(e){this.rawData=e},addFeature(e){e.scaler=0;let t=this.features.findIndex((t=>t.name===e.name));-1===t?this.features.push(e):this.features[t]=e},setClassTransformation(e){this.classTransformations.push(e)},addTransformation(e){let t=this.transformations.findIndex((t=>t.name===e.name));-1===t?this.transformations.push(e):this.transformations[t]=e},addResult(e){this.results.push(e)},addMessage(e){var t=new Date;e["date"]=t.toLocaleString(),this.messages.push(e)},removeResult(e){const t=this.results.findIndex((t=>t.id===e));t>-1&&this.results.splice(t,1)},getResultVisualizations(e){const t=this.results.findIndex((t=>t.id===e));if(t>-1){let e=this.results[t].tables,s=this.results[t].plots;return[e,s]}},resetDF(){this.df={}},updateFeature(e){let t=this.features.findIndex((t=>t.name===e.name));-1!==t&&(this.features[t]=e)},removeItem(e){const t=this.features.lastIndexOf(e);t>-1&&this.features.splice(t,1)},setTarget(e){this.target=e},setmodelTask(e){this.isClassification=e},setActiveTab(e){this.activeTab=e},setResultActiveTab(e){this.resultActiveTab=e}}}),v=1e4;var x={setup(){const e=y();return{settings:e}},name:"UploadComponent",props:{msg:String},data(){return{sampleDataset:"none",file:null,separator:2,header:!0,decimal:1,decimalOptions:[{id:1,label:"."},{id:2,label:","}],separatorOptions:[{id:1,label:"."},{id:2,label:","},{id:3,label:"space"}],samplDataOptions:[{id:0,name:"none",label:"Select toy dataset"},{id:1,name:"iris",label:"iris"},{id:2,name:"wine",label:"wine"},{id:3,name:"diabetes",label:"diabetes"},{id:4,name:"housing",label:"California Housing"},{id:5,name:"Titanic",label:"Titanic"}]}},watch:{file:async function(e){try{let t=await this.process_file(e,e.name.split(".")[1]);this.initDataframe(t,e.name.split(".")[0])}catch(t){this.$buefy.toast.open("Failed to parse the dataset.")}}},methods:{shuffle(e,t){var s,a,i=e.length;while(i)a=Math.floor(this.random(t)*i--),s=e[i],e[i]=e[a],e[a]=s,++t},random(e){var t=1e4*Math.sin(e++);return t-Math.floor(t)},async initDataframe(e,t){this.settings.resetFeatures(),this.settings.setDatasetName(t),this.settings.setDatasetShape({count:e.$data.length,columns:e.columns.length});let s=await e.sample(e.$data.length,{seed:this.settings.getSeed});this.settings.setDataframe(s),this.$emit("uploaded",!0)},async process_file(e,t){let s={separator:this.separator,delimiter:this.decimal,header:this.header},a=await f.createParser(t,s).parse(e);a.length>v?(this.settings.setDatasizeFlag(!0),this.shuffle(a,this.settings.getSeed),a=a.slice(0,v)):this.settings.setDatasizeFlag(!1);let i=new g.DataFrame(a),n=i.columns.findIndex((e=>"id"===e.toLowerCase()));return n>-1&&i.drop({columns:i.columns[n],inplace:!0}),this.settings.setRawData(a),this.$emit("uploaded-file",e),i},async handleFileSelect(e){if("none"==e)return;e+=".csv";let t,s=this;fetch("/"+e).then((e=>e.blob())).then((async a=>{t=new File([a],e);let i=await this.process_file(t,"csv");s.initDataframe(i,e.split(".")[0])})).catch((e=>{console.error("Error fetching the file:",e)}))}}},w=x,C=s(81656),k=(0,C.A)(w,l,c,!1,null,null,null),S=k.exports;const z={Numerical:{id:1,name:"Numerical"},Nominal:{id:2,name:"Nominal"},Ordinal:{id:3,name:"Ordinal"}},A={SPLIT:1,NO:2,KFOLD:3},P={No:{id:0,name:"No"},Scale:{id:1,name:"Scale"},"x^2":{id:2,name:"x^2"},"ln(x)":{id:3,name:"ln(x)"},Standardize:{id:4,name:"Standardize"}},E={classification:{logistic_regression:{id:1,label:"Logistic Regression",title:"Logi.Reg",value:1,options:{regularization:{label:"regulrization",type:"select",default:"Lasso",value:"Lasso",values:[{label:"adaptive lasso",value:"Lasso"},{label:"ridge",value:"ridge"}]}}},discriminant_analysis:{id:2,label:"Discriminant Analysis",title:"DA",value:2,options:{type:{label:"type",type:"select",default:"linear",values:[{label:"linear",value:"linear"},{label:"quadratic",value:"quadratic"}]},priors:{label:"priors",type:"text",placeholder:"comma separated priors"}}},k_nearest_neighbour:{id:3,label:"k nearest neighbour",title:"KNN",value:3,options:{min:{label:"min",type:"number",default:3},max:{label:"max",type:"number",default:9},metric:{label:"metrics",type:"select",default:"manhattan",values:[{label:"euclidean",value:"euclidean"},{label:"manhattan",value:"manhattan"}]}}},support_vector_machine:{id:4,label:"Support vector machine",title:"SVM",value:4,options:{kernel:{label:"kernel",type:"select",default:"rbf",values:[{label:"RBF",value:"rbf"},{label:"Linear",value:"linear"},{label:"Polynomial",value:"poly"},{label:"Sigmoid",value:"sigmoid"}]},bias:{label:"bias",type:"number",for:["Sigmoid","Sigmoid"],default:0},c:{label:"Regularization parameter",type:"number",default:1},degree:{label:"degree",type:"number",for:["Polynomial"],default:3}}},random_forest:{id:5,label:"Random forest",title:"RF",value:5,options:{estimators:{label:"estimators",type:"number",default:100},features:{label:"features",type:"number",default:"sqrt"},depth:{label:"depth",type:"number",default:5},criteria:{label:"criteria",type:"select",default:"gini",values:[{label:"gini",value:"gini"},{label:"log loss",value:"log_loss"},{label:"entropy",value:"entropy"}]}}},boosting:{id:6,label:"Boosting",title:"Boosting",value:6,options:{booster:{type:"select",label:"booster",default:"gbtree",values:[{label:"gbtree",value:"gbtree"},{label:"gblinear",value:"gblinear"},{label:"dart",value:"dart"}]},eta:{label:"learning rate",type:"number",default:.3},estimators:{label:"estimators",type:"number",default:200},depth:{label:"depth",type:"number",default:5}}},naive_bayes:{label:"Naive Bayes",title:"NB",value:7,id:7,options:{laplace:{label:"laplace smoothing",type:"number",default:.05},priors:{label:"priors",type:"text",placeholder:"comma separated priors"},type:{label:"type",type:"select",default:"Gaussian",values:[{label:"Gaussian",value:"Gaussian"},{label:"Multinomial",value:"Multinomial"},{label:"Bernoulli",value:"Bernoulli"}]}}}},regression:{linear_regression:{label:"Linear Regression",title:"Lin.Reg",value:9,id:9,feature_selection:["no","Lasso","ridge"],criteria:["AIC","BIC","AR2"],options:{regularization:{label:"regularization",type:"select",default:"Lasso",values:[{label:"adaptive lasso",value:"Lasso"},{label:"Ridge",value:"Ridge"}]}}},polynomial_regression:{label:"Polynomial Regression",title:"Poly.Reg",value:14,id:14,feature_selection:["no","Lasso","ridge"],criteria:["AIC","BIC","AR2"],options:{regularization:{label:"regularization",type:"select",default:"Lasso",values:[{label:"Lasso",value:"Lasso"},{label:"Ridge",value:"Ridge"}]},degree:{label:"Degree",type:"number",default:2}}},k_nearest_neighbour:{label:"k nearest neighbour Regression",title:"KNN",value:10,id:10,options:{min:{label:"min",type:"number",default:3},max:{label:"max",type:"number",default:9}}},boosting:{label:"Boosting Regression",title:"Boosting",value:11,id:11,options:{booster:{label:"booster",type:"select",default:"gbtree",values:[{label:"gbtree",value:"gbtree"},{label:"gblinear",value:"gblinear"},{label:"dart",value:"dart"}]},eta:{label:"learning rate",type:"number",default:.3},estimators:{label:"estimators",type:"number",default:200},depth:{label:"depth",type:"number",default:5}}},support_vector_machine:{label:"Support vector machine Regression",title:"SVM.Reg",value:12,id:12,options:{kernel:{label:"kernel",type:"select",default:"rbf",values:[{label:"RBF",value:"rbf"},{label:"Linear",value:"linear"},{label:"Polynomial",value:"poly"},{label:"Sigmoid",value:"sigmoid"}]},gamma:{label:"gamma",type:"number",for:["RBF","Sigmoid","Polynomial"],default:1},bias:{label:"bias",type:"number",for:["Sigmoid","Sigmoid"],default:0},degree:{label:"degree polynomial",type:"number",for:["Polynomial"],default:3}}},random_forest:{label:"Random forest Regression",title:"RF.Reg",value:13,id:13,options:{estimators:{label:"num of estimators",type:"number",default:100},features:{label:"features length",type:"number",default:"sqrt"},depth:{label:"depth",type:"number",default:5},criteria:{type:"select",label:"criteria",default:"squared_error",values:[{label:"squared_error",value:"squared_error"},{label:"absolute_error",value:"absolute_error"},{label:"friedman_mse",value:"friedman_mse"},{label:"poisson",value:"poisson"}]}}},kernel_regression:{label:"Kernel Regression",title:"Ker.Reg",value:15,id:15,options:{estimators:{type:"number",default:100}}},bspline_regression:{label:"Bspline Regression",title:"Bspl.Reg",value:16,id:16,options:{knots:{label:"knots",type:"number",default:5},degree:{label:"degree",type:"number",default:3}}}}};s(14603),s(47566),s(98721);const F=new Worker(new URL(s.p+s.u(221),s.b)),T={};F.onmessage=e=>{const{id:t,...s}=e.data,a=T[t];delete T[t],a(s)};const N=(()=>{let e=0;return(t,s)=>(e=(e+1)%Number.MAX_SAFE_INTEGER,new Promise((a=>{T[e]=a,F.postMessage({...s,python:t,id:e})})))})();class D{constructor(){}async predict(e,t,s=[]){this.context={x_train:e,x_test:s,has_test_set:s.length>0,n:+t};const a="\n        import matplotlib.pyplot as plt\n        import numpy as np\n        from sklearn.decomposition import PCA\n        from js import x_train,n,x_test,has_test_set\n        from sklearn.preprocessing import StandardScaler\n        x_train = np.array(x_train)\n        scaler = StandardScaler()\n        X_scaled = scaler.fit_transform(x_train) \n        pca_x = PCA(n_components=n,random_state = 42)\n        pca = pca_x.fit_transform(np.array(X_scaled))\n        pca_test=[]\n        if has_test_set:\n            x_test = np.array(x_test)\n            x_test_scaled= scaler.transform(x_test) \n            pca_test = pca_x.fit_transform(np.array(x_test_scaled))\n        ccircle = []\n        eucl_dist = []\n        for i,j in enumerate(x_train.T):\n            corr1 = np.corrcoef(j,pca[:,0])[0,1]\n            corr2 = np.corrcoef(j,pca[:,1])[0,1]\n            ccircle.append((corr1, corr2))\n            eucl_dist.append(np.sqrt(corr1**2 + corr2**2))\n        (pca,np.arange(1, len(pca_x.explained_variance_ratio_) + 1), pca_x.explained_variance_ratio_,ccircle,eucl_dist,pca_test)\n    ";try{const{results:e,error:t}=await N(a,this.context);if(e)return e;if(t)throw Error("Faced errot fitting PCA")}catch(i){throw Error("Failed to fit PCA")}}}var q=s(8964),M=s.n(q),I=s(91114);function R(e,t){return null==t&&(t=.5),tf.util.assert(t>=0&&t<=1,`Expected threshold to be >=0 and <=1, but got ${t}`),tf.tidy((()=>{const s=e.greater(tf.scalar(t));return tf.where(s,tf.onesLike(e),tf.zerosLike(e))}))}function O(e){let t=e.replace(/\s/g,"").replace(/[^\w-]/g,"_");return t}async function L(e,t,s){const a={y:e,y_pred:t,labels:s},i="\n        from sklearn.metrics import precision_recall_fscore_support, classification_report, f1_score,accuracy_score\n        from js import y_pred,y,labels       \n        from sklearn.metrics import recall_score,precision_score\n\n        precision = precision_score(y, y_pred, average=None,labels=labels)\n        recall = recall_score(y, y_pred, average=None,labels=labels)\n        f1_micro = f1_score(y, y_pred, average='micro')\n        f1_macro = f1_score(y, y_pred, average='macro')\n        accuracy = accuracy_score(y, y_pred)\n        (precision,recall,f1_micro,f1_macro,accuracy)\n    ";try{const{results:e,error:t}=await N(i,a);if(e)return{precision:e[0],recall:e[1],f1_micro:e[2],f1_macro:e[3],accuracy:e[4]};if(t)throw t}catch(n){throw n}}function X(e,t){const s=B(e),a=e.reduce(((e,t)=>e+Math.pow(t-s,2)),0),i=e.reduce(((e,s,a)=>e+Math.pow(s-t[a],2)),0);return 1-i/a}function j(e,t){if(e.length!==t.length)throw new Error("The lengths of actual values and predicted values must be the same.");const s=e.length;let a=0;for(let n=0;n<s;n++){const s=Math.pow(e[n]-t[n],2);a+=s}const i=a/s;return i}function B(e){return e.reduce(((e,t)=>e+t),0)/e.length}function G(e,t,s){try{switch(s){case"0":break;case"1":{let s=new g.MinMaxScaler;s.fit(e[t]),e.addColumn(t,s.transform(e[t]),{inplace:!0});break}case"2":e.addColumn(t,e[t].apply((e=>e*e)),{inplace:!0});break;case"3":e.addColumn(t,e[t].apply((e=>{let t=Math.log(e);if(isNaN(t))throw new Error("falied at data transformation.");return Math.log(e)})),{inplace:!0});break;case"4":{let s=new g.StandardScaler;s.fit(e[t]),e.addColumn(t,s.transform(e[t]),{inplace:!0});break}default:break}}catch(a){throw new Error("falied at data transformation.")}}function U(e,t,s){for(let a=0;a<t.length;a++){const i=t[a];let n=s.find((e=>e.name===i));n&&G(e,i,n.scaler.toString())}return e}function J(e,t=!1){if(t){let t=[],s=[],a=[],i=[];e.columns.forEach((a=>{"string"===e.column(a)?.dtype?t.push(a):s.push(a)})),t.forEach((t=>{let s=H(e.column(t).values).mode;a.push(s)})),s.forEach((t=>{let s=e.column(t).mean();i.push(s)})),e=e.fillNa(a,{columns:t}),e=e.fillNa(i,{columns:s})}else e.dropNa({axis:1,inplace:!0});return e}function H(e){if(0===e.length)return null;const t={total:0,mode:""};for(let i=0;i<e.length;i++){const s=e[i];null!==s&&void 0!==s&&(t["total"]++,s in t?t[s]++:t[s]=1)}let s=null,a=0;for(const i in t)"total"!==i&&t[i]>a&&(s=i,a=t[i]);return t["mode"]=s,t}function V(e,t){let s=e.copy(),a=t.filter((e=>e.type===z.Nominal.id||e.type===z.Ordinal.id)),i=[];return a.forEach((e=>{if(e.type===z.Ordinal.id){let t=new g.LabelEncoder;t.fit(s[e.name]);let a=t.transform(s[e.name]);s.addColumn(e.name,a.values,{inplace:!0}),i.push(e.name)}else s=(0,g.getDummies)(s,{columns:[e.name]}),s.drop({columns:[s.columns.find((t=>t.includes(e.name+"_")))],inplace:!0}),i.push(...s.columns.filter((t=>t.includes(e.name+"_"))))})),[s,i]}var W=s(79811),Q=s(96021),K=s(65599),Y=s(97271);class Z{constructor(){}async predict(e,t,s=123){this.context={x_train:e,n:+t,seed:s};const a="\n        import matplotlib.pyplot as plt\n        from sklearn.manifold import TSNE\n        import numpy as np\n        from js import x_train,n,seed\n        from sklearn.preprocessing import StandardScaler\n        X = np.array(x_train)\n        embedded = TSNE(n_components=n, learning_rate='auto', random_state=seed).fit_transform(X)\n        embedded\n    ";try{const{results:e,error:t}=await N(a,this.context);if(e)return e;if(t)throw Error("Faced errot fitting PCA")}catch(i){throw Error("Failed to fit PCA")}}}const ee={toImageButtonOptions:{format:"png",height:null,width:null,scale:2}};class te{constructor(){(0,I.A)(this,"kernelFunctions",{gaussian:function(e){return Math.exp(-.5*e*e)/Math.sqrt(2*Math.PI)},uniform:function(e){return Math.abs(e)<=1?.5:0},triangular:function(e){return Math.abs(e)<=1?1-Math.abs(e):0},biweight:function(e){return Math.abs(e)<=1?15/16*Math.pow(1-e*e,2):0},triweight:function(e){return Math.abs(e)<=1?35/32*Math.pow(1-e*e,3):0},Epanechnikov:function(e){return Math.abs(e)<=1?.75*(1-e*e):0}}),this.color_scheme=Q.A,this.color_scheme_sequential=K.Ay}classification_target_chart(e,t,s,a,i=""){var n=[...new Set(t)],r=t.map((e=>this.indexToColor(n.indexOf(e)))),o=[];o.push({name:"Count",data:e.map(((e,t)=>({y:e,color:r[t]})))}),Highcharts.chart(a,{credits:{enabled:!1},title:{text:""},chart:{type:"column"},xAxis:{categories:n},yAxis:{min:0},plotOptions:{column:{pointPadding:.1,borderWidth:0}},colors:r,series:o})}regression_target_chart(e,t,s){let a=[],i=[],n=e;var r=W.Wj(n,100);let o=W.JL(e,"gaussian","nrd");r.forEach((e=>{i.push(o(e,"nrd")),a.push([e,i[i.length-1]])})),Highcharts.chart(t,{credits:{enabled:!1},legend:{enabled:!1,verticalAlign:"top"},chart:{height:"300",type:"spline",animation:!0},title:{text:s},yAxis:{title:{text:null}},tooltip:{valueDecimals:3},plotOptions:{series:{marker:{enabled:!1},dashStyle:"shortdot",area:!0}},series:[{type:"area",dashStyle:"solid",lineWidth:2,data:a}]})}draw_categorical_barplot(e,t,s){const a=s+"- barplot";$("#categories_barplots").append(`<div class="column is-4" style="height:40vh;" id="${a}"></div>`);const i=e.reduce(((e,t)=>(e[t]=(e[t]||0)+1,e)),{}),n=Object.entries(i).map((([e,t])=>({value:e,count:t})));n.sort(((e,t)=>t.count-e.count));const r=n.slice(0,5);new Highcharts.Chart({chart:{renderTo:a,type:"column"},xAxis:{categories:r.map((e=>e.value))},title:{text:s},yAxis:{min:0,labels:{overflow:"justify"}},credits:{enabled:!1},plotOptions:{bar:{dataLabels:{enabled:!0}}},series:[{showInLegend:!1,name:s,data:r.map((e=>e.count))}]})}roc_chart(e,t,s){var a={x:s,y:t,type:"scatter",mode:"lines",name:"ROC Curve"},i={x:[0,1],y:[0,1],type:"scatter",name:"diagonal"},n={showlegend:!1,title:"ROC Curve",xaxis:{title:"False Positive Rate"},yaxis:{title:"True Positive Rate"}},r=[a,i];M().newPlot(e,r,n)}falsePositives(e,t){return tf.tidy((()=>{const s=tf.scalar(1),a=tf.scalar(0);return tf.logicalAnd(e.equal(a),t.equal(s)).sum().cast("float32")}))}indexToColor(e,t){return this.color_scheme_sequential((e+1)/t)}indexToColorSequential(e,t,s){let a=(e-t)/(s-t);return this.color_scheme_sequential(a)}reshape(e,t){if(0===t.length)return e[0];const[s,...a]=t,i=[],n=a.reduce(((e,t)=>e*t),1);console.log(n);for(let r=0;r<s;r++)i.push(this.reshape(e.slice(r*n,(r+1)*n),a));return i}async plot_tsne(e,t,s,a,i){s=s.flat();const n=new Z;let r=await n.predict(e,i,a),o=r[0].length,l=[],c=1,d=[];if(t){var m=[...new Set(s.flat())];d=s.map((e=>this.indexToColor(m.indexOf(e),m.length)))}else{let e=Math.max(...s),t=Math.min(...s);d=s.map((s=>this.indexToColorSequential(s,t,e)))}for(let g=0;g<o;g++)for(let e=0;e<o;e++){if(e<g){let t=r.map((t=>t[e])),s=r.map((e=>e[g]));l.push({x:t,y:s,mode:"markers",type:"scatter",xaxis:"x"+c,yaxis:"y"+c,marker:{color:d,size:2}})}c++}for(var p={width:150*o,height:150*o,spacing:0,title:{text:"TSNE Matrix",font:{size:14},xref:"paper",x:.05},showlegend:!1,boxmode:"overlay",grid:{rows:o,xgap:0,ygap:0,columns:o,pattern:"independent"},margin:{t:30,r:30,l:30,b:40}},u=0;u<o;u++)for(var h=0;h<o;h++){var _="xaxis"+(u*o+h+1),f="yaxis"+(u*o+h+1);let e=10;p[_]={linecolor:"black",linewidth:1,mirror:!0,showgrid:!1,showticklabels:!1,tickfont:{size:e}},p[f]={linecolor:"black",linewidth:1,mirror:!0,showgrid:!1,showticklabels:!1,tickfont:{size:e}},u===o-1&&(p[_]={linecolor:"black",linewidth:1,mirror:!0,tickfont:{size:e},title:{text:"Component-"+(h+1),font:{size:e}}}),0===h&&(p[f]={linecolor:"black",linewidth:1,mirror:!0,tickfont:{size:e},title:{text:"Component-"+(u+1),font:{size:e}}})}M().react("tsne",l,p,{...ee,staticPlot:!1})}trueNegatives(e,t){return tf.tidy((()=>{const s=tf.scalar(0);return tf.logicalAnd(e.equal(s),t.equal(s)).sum().cast("float32")}))}falsePositiveRate(e,t){return tf.tidy((()=>{const s=this.falsePositives(e,t),a=this.trueNegatives(e,t);return s.div(s.add(a))}))}drawROC(e,t){return tf.tidy((()=>{const s=[0,.05,.1,.15,.2,.25,.3,.35,.4,.45,.5,.55,.6,.65,.7,.75,.8,.85,.9,.92,.94,.96,.98,1],a=[],i=[];let n=0;for(let r=0;r<s.length;++r){const o=s[r],l=R(t,o).as1D(),c=this.falsePositiveRate(e,l).dataSync()[0],d=tf.metrics.recall(e,l).dataSync()[0];i.push(c),a.push(d),r>0&&(n+=(a[r]+a[r-1])*(i[r-1]-i[r])/2)}return[n,i,a]}))}nrd(e){let t=W.Fx(e);const s=W.Z0(e);return"number"===typeof s&&(t=Math.min(t,s/1.34)),1.06*t*Math.pow(e.length,-.2)}hexToRgb(e){var t=/^#?([a-f\d]{2})([a-f\d]{2})([a-f\d]{2})$/i.exec(e);return t?{r:parseInt(t[1],16),g:parseInt(t[2],16),b:parseInt(t[3],16),a:.5}:null}draw_kde(e,t,s,a="nrd",i=!1,n=!1){try{let m=e.column(t).values,p=this.nrd(m).toFixed(2),u=e.loc({columns:[t,s]}),h=[...new Set(u.column(s).values)];2===h.length&&h.sort();let _=u.values,f=[];var r=h.map((e=>this.indexToColor(h.indexOf(e),h.legend)));if(i)for(let e=0;e<h.length;e++){const t=h[e];let s=[];for(let e=0;e<_.length;e++){const a=_[e];a[1]===t&&s.push(a[0])}f.push(s)}else f.push(e[t].values);document.getElementById("kde_panel").style.display="block";var o=document.createElement("div");if(o.className="column is-3",o.setAttribute("id",t+"-kde-plot"),!n){let s=O(t);$("#container").append(`<div class="column is-4 is-size-6-tablet my-1">\n                <div class="columns is-multiline">\n                <div class="column is-12" >\n                    <div id="${s+"-kde-plot"}"> </div>\n                    <div id="${s+"-boxplot"}" style="height:20vh;width: 100%">\n                    </div>\n                    <div class="field has-addons has-addons-centered my-1">\n                    <div class="control">\n                    <span class="select is-small">\n                      <select id="${s+"-kernel_type"}">\n                      <option value="gaussian">gaussian</option>\n                        <option value="uniform">uniform</option>\n                        <option value="triangular">triangular</option>\n                        <option value="biweight">biweight</option>\n                        <option value="triweight">triweight</option>\n                        <option value="Epanechnikov">Epanechnikov</option>\n                      </select>\n                    </span>\n                    <p class="help is-success">Kernel</p>\n                  </div>\n                  <div class="control">\n                        <div class="select is-small">\n                            <select id="${s+"--normal"}">\n                                <option value="0">No</option>\n                                <option value="1">Scale</option>\n                                <option value="2">x^2</option>\n                                <option value="3">ln(x)</option>\n                                <option value="4">Standardize </option>\n                            </select>\n                        </div>\n                    <p class="help is-success">Normalization</p>\n                    </div>\n                        <div class="control">\n                            <input class="input is-small" type="number"  min="0" id="${s+"-kde"}" value="${p}">\n                            <p class="help is-success">Bandwidth</p>\n                        </div>\n                        <p class="control">\n                            <a class="button is-success is-small" id="${s+"-kde-button"}">\n                                Apply\n                            </a>\n                        </div>\n                    </div>\n                  </div>\n                </div>`),document.getElementById(s+"--normal").addEventListener("change",(function(){const a=document.getElementById("target").value;let i=document.getElementById(a).value!==z.Numerical,n=e.loc({columns:[t,a]}),r=document.getElementById(s+"--normal").value;G(n,t,r),n.dropNa({axis:1,inplace:!0});var o=parseFloat(document.getElementById(s+"-kde").value);l.draw_kde(n,t,a,o,i,!0)}))}var l=this;let g=O(t);document.getElementById(g+"-kde-button").addEventListener("click",(function(){const s=document.getElementById("target").value;let a=document.getElementById(s).value!==z.Numerical,i=e.loc({columns:[t,s]}),n=document.getElementById(g+"--normal").value;G(i,t,n);var r=parseFloat(document.getElementById(g+"-kde").value);i.dropNa({axis:1,inplace:!0}),l.draw_kde(i,t,s,r,a,!0)}));let b=g+"-kde-plot",y=[...u.column(t).values];var c=W.Wj(y,100);let v,x=[],w=document.getElementById(g+"-kernel_type")?.value??"gaussian",C=[];if(i)for(let e=0;e<f.length;e++){if(f[e].length>2){let t=[];v=W.JL(f[e],this.kernelFunctions[w],a);let s=[];c.forEach((e=>{t.push(v(e,a)),s.push([e,t[t.length-1]])})),x.push(s)}else x.push([]);C.push({name:h[e],x:f[e],marker:{color:r[e]},type:"box"})}else{for(let e=0;e<f.length;e++)if(f[e].length>2){let t=[];v=W.JL(f[e],this.kernelFunctions[w],a);let s=[];c.forEach((e=>{t.push(v(e,a)),s.push([e,t[t.length-1]])})),x.push(s)}else x.push([]);C.push({name:t,x:m,type:"box"})}let k=4e3;var d={yaxis:{visible:!1},showlegend:!1,margin:{l:20,r:10,b:60,t:10},legend:{x:1,xanchor:"right",y:1}};M().newPlot(g+"-boxplot",C,d,{autosize:!0,responsive:!0,modeBarButtonsToRemove:["pan","resetScale2d","select2d","resetViews","sendDataToCloud","hoverCompareCartesian","lasso2d","drawopenpath "]}),Highcharts.chart(b,{credits:{enabled:!1},legend:{enabled:!!i,align:"right",verticalAlign:"top"},chart:{height:"300",type:"spline",animation:!0},title:{text:t},yAxis:{title:{text:null}},tooltip:{valueDecimals:3},plotOptions:{series:{marker:{enabled:!1},dashStyle:"shortdot",color:r,animation:{duration:k},area:!0}},series:x.map(((e,t)=>({type:"area",name:h[t],dashStyle:"solid",lineWidth:2,color:r[t],data:e})))}),window.dispatchEvent(new Event("resize"))}catch(m){throw new Error("falied at plotting kde.")}}downloadPlot(e){M().toImage(e,{format:"png",width:null,height:null,scale:2}).then((function(e){const t=document.createElement("a");t.href=e,t.download="plot.png",document.body.appendChild(t),t.click(),document.body.removeChild(t)}))}async classificationPCA(e,t,s,a,i,n){t=t.flat();const r=new D;var o=t.map((e=>this.indexToColor(a.indexOf(e),a.length)));const l=await r.predict(e,n);let c=[],d=[],m=[],p=[],u=[],h=[],_=[],f=[];l[0].forEach(((a,i)=>{if(s["indexes"].includes(i)){let n=s["indexes"].findIndex((e=>e==i));u.push(e[i].join()),h.push([t[i],s["mispredictions"][n]]),m.push(a[0]),p.push(a[1]),_.push(o[i])}else c.push(a[0]),d.push(a[1]),f.push(o[i])}));var g={x:c,y:d,name:"Predictions",text:t,mode:"markers",type:"scatter",marker:{size:4,color:f,symbol:"circle"}},b={name:"Missclassifications",x:m,y:p,text:u,customdata:h,mode:"markers",type:"scatter",marker:{size:7,color:_,symbol:"cross"},hovertemplate:"Features : %{text}<br>True class: %{customdata[0]}<br>Predited class: %{customdata[1]}<extra></extra>"},y=[g,b];M().newPlot("pca_results_"+i,y,{title:{text:"Principle Component Analysis of Predictions"},hovermode:"closest",hoverlabel:{bgcolor:"#FFF"},showlegend:!0,legend:{x:1,xanchor:"right",y:1,bgcolor:"rgba(0,0,0,0)"},xaxis:{linecolor:"black",linewidth:1,mirror:!0,title:"PC1"},yaxis:{linecolor:"black",linewidth:1,mirror:!0,title:"PC2"}},{...ee,staticPlot:!1,responsive:!0,modeBarButtonsToRemove:["resetScale2d","select2d","resetViews","sendDataToCloud","hoverCompareCartesian","lasso2d","drawopenpath "]})}purge_charts(e){M().purge(e)}async draw_pca(e,t,s,a,i,n,r=!1){const o=new D;s=s.flat();const[l,c,d,m,p]=await o.predict(e,a);let u=l[0].length,h=[],_=[];for(let N=0;N<i.length;N++){let e=[],t=i[N];l.forEach(((a,i)=>{e.push({x:a[t[0]-1],y:a[t[1]-1],label:s[i]}),h.push(s[i][0])}))}_=[];let f=1,g=[];if(t){var b=[...new Set(s)];g=s.map((e=>this.indexToColor(b.indexOf(e),b.length)))}else{let e=Math.max(...s),t=Math.min(...s);g=s.map((s=>this.indexToColorSequential(s,t,e)))}for(let N=0;N<u;N++)for(let t=0;t<u;t++){if(t<N){let e=l.map((e=>e[t])),s=l.map((e=>e[N]));_.push({x:e,y:s,mode:"markers",type:"scatter",xaxis:"x"+f,yaxis:"y"+f,marker:{color:g,size:2}})}else if(t>N){let s=l.map((e=>e[t])),a=e.map((e=>e[N]));_.push({x:s,y:a,mode:"markers",type:"scatter",xaxis:"x"+f,yaxis:"y"+f,marker:{color:g,size:2}})}else{let s=l.map((e=>e[t])),a=e.map((e=>e[N]));_.push({x:s,y:a,mode:"markers",type:"scatter",xaxis:"x"+f,yaxis:"y"+f,marker:{color:g,size:2}})}f++}for(var y={width:150*u,height:150*u,spacing:0,title:{text:"PCA Matrix",font:{size:14},xref:"paper",x:.05},showlegend:!1,boxmode:"overlay",grid:{rows:u,xgap:0,ygap:0,columns:u,pattern:"independent"},margin:{t:30,r:30,l:30,b:40}},v=0;v<u;v++)for(var x=0;x<u;x++){var w="xaxis"+(v*u+x+1),C="yaxis"+(v*u+x+1);let e=10;y[w]={linecolor:"black",linewidth:1,mirror:!0,showgrid:!1,showticklabels:!1,tickfont:{size:e}},y[C]={linecolor:"black",linewidth:1,mirror:!0,showgrid:!1,showticklabels:!1,tickfont:{size:e}},v===u-1&&(y[w]={linecolor:"black",linewidth:1,mirror:!0,tickfont:{size:e},title:{text:"PC-"+(x+1),font:{size:e}}}),0===x&&(y[C]={linecolor:"black",linewidth:1,mirror:!0,tickfont:{size:e},title:{text:"PC-"+(v+1),font:{size:e}}})}M().react("pca_matrix",_,y,{...ee,staticPlot:!0});let k=[],S=[];p.forEach(((e,t)=>{k.push({axref:"x",x:0,ayref:"y",y:0,arrowside:"start",arrowcolor:this.indexToColor(t,p.length),font:{color:this.indexToColor(t,p.length),size:8},xanchor:"left",yanchor:"top",arrowwidth:1.2,arrowhead:5,text:n[t],hovertext:n[t]+`(${m[t][0].toFixed(2)},${m[t][1].toFixed(2)})`,ax:m[t][0],ay:m[t][1]})})),S=[{type:"circle",xref:"x",yref:"y",x0:-1,y0:-1,x1:1,y1:1,line:{color:"rgba(50, 171, 96, 1)"}}],M().newPlot("correlation_circle",[{x:[],y:[],type:"scatter",mode:"markers"}],{title:{text:"Biplot",font:{size:14},xref:"paper",x:.05},annotations:k,shapes:S,showlegend:!0,height:300,width:300,margin:{l:60,r:40,b:60,t:40,pad:10},legend:{x:1,xanchor:"right",y:1,bgcolor:"rgba(0,0,0,0)"},xaxis:{range:[-1.2,1.2],linecolor:"black",linewidth:1,mirror:!0,title:"cor with PC1"},yaxis:{range:[-1.2,1.2],linecolor:"black",linewidth:1,mirror:!0,title:"cor with PC2"}},{...ee,responsive:!0});let z=[],A=0,P=[];d.forEach(((e,t)=>{A+=e,P.push(t+1),z.push(A)}));var E={name:"Propotional",x:P,y:d,type:"scatter"},F={name:"Cumulative",x:P,y:z,type:"scatter"},T={showlegend:!1,x:[1.1,1.1],y:[.92,.82],text:["0.9","0.8"],mode:"text"},$=[E,F,T];return r&&M().newPlot("scree_plot",$,{title:{text:"Scree Plot",font:{size:14},xref:"paper",x:.05},legend:{x:.1,y:.2,traceorder:"normal",orientation:"h",font:{size:8},bgcolor:"rgba(0,0,0,0)"},shapes:[{type:"line",x0:1,y0:.9,x1:Math.max(...P),y1:.9,line:{color:"rgb(250, 0, 0)",width:1.5,dash:"dashdot"}},{type:"line",x0:1,y0:.8,x1:Math.max(...P),y1:.8,line:{color:"rgb(50, 171, 96)",width:1.5,dash:"dashdot"}}],margin:{l:60,r:60,b:40,t:40,pad:10},xaxis:{linecolor:"black",linewidth:1,tickmode:"linear",dtick:1,mirror:!0,zeroline:!1,title:"Number of PCs"},yaxis:{linecolor:"black",linewidth:1,rang:[0,1],zeroline:!1,mirror:!0,title:"Explained variance"}},{...ee,responsive:!0}),[l.map((e=>Array.from(e))),z]}drawStackedHorizontalChart(e,t){var s={x:[20,14,23],y:["giraffes","orangutans","monkeys"],name:"SF Zoo",orientation:"h",marker:{color:"rgba(55,128,191,0.6)",width:1},type:"bar"},a={x:[12,18,29],y:["giraffes","orangutans","monkeys"],name:"LA Zoo",orientation:"h",type:"bar",marker:{color:"rgba(255,153,51,0.6)",width:1}},i=[s,a],n={title:"Colored Bar Chart",barmode:"stack"};M().newPlot("myDiv",i,n)}regularization_plot(e,t,s){const a=[];s.forEach(((s,i)=>{a.push({x:e,y:t.map((e=>e[i])),type:"scatter",name:s,mode:"line"})}));var i={colorway:["#f3cec9","#e7a4b6","#cd7eaf","#a262a9","#6f4d96","#3d3b72","#182844"],title:"Lasso Coefficients as Alpha varies",xaxis:{type:"log",title:"Alpha (Regularization Strength)"},yaxis:{title:"Coefficient Value"}};M().newPlot("lasso_plot",a,i)}argmax(e){return e.reduce(((e,t,s,a)=>t>a[e]?s:e),0)}probabilities_boxplot(e,t,s,a){let i=[],n=[],r={};t.forEach(((t,s)=>{t in r||(r[t]=[]),r[t].push(e[s])}));for(const c in r){const e=r[c];e.forEach((e=>{const t=Math.max(...e);n.push({trueClass:c,predicted:e.findIndex((e=>e==t)),probablity:e})}))}let o=0,l=n.map((e=>e.predicted));for(let c in r){let e=s.findIndex((e=>e==c));i.push({type:"box",name:c,marker:{color:this.indexToColor(e,s.length),size:2,line:{outlierwidth:.3}},line:{width:.5},y:n.map((e=>e.probablity[o])),x:l}),o++}M().newPlot("proba_plot_"+a,i,{xaxis:{linecolor:"black",linewidth:1,mirror:!0,title:"class"},yaxis:{title:"Predicted Probability",linecolor:"black",zeroline:!1,linewidth:1,mirror:!0},legend:{x:1,xanchor:"right",y:1,bgcolor:"rgba(0,0,0,0)"},boxmode:"group"},{responsive:!0})}async plotConfusionMatrix(e,t,s,a,i){const n=await Y.metrics.confusionMatrix(e,t,a.length);let r=await L(e.arraySync(),t.arraySync(),a),o=r.accuracy.toFixed(2),l=r.f1_micro.toFixed(2),c=r.f1_macro.toFixed(2),d=n[0].length,m=[],p=[];for(let f=0;f<d;f++)m.push(parseFloat(r.precision[f].toFixed(2)));for(let f=0;f<d;f++)p.push(parseFloat(r.recall[f].toFixed(2)));g.tensorflow.dispose(e),g.tensorflow.dispose(t);const u=["Precession","Recall","F1 score","Support"];s.push("Precession"),p.push(0),n.push(m);let h=s.filter((e=>!u.includes(e))),_=[];for(let f=0;f<n.length;f++){const e=n[f];f<n.length-1&&e.push(p[f]);for(let t=0;t<e.length;t++){const s=e[t];_.push([t,f,s])}}return h.push("Recall"),Highcharts.chart("confusion_matrix_"+i,{credits:{enabled:!1},exporting:{enabled:!0},chart:{type:"heatmap",plotBorderWidth:1},title:{text:"",style:{fontSize:"0.75em"}},xAxis:[{categories:h,title:{text:"Predicted Class"}},{linkedTo:0,opposite:!0,tickLength:0,labels:{formatter:function(){var e=this.chart,t=(Highcharts.each,e.series[0]),s=0,i=this.value;return t.options.data.forEach((function(e,t){e[0]===i&&e[1]<a.length&&(s+=e[2])})),+s.toFixed(2)}}}],yAxis:[{categories:s,title:{text:"Actual Class"},reversed:!0,endOnTick:!1},{linkedTo:0,opposite:!0,tickLength:0,labels:{formatter:function(){var e=this.chart,t=(Highcharts.each,e.series[0]),s=0,i=this.value;return t.options.data.forEach((function(e,t){e[1]<a.length&&e[1]===i&&e[0]<a.length&&(s+=e[2])})),+s.toFixed(2)}},title:null}],colorAxis:{min:0,minColor:"#FFFFFF",maxColor:Highcharts.getOptions().colors[0]},legend:{enabled:!1,align:"center",layout:"horizontal",margin:0,verticalAlign:"top",y:5,symbolHeight:10},series:[{name:"",borderWidth:1,data:_,dataLabels:{enabled:!0,useHTML:!0,color:"#000000",formatter:function(){var e=this.series.data.reduce((function(e,t,s){return(s+1)%(a.length+1)===0?e:+(e+t?.value).toFixed(2)}),0),t=this.point.value,s=this.point.index>=this.series.data.length-1*(a.length+1);if(s||(this.point.index+1)%(a.length+1)===0)return'<p style="margin:auto; text-align:center;">'+ +t.toFixed(2)+"</p>";var i=+(t/e*100).toFixed(2);return'<p style="margin:auto; text-align:center;">'+ +t.toFixed(2)+"<br/>("+(+i).toFixed(2)+"%)</p> "}}}],responsive:{rules:[{condition:{maxWidth:200},chartOptions:{yAxis:{labels:{format:"{substr value 0 1}",padding:0,style:{fontSize:"6px"}}}}}]}}),[o,l,c]}plot_regularization(e,t,s,a){let i=`\n                    <div class="column is-6" id="regularization_${a}" style="height: 40vh;">\n                    </div>\n    `;$("#tabs_info li[data-index='"+a+"'] #results_"+a).append(i);let n=[];for(let o=0;o<s.length;o++)n.push({name:s[o],data:e.map((e=>e[o]))});const r=[];for(let o=0;o<t.length;o++)r.push(t[o].toFixed(2));Highcharts.chart("regularization_"+a,{title:{text:""},yAxis:{title:{text:"Coefficients"}},xAxis:{title:{text:"penalty weight"},categories:r},legend:{layout:"vertical",align:"right",verticalAlign:"middle"},plotOptions:{series:{label:{connectorAllowed:!1}}},series:n,responsive:{rules:[{condition:{maxWidth:500},chartOptions:{legend:{layout:"horizontal",align:"center",verticalAlign:"bottom"}}}]}})}yhat_plot(e,t,s,a=""){M().newPlot(s,[{x:e,y:t,type:"scatter",name:"y",mode:"markers",marker:{color:"blue",size:4}},{x:e,y:e,mode:"lines",type:"scatter",line:{color:"red",dash:"solid"},name:"y = x line"}],{height:300,width:300,title:{text:a,font:{size:14},xref:"paper",x:.05},showlegend:!1,xaxis:{linecolor:"black",linewidth:1,mirror:!0,title:{text:"y",font:{size:14}}},yaxis:{linecolor:"black",linewidth:1,mirror:!0,title:{text:"Predictions",font:{size:14}}},margin:{l:40,r:10,b:40,t:40,pad:0}},{responsive:!0,staticPlot:!1,...ee})}comparison(e,t,s,a="",i=""){M().newPlot(s,[{x:e,y:t,type:"scatter",name:"y",mode:"line",marker:{color:"blue",size:4}}],{height:300,width:300,title:{text:a,font:{size:14},xref:"paper",x:.05},showlegend:!1,xaxis:{linecolor:"black",tickangle:-45,linewidth:1,mirror:!0,title:{font:{size:14}}},yaxis:{linecolor:"black",linewidth:1,mirror:!0,title:{text:i,font:{size:14}}},margin:{l:40,r:10,b:80,t:40,pad:0}},{responsive:!0,staticPlot:!1,...ee})}residual_plot(e,t,s,a=""){M().newPlot(s,[{x:e,y:t,type:"scatter",name:"y",mode:"markers",marker:{color:"blue",size:4}},{x:e,y:e.map((e=>0)),mode:"lines",type:"scatter",line:{color:"red",dash:"solid"}}],{height:300,width:300,title:{text:a,font:{size:14},xref:"paper",x:.05},showlegend:!1,xaxis:{linecolor:"black",linewidth:1,mirror:!0,title:{text:"y",font:{size:14}}},yaxis:{linecolor:"black",linewidth:1,mirror:!0,title:{text:"Residuals",font:{size:14}}},margin:{l:40,r:10,b:40,t:40,pad:0}},{responsive:!0,...ee,staticPlot:!1})}ScatterplotMatrix(e,t,s,a,i=!0,n,r,o){return new Promise(((n,o)=>{setTimeout((()=>{let o=[...new Set(s)];2===o.length&&o.sort(),console.log("splom",o);var l=s.map((e=>this.indexToColor(o.indexOf(e),o.length)));let c=[],d=1;for(let n=0;n<t.length;n++)for(let m=0;m<t.length;m++){if(n===m){let s,l=[],m=[],p=[];if(i)if(n>=t.length-a)if(n===t.length-1){for(let t=0;t<o.length;t++)l.push(e.filter((s=>s[e[0].length-1]===o[t])).map((e=>e[n])));c.push({x:o.map((e=>""+e)),y:l.map((e=>e.length)),type:"bar",xaxis:"x"+d,yaxis:"y"+d,marker:{color:o.map(((e,t)=>this.indexToColor(t,o.length))),opacity:.7}})}else{let t=[...new Set(e.map((e=>e[n])))];for(let s=0;s<o.length;s++){let a=e.filter((t=>t[e[0].length-1]===o[s])),i=[];t.forEach((e=>i.push(a.filter((t=>t[n]===e)).length))),l.push({items:a,counts:i})}o.forEach(((e,s)=>{c.push({x:t,y:l[s].counts,type:"bar",xaxis:"x"+d,yaxis:"y"+d,marker:{color:this.indexToColor(s,o.length),opacity:.7}})}))}else{for(let t=0;t<o.length;t++)l.push(e.filter((s=>s[e[0].length-1]===o[t])).map((e=>e[n])));for(let e=0;e<l.length;e++)if(l[e].length>2){let t=this.nrd(l[e]).toFixed(2);m=W.Wj(l[e],100);let a=[];s=W.JL(l[e],"gaussian","nrd");let i=[];m.forEach((e=>{a.push(s(e,t)),i.push([e,a[a.length-1]])})),p.push(i)}else p.push([]);for(let e=0;e<p.length;e++)c.push({type:"scatter",x:p[e].map((e=>e[0])),y:p[e].map((e=>e[1])),xaxis:"x"+d,yaxis:"y"+d,mode:"lines",name:"Red",fill:"tozeroy",line:{color:this.indexToColor(e,o.length),opacity:.7,width:3}})}else if(r.includes(t[n])){let t=e.map((e=>e[n])),s=[...new Set(t)],a=[];for(let e=0;e<s.length;e++){const i=s[e];a.push(t.filter((e=>e===i)).length)}c.push({x:s,y:a,type:"bar",name:"Trace 1",xaxis:"x"+d,yaxis:"y"+d})}else{l.push(e.map((e=>e[n])));for(let e=0;e<l.length;e++)if(l[e].length>2){let t=[],a=this.nrd(l[e]).toFixed(2);m=W.Wj(l[e],100),s=W.JL(l[e],"gaussian","nrd");let i=[];m.forEach((e=>{t.push(s(e,a)),i.push([e,t[t.length-1]])})),p.push(i)}else p.push([]);c.push({type:"scatter",x:p[0].map((e=>e[0])),y:p[0].map((e=>e[1])),mode:"lines",fill:"tozeroy",xaxis:"x"+d,yaxis:"y"+d,name:"Red",line:{color:"rgb(219, 64, 82)",opacity:.7,width:3}})}}else if(n===t.length-1)c.push({y:e.map((e=>e[n])),x:e.map((e=>e[m])),color:l,marker:{colorscale:"Portland",color:i?l:s,opacity:.7,size:2},type:"scattergl",mode:"markers",xaxis:"x"+d,yaxis:"y"+d});else if(m>=t.length-a)if(i){let s=[...new Set(e.map((e=>e[m])))].sort(((e,t)=>e-t)),a=[];for(let i=0;i<o.length;i++)for(let r=0;r<s.length;r++){let l=e.filter((e=>e[m]===s[r]&&e[t.length-1]===o[i]));l&&a.push({y:l.map((e=>e[n])),marker:{color:this.indexToColor(i,o.length),size:2,line:{outlierwidth:.3}},type:"box",xaxis:"x"+d,yaxis:"y"+d,line:{width:.5}})}if(m<t.length-1){for(let e=0;e<a.length/2;e++)a[e]["x"]=Array(a[e]["y"].length).fill(e),a[a.length/2+e]&&(a[a.length/2+e]["x"]=Array(a[e]["y"].length).fill(e+.5));c=c.concat(a)}else c=c.concat(a)}else c.push({x:[],y:[],mode:"lines",name:"Trace 1"});else if(m>n){let t=e.map((e=>e[n])),s=e.map((e=>e[m]));c.push({x:[1.5],y:[1.5],text:[jStat.corrcoeff(t,s).toFixed(2)],mode:"text",textfont:{size:12,color:"black"},xaxis:"x"+d,yaxis:"y"+d,type:"scatter"})}else c.push({y:e.map((e=>e[n])),x:e.map((e=>e[m])),color:l,type:"scattergl",mode:"markers",marker:{colorscale:"Portland",color:i?l:s,size:2},xaxis:"x"+d,yaxis:"y"+d});d++}for(var m={width:100*t.length,height:100*t.length,spacing:0,showlegend:!1,boxmode:"overlay",grid:{rows:t.length,xgap:0,ygap:0,columns:t.length,pattern:"independent"},margin:{t:20,r:20}},p=0;p<t.length;p++)for(var u=0;u<t.length;u++){var h="xaxis"+(p*t.length+u+1),_="yaxis"+(p*t.length+u+1);let e=10;m[h]={linecolor:"black",linewidth:1,mirror:!0,showgrid:!1,showticklabels:!1,tickfont:{size:e}},m[_]={linecolor:"black",linewidth:1,mirror:!0,showgrid:!1,showticklabels:!1,tickfont:{size:e}},p===t.length-1&&(m[h]={linecolor:"black",linewidth:1,mirror:!0,tickfont:{size:e},title:{text:t[u],font:{size:e}}}),0===u&&(m[_]={linecolor:"black",linewidth:1,mirror:!0,tickfont:{size:e},title:{text:t[p],font:{size:e}}})}M().react("scatterplot_mtx",c,m,{...ee,staticPlot:!0,modeBarButtonsToRemove:["resetScale2d","select2d","resetViews","sendDataToCloud","hoverCompareCartesian","lasso2d","drawopenpath "]}),n()}),1e3)}))}KNNPerformancePlot(e,t,s,a="Accuracy"){let i=[];i.push({x:e.map((e=>e[1])),y:e.filter((e=>"manhattan"===e[0])).map((e=>Number(e[2]))),mode:"lines",name:"manhattan test set",line:{color:"rgb(55, 128, 191)",width:2}}),i.push({x:e.map((e=>e[1])),y:e.filter((e=>"euclidean"===e[0])).map((e=>Number(e[2]))),mode:"lines",name:"euclidean test set",line:{color:"rgb(219, 64, 82)",width:2}});var n={showlegend:!0,legend:{x:.1,y:.2,traceorder:"normal",orientation:"h",font:{size:12},bgcolor:"rgba(0,0,0,0)"},xaxis:{linecolor:"black",linewidth:1,mirror:!0,title:{text:"K"}},yaxis:{range:[0,1],linecolor:"black",linewidth:1,mirror:!0,title:{text:a}},shapes:[{type:"line",x0:t,y0:0,x1:t,y1:1,line:{dash:"dot",color:"rgb(55, 128, 191)",width:1}}]};M().newPlot("knn_table_"+s,i,n,{responsive:!0})}KNNPerformancePlotRegression(e,t,s,a){let i=[];i.push({x:e.map((e=>e.k)),y:e.filter((e=>"manhattan"===e.metric)).map((e=>Number(e.evaluation.toFixed(2)))),mode:"lines",name:"manhattan test set",line:{color:"rgb(55, 128, 191)",width:2}}),i.push({x:e.map((e=>e.k)),y:e.filter((e=>"euclidean"===e.metric)).map((e=>Number(e.evaluation.toFixed(2)))),mode:"lines",name:"euclidean test set",line:{color:"rgb(219, 64, 82)",width:2}}),i.push({x:e.map((e=>e.k)),y:e.filter((e=>"manhattan"===e.metric)).map((e=>Number(e.evaluation_train.toFixed(2)))),mode:"lines",name:"manhattan train set",line:{color:"rgb(55, 128, 191)",width:1}}),i.push({x:e.map((e=>e.k)),y:e.filter((e=>"euclidean"===e.metric)).map((e=>Number(e.evaluation_train.toFixed(2)))),mode:"lines",name:"euclidean train set",line:{color:"rgb(219, 64, 82)",width:1}});var n=Number.POSITIVE_INFINITY,r=Number.NEGATIVE_INFINITY;i.forEach((e=>{let t=Math.min(...e.y),s=Math.max(...e.y);t<n&&(n=t),s>r&&(r=s)}));var o={showlegend:!0,legend:{x:.1,y:.2,traceorder:"normal",orientation:"h",font:{size:10},bgcolor:"rgba(0,0,0,0)"},xaxis:{title:{text:"K"}},yaxis:{title:{text:"MSE"}},shapes:[{type:"line",x0:t.k,y0:n,x1:t.k,y1:r,line:{color:"rgb(55, 128, 191)",width:1}},{type:"line",x0:s.k,y0:n,x1:s.k,y1:r,line:{color:"rgb(55, 128, 191)",width:1}}]};M().newPlot("knn_table_"+a,i,o)}correaltoinMatrixColorscale(e){let t=e[0].length,s=[];for(let r=0;r<t;r++)s.push(...e[r]);s.sort();let a=0;for(let r=0;r<s.length;r++){if(!(s[r]<0))break;a+=1}let i=Math.round((a-1)/s.length*100)/100,n=[[0,"rgb(0, 0, 100)"],[i,"rgb(161, 161, 255)"],[i+.001,"rgb(253, 237, 237)"],[1,"rgb(255, 0, 0)"]];return n}async correlationHeatmap(e,t,s){for(var a=[{z:t,x:s,y:s,type:"heatmap",zmin:-1,zmax:1,hoverongaps:!1,colorscale:[[0,"rgb(74,141,255)"],[.1,"rgb(102,151,255)"],[.2,"rgb(121,170,255)"],[.3,"rgb(137,187,255)"],[.4,"rgb(205,221,255)"],[.5,"rgb(255,255,255)"],[.51,"rgb(253, 237, 237)"],[.6,"rgb(255,169,169)"],[.75,"rgb(249,100,100)"],[.95,"rgb(225,0,0)"],[1,"rgb(165,0,0)"]],showscale:!1}],i={annotations:[],font:{size:10},xaxis:{ticks:"",side:"bottom",tickangle:-90},yaxis:{autorange:"reversed",tickangle:-45,ticks:"",ticksuffix:" "},autosize:!0},n=0;n<s.length;n++)for(var r=s.length-1;r>=0;r--){var o=t[n][r];let e;e="black";var l={xref:"x1",yref:"y1",x:s[n],y:s[r],text:o.toFixed(2),font:{family:"Arial",size:8,color:e},showarrow:!1};i.annotations.push(l)}await M().newPlot(e,a,i,{...ee,responsive:!0})}async dendogramPlot(e,t,s,a,i){var n={x:a,y:a,z:t,type:"heatmap",zmin:-1,zmax:1,hoverongaps:!1,colorscale:[[0,"rgb(74,141,255)"],[.1,"rgb(102,151,255)"],[.2,"rgb(121,170,255)"],[.3,"rgb(137,187,255)"],[.4,"rgb(205,221,255)"],[.5,"rgb(255,255,255)"],[.51,"rgb(253, 237, 237)"],[.6,"rgb(255,169,169)"],[.75,"rgb(249,100,100)"],[.95,"rgb(225,0,0)"],[1,"rgb(165,0,0)"]],xaxis:"x",yaxis:"y",colorbar:{thickness:10,len:.5}};let r=[],o=s.length+1,l=0,c=0,d=0,m=0;for(let k=0;k<i.length;k++)r.push(a.findIndex((e=>e==i[k])));let p=[];for(let k=0;k<o;k++)p.push(10*(k+1));let u={data:[],layout:{width:"100%",showlegend:!1,xaxis:{showticklabels:!0,tickmode:"array",ticks:"outside",showgrid:!1,mirror:"allticks",zeroline:!1,showline:!0,rangemode:"tozero",type:"linear"},yaxis:{showticklabels:!0,ticks:"outside",showgrid:!1,mirror:"allticks",zeroline:!1,showline:!0,rangemode:"tozero",type:"linear"},hovermode:"closest",autosize:!1,height:"100%"}},h={data:[],layout:{width:"100%",showlegend:!1,xaxis:{showticklabels:!0,ticks:"outside",showgrid:!1,mirror:"allticks",zeroline:!1,showline:!0,rangemode:"tozero",type:"linear"},yaxis:{showticklabels:!0,tickmode:"array",ticks:"outside",showgrid:!1,mirror:"allticks",zeroline:!1,showline:!0,rangemode:"tozero",type:"linear"},hovermode:"closest",autosize:!1,height:"100%"}},_={};s.forEach(((e,t)=>{let s,a;if(r[e[0]]+1&&(s=r[e[0]]+1??e[0]+1),r[e[1]]+1&&(a=r[e[1]]+1??e[1]+1),0==l&&(l=parseFloat(t+1)/o),s<=o&&a<=o)m=(s*(Math.max(...p)/o)+a*(Math.max(...p)/o))/2,u.data.push({yaxis:"y2",x:[10*s,10*s,10*a,10*a],mode:"lines",xaxis:"x",marker:{color:`${this.indexToColor(t)}`},y:[c,l,l,c],type:"scatter"});else{c=s<=o?l:_[e[0]]?.y_current,l=parseFloat(t+1)/o;let i=[s<=o?10*s:_[e[0]]?.x,s<=o?10*s:_[e[0]]?.x,a<=o?10*a:_[e[1]]?.x,a<=o?10*a:_[e[1]]?.x],n=[_[e[0]]?.y_current??0,l,l,_[e[1]]?.y_current??0];u.data.push({yaxis:"y2",x:i,mode:"lines",xaxis:"x",marker:{color:`${this.indexToColor(t)}`},y:n,type:"scatter"}),m=i.reduce(((e,t)=>e+t),0)/4}_[o+t]={x:m,y_current:l}}));let f=0,g=0;_=[],s.forEach(((e,t)=>{let s=r[e[0]]+1,a=r[e[1]]+1;if(0==f&&(f=parseFloat(t+1)/o),s<=o&&a<=o)d=(-10*s+-10*a)/2-2,h.data.push({yaxis:"y",y:[-10*s,-10*s,-10*a,-10*a],mode:"lines",xaxis:"x2",marker:{color:`${this.indexToColor(t)}`},x:[g,f,f,g],type:"scatter"});else{g=s<=o?f:_[e[0]].x,f=parseFloat(t+1)/o;let i=[s<=o?-10*s:_[e[0]]?.y,s<=o?-10*s:_[e[0]]?.y,a<=o?-10*a:_[e[1]]?.y,a<=o?-10*a:_[e[1]]?.y];h.data.push({yaxis:"y",y:i,mode:"lines",xaxis:"x2",marker:{color:`${this.indexToColor(t)}`},x:[_[e[0]]?.x??0,f,f,_[e[1]]?.x??0],type:"scatter"}),d=i.reduce(((e,t)=>e+t),0)/4}_[o+t]={y:d,x:f}}));for(var b={annotations:[],font:{size:10},autosize:!0,yaxis:{domain:[0,.75],mirror:!1,showgrid:!1,showline:!1,zeroline:!1,showticklabels:!0,ticks:"",tickvals:p.map((e=>-e)),ticktext:a,tickangle:-45},xaxis:{domain:[0,.75],mirror:!1,showgrid:!1,showline:!1,zeroline:!1,showticklabels:!0,ticks:"",tickvals:p,ticktext:a,tickangle:-90},xaxis2:{domain:[.75,1],mirror:!1,showgrid:!1,showline:!1,zeroline:!1,showticklabels:!1,ticks:"",ticktext:a},yaxis2:{domain:[.75,1],mirror:!1,showgrid:!1,showline:!1,zeroline:!1,showticklabels:!1,ticktext:a},showlegend:!1,coloraxis:{colorscale:"YlGnBu",showscale:!0,cmin:-1,cmax:1},margin:{l:60,r:30,b:60,t:30}},y=0;y<a.length;y++)for(var v=a.length-1;v>=0;v--){var x=t[y][v];let e;e="black";var w={xref:"x",yref:"y",x:p[y],y:-p[v],text:x.toFixed(2),font:{family:"Arial",size:8,color:e},showarrow:!1};b.annotations.push(w)}let C=u["data"];C=C.concat(h["data"]),n["x"]=p,n["y"]=p.map((e=>-e)),C=C.concat(n),M().newPlot(e,C,b,{...ee,responsive:!0})}PFIBoxplot(e,t,s){let a=[],i=[];t.forEach((e=>{const t=e.reduce(((e,t)=>e+t),0);i.push(t/e.length)}));Math.max(...i),Math.min(...i);t.forEach(((e,i)=>{a.push({x:Array.from(e),type:"box",name:s[i],marker:{color:this.indexToColor(i,t.length)}})}));var n={title:{text:"Permutation Feature Importance",font:{size:14},xref:"paper",x:.05},showlegend:!1,xaxis:{linecolor:"black",linewidth:1,mirror:!0,zeroline:!1},yaxis:{linecolor:"black",linewidth:1,mirror:!0,automargin:!0,zeroline:!1}};M().newPlot("pfi_boxplot_"+e,a,n,{responsive:!0})}plotPDP(e,t,s,a,i,n){let r="pdp_containers_"+e;e="pdp_plot_"+e,s.forEach(((s,o)=>{let l=document.getElementById(r),c=document.createElement("div");c.classList.add("column","is-6");let d=e+"_"+o;c.id=d,c.style.height="400px",l.after(c);let m=[];const p=n.includes(i[o]);t[o].forEach(((e,i)=>{p?m.push({x:s,y:Array.from(e),type:"bar",name:a[i],marker:{color:this.indexToColor(i,t[o].length)}}):m.push({x:s,y:Array.from(e),mode:"line",name:a[i],marker:{color:this.indexToColor(i,t[o].length)}})}));var u={title:{text:"Partial Dependence Plot - "+i[o],font:{size:14},xref:"paper",x:.05},legend:{orientation:"h"},font:{size:10},autosize:!0,xaxis:{linecolor:"black",linewidth:1,mirror:!0,zeroline:!1},yaxis:{linecolor:"black",zeroline:!1,linewidth:1,mirror:!0,title:{text:"Prediction"}}};M().newPlot(d,m,u,{...ee,responsive:!0})}))}plotPDPRegression(e,t,s,a,i,n){let r="pfi_boxplot_"+e,o=document.getElementById(r),l=document.createElement("div");l.classList.add("column","is-6");const c=e+"_number";l.id=c,l.style.height="400px",o.after(l),o=document.getElementById(c),l=document.createElement("div"),l.classList.add("column","is-6");const d=e+"_class";l.id=d,l.style.height="400px",o.after(l);let m=[],p=[];s.forEach(((e,s)=>{n.includes(i[s])?t[s].forEach(((a,n)=>{p.push({x:e,y:Array.from(a),type:"bar",name:i[s],marker:{color:this.indexToColor(s,t.length),opacity:.7}})})):t[s].forEach(((a,n)=>{let r=new g.MinMaxScaler;r.fit(e);let o=e;m.push({x:o,y:Array.from(a),mode:"line",name:i[s],marker:{color:this.indexToColor(s,t.length)}})}))}));var u={title:{text:"Partial Dependence Plot",font:{size:14},xref:"paper",x:.05},legend:{x:.1,y:1,orientation:"h",font:{size:8},bgcolor:"rgba(0,0,0,0)"},font:{size:10},autosize:!0,xaxis:{linecolor:"black",linewidth:1,mirror:!0,zeroline:!1,title:{text:"Feature"}},yaxis:{linecolor:"black",linewidth:1,mirror:!0,zeroline:!1,title:{text:"Prediction"}}};M().newPlot(c,m,u,{...ee,responsive:!0});var h={title:{text:"Partial Dependence Plot",font:{size:14},xref:"paper",x:.05},barmode:"group",font:{size:10},autosize:!0,xaxis:{linecolor:"black",linewidth:1,mirror:!0,title:{text:"Feature"}},bargap:.05,yaxis:{linecolor:"black",linewidth:1,mirror:!0,title:{text:"Prediction"}}};M().newPlot(d,p,h)}drawAutoencoder(e,t=1,s=0,a,i){a=a.map((e=>e[0]));let n=[];if(i){var r=[...new Set(a)];n=e.map(((e,t)=>this.indexToColor(r.indexOf(a[t]),r.length)))}else{let e=Math.min(...a),t=Math.max(...a);n=a.map((s=>this.indexToColorSequential(s,e,t)))}var o={x:e.map((e=>e[t])),y:e.map((e=>e[s])),mode:"markers",type:"scatter",name:"Team A",marker:{size:3,color:n}},l=[o],c={legend:{y:.5,yref:"paper",font:{family:"Arial, sans-serif",size:20,color:"grey"}},xaxis:{linecolor:"black",linewidth:1,mirror:!0,zeroline:!1},yaxis:{linecolor:"black",linewidth:1,zeroline:!1,mirror:!0},margin:{l:50,r:40,b:50,t:40,pad:20}};M().newPlot("autoencoder",l,c)}plotROC(e,t,s,a,i){let n=[];t.forEach(((e,t)=>{n.push({x:e,y:s[t],mode:"line",name:a[t],marker:{color:this.indexToColor(t,a.length)}})})),n.push({x:[0,1],y:[0,1],mode:"line",name:"Chance Line",marker:{color:"black"},line:{dash:"dot",width:1}});var r={title:{text:(a.length>2?" One-vs-Rest Strategy ROC Curve":"ROC Curve")+" AUC: "+(+i).toFixed(2),font:{size:14}},margin:{b:40},legend:{x:1,xanchor:"right",y:.1,bgcolor:"rgba(0,0,0,0)"},showlegend:!0,xaxis:{linecolor:"black",linewidth:1,range:[-.1,1.1],mirror:!0,title:{text:"False positive rate"}},yaxis:{linecolor:"black",linewidth:1,mirror:!0,range:[-.1,1.1],title:{text:"True positive rate"}}};M().newPlot("roc_plot_"+e,n,r,{responsive:!0})}uniformSplist(e){let t=[];for(let s=0;s<e;s++)t.push(s/(e-1));return t}parallelCoordinatePlot(e,t,s,a){let i=new g.LabelEncoder;a&&(i.fit(t),t=i.transform(t));var n=[...new Set(t)];2===n.length&&n.sort(),console.log("pc labels",n);let r=this.uniformSplist(n.length),o=n.map(((e,t)=>[r[t],this.indexToColor(n.indexOf(e),n.length)]));var l=[{type:"parcoords",pad:[20,20,20,20],line:{color:t,colorscale:a?o:"jet"},dimensions:[]}];s.forEach(((t,s)=>{l[0].dimensions.push({label:t,values:e.map((e=>e[s]))})}));var c={title:{text:"Parallel Coordinate Plot",font:{size:14},xref:"paper",x:.05},xaxis:{linecolor:"black",linewidth:1,mirror:!0},yaxis:{linecolor:"black",linewidth:1,mirror:!0}};M().newPlot("parallel_coordinate_plot",l,c,{...ee,responsive:!0,modeBarButtonsToRemove:["resetScale2d","select2d","resetViews","sendDataToCloud","hoverCompareCartesian","lasso2d","drawopenpath "]})}}class se{constructor(e,t){this.data_parser=e,this.chart_controller=t}get_model_settings(){let e={},t=parseInt(document.getElementById("model_name").value);const s=document.getElementById("target").value;let a=document.getElementById(s).value!==z.Numerical;var i;if(a){for(const n in E.classification)if(E.classification[n].value===t){t=n,e.name=E.classification[n].label,i=E.classification[t];break}}else for(const n in E.regression)if(E.regression[n].value===t){t=n,e.name=E.regression[n].label,i=E.regression[t];break}t=parseInt(document.getElementById("model_name").value);for(const n in i?.options)if("select"===i.options[n].type){let s=document.getElementById(n+"_"+t)?.value;e[n]=s??i.options[n].default}else if("number"===i.options[n].type){let s=document.getElementById(n+"_"+t)?.value;e[n]=s?parseFloat(s):i.options[n].default}else{let s=document.getElementById(n+"_"+t)?.value;e[n]=s??i.options[n].default}return e}scale_data(e,t,s){switch(s){case"1":{let s=new g.MinMaxScaler;s.fit(e[t]),e.addColumn(t,s.transform(e[t]),{inplace:!0});break}case"2":e.addColumn(t,e[t].apply((e=>e*e)),{inplace:!0});break;case"3":e.addColumn(t,e[t].apply((e=>Math.log(e))),{inplace:!0});break;case"4":{let s=new g.StandardScaler;s.fit(e[t]),e.addColumn(t,s.transform(e[t]),{inplace:!0});break}default:break}}createAlgorithmsSelect(e){let t='<div id="algorithm" class="column is-9"><div class="select is-small mb-1"> <select id="model_name" class="select">';const s=1==e?"regression":"classification";for(const a in E[s])if(E.hasOwnProperty.call(E[s],a)){const e=E[s][a];t+=`<option value="${e.value}">${e.label}</option>`}return t+="</select></div></div>",t}updateAlgorithmsSelect(e){let t='<div class="select is-small mb-1"> <select id="model_name" class="select">';const s=1==e?"regression":"classification";for(const a in E[s])if(E.hasOwnProperty.call(E[s],a)){const e=E[s][a];t+=`<option value="${e.value}">${e.label}</option>`}return t+="</select></div>",t}find_selected_columns(e,t=!1){const s=[];return e.forEach((e=>{let a=O(e);(document.getElementById(a+"-checkbox").checked||t)&&s.push(e)})),s}find_selected_columns_types(e,t=!0){if(!1===t){const t=document.getElementById("target").value;e=e.filter((e=>e!==t))}const s=[];return e.forEach((e=>{let t=O(e);s.push({name:e,type:document.getElementById(t).value})})),s}createTargetDropdown(e){let t='<div  class="column is-12"><div class="label is-size-7">Target</div><div class="select is-fullwidth is-small mb-1"> <select id="target">';return e.columns.forEach((e=>{let s=O(e);t+=`<option value="${s}">${s}</option>`})),t+="</select></div></div>",t}createFeaturesDropdown(e){let t='<div  class="column is-4"><h4>Target</h4><div class="select mb-1"> <select class="select" id="kde_feature">';for(const s in e)t+=`<option value="${s}">${s}</option>`;return t+="</select></div></div>",t}insertSpaces(e){return e=e.replace(/([a-z])([A-Z])/g,"$1 $2"),e=e.replace(/([A-Z])([A-Z][a-z])/g,"$1 $2"),e}renderDatasetStats(e,t,s){let a=[],i=[];const n=[{field:"name",label:"#"},{field:"min",label:"Min"},{field:"max",label:"Max"},{field:"mean",label:"Mean"},{field:"median",label:"Median"},{field:"std",label:"std"},{field:"missingVlauesCount",label:"# NAs"},{field:"type",label:"type"}],r=[{field:"name",label:"#"},{field:"shape",label:"Shape"},{field:"mode",label:"Mode"},{field:"percentage",label:"Mode Percentage"},{field:"missingVlauesCount",label:"# NAs"}];for(let o=0;o<t.length;o++){const s=t[o].name;a.push({name:s,min:e.column(s).min().toFixed(2),max:e.column(s).max().toFixed(2),median:e.column(s).median().toFixed(2),mean:e.column(s).mean().toFixed(2),std:e.column(s).std().toFixed(2),missingValuesCount:e.column(s).isNa().sum(),type:1,selected:t[o].selected})}return s.forEach((t=>{let s=t.name;const a=[...new Set(e.column(s).values)],n=this.getCategoricalMode(e.column(s).values);i.push({name:s,shape:a.length,mode:n["mode"],percentage:(n[n["mode"]]/n["total"]).toFixed(2),missingValuesCount:e.column(s).isNa().sum(),type:2,selected:t.selected})})),[n,a,r,i]}getCategoricalMode(e){if(0===e.length)return null;const t={total:0,mode:""};for(let i=0;i<e.length;i++){const s=e[i];null!==s&&void 0!==s&&(t["total"]++,s in t?t[s]++:t[s]=1)}let s=null,a=0;for(const i in t)"total"!==i&&t[i]>a&&(s=i,a=t[i]);return t["mode"]=s,t}get_numeric_columns(e,t){let s=this.find_selected_columns(e.columns,!t),a=this.find_selected_columns_types(s);s=s.filter((e=>{let t=a.findIndex((t=>t.name===e));return a[t]?.type===z.Numerical}));let i=[];return e.columns.forEach((t=>{"string"!==e.column(t).dtype&&"Id"!==t&&s.includes(t)&&i.push(t)})),i}get_categorical_columns(e,t){let s=this.find_selected_columns(e.columns,!t),a=this.find_selected_columns_types(s);s=s.filter((e=>{let t=a.findIndex((t=>t.name===e));return-1!==t&&a[t]?.type!==z.Numerical}));let i=[];return e.columns.forEach((e=>{"Id"!==e&&s.includes(e)&&i.push(e)})),i}column_types(e){let t=this.find_selected_columns(e,!1);return this.find_selected_columns_types(t)}async visualize(e,t){this.renderDatasetStats(e);let s=this.get_numeric_columns(e,!0),a=this.get_categorical_columns(e,!0);const i=document.getElementById("target").value;let n=[...new Set(s.concat(a))];const r=e.loc({columns:n});r.dropNa({axis:1,inplace:!0}),s=s.filter((e=>e!==i));let o=document.getElementById(i).value!==z.Numerical,l=0;if(s.length>0&&l<10&&(document.getElementById("container").innerHTML="",s.forEach((e=>{e!==i&&this.chart_controller.draw_kde(r,e,i,"nrd",o)})),l++),l=0,a.length>0&&l<10&&(document.getElementById("categories_barplots").innerHTML="",a.forEach((e=>{e!==i&&this.chart_controller.draw_categorical_barplot(r.loc({columns:[e]}).values,i,e)})),l++),o){let s=e.column(i).values,a=[...new Set(s)],n=[];for(let e=0;e<a.length;e++)n.push(s.filter((t=>t===a[e])).length);this.chart_controller.classification_target_chart(n,a,t,"target_chart",i)}else this.chart_controller.regression_target_chart(e.column(i).values,"target_chart",i);s=this.get_numeric_columns(e,!0),a=this.get_categorical_columns(e,!0),e=this.data_parser.handle_missing_values(e)}toggle_loading_progress(e=!1){let t=document.getElementById("progress");t.style.display=e?"none":"block"}init_tooltips(e){e("#kde_help",{interactive:!0,popperOptions:{positionFixed:!0},content:"Default bandwidth method :Silvermans rule of thumb"}),e("#normalization_help",{interactive:!0,popperOptions:{positionFixed:!0},content:"<p>not functional yet</p><p>standard scaler uses z = (x - u) / s</p><p>Transform features by scaling each feature to a given range</p>",allowHTML:!0}),e("#imputation_help",{interactive:!0,popperOptions:{positionFixed:!0},content:"currently we are just deleting rows with missing values",allowHTML:!0}),e("#cv_help",{interactive:!0,popperOptions:{positionFixed:!0},content:"option 1 and 2 are working",allowHTML:!0})}predictions_table_regression(e,t,s,a){let i=[];e.addColumn("residuals: ",t.map(((e,t)=>e-s[t])),{inplace:!0}),e.addColumn("predictions: ",s,{inplace:!0}),e.addColumn("y",t,{inplace:!0}),e.columns.forEach((e=>{i.push({title:e})}));let n=e.columns.slice().reverse();new DataTable("#predictions_table_"+a,{pageLength:5,responsive:!1,paging:!0,columnDefs:[{render:function(e){return e.toFixed(2)},targets:"_all"}],bPaginate:!0,columns:i.reverse(),data:e.loc({columns:n}).values,bDestroy:!0})}removeTable(e){$(e).DataTable().destroy()}predictions_table(e,t,s,a=null,i=0){let n=[];null!==a&&e.addColumn("probs",a,{inplace:!0}),e.addColumn("y",t,{inplace:!0}),e.addColumn("predictions",s,{inplace:!0}),e.columns.forEach((e=>{n.push({title:e})}));let r=e.columns.slice().reverse();new DataTable("#predictions_table_"+i,{pageLength:10,responsive:!1,paging:!0,bPaginate:!0,columns:n.reverse(),data:e.loc({columns:r}).values,bDestroy:!0,columnDefs:[{},{render:function(e){return e.toFixed(2)},targets:[...Array(n.length).keys()].filter((e=>e>=2))}],rowCallback:function(e,t){var s=t[0],a=t[1];s!==a&&$(e).addClass("is-danger")}})}}class ae{constructor(){this.chartController=new te,this.ui=new se(null,null),this.task=null,this.predictions=[],this.hasProbability=!1,this.plots=[],this.tables=[],this.seed=1,this.hasExplaination=!0,this.id=null,this.helpSectionId="help"}async train(e,t,s,a){throw new Error("Not implemented",e,t,s,a)}async evaluateModel(e,t,s){return await L(e,t,s)}generatePythonCode(e,t){return`\nfrom sklearn.datasets import load_iris\n${e}\nfrom sklearn.inspection import partial_dependence, PartialDependenceDisplay, permutation_importance\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n# Load the Iris dataset\niris = load_iris()\nX, y = iris.data, iris.target\nfeature_names = iris.feature_names\nclass_names = iris.target_names\n\n# Split the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Fit the model\n${t}\nmodel.fit(X_train,y_train)\n# Confusion Matrix\ny_pred = model.predict(X_test)\nconf_matrix = confusion_matrix(y_test, y_pred, labels=np.unique(y))\ndisp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=class_names)\ndisp.plot(cmap=plt.cm.Blues, values_format="d")\nplt.title("Confusion Matrix")\nplt.show()\n\n# PCA of Results\npca = PCA(n_components=2)\nX_test_pca = pca.fit_transform(X_test)\n\n# Plot PCA results with true labels and predicted labels\nplt.figure(figsize=(12, 6))\n\n# Subplot 1: PCA with True Labels\nplt.subplot(1, 2, 1)\nscatter = plt.scatter(X_test_pca[:, 0], X_test_pca[:, 1], c=y_test, cmap='viridis', s=50)\nplt.colorbar(scatter, ticks=np.arange(len(class_names)), label="True Labels")\nplt.title("PCA of Test Set (True Labels)")\nplt.xlabel("Principal Component 1")\nplt.ylabel("Principal Component 2")\n\n\nplt.tight_layout()\nplt.show()\n# Compute and plot Partial Dependence Plot (PDP)\nfig, ax = plt.subplots(figsize=(12, 8))\nPartialDependenceDisplay.from_estimator(\n    model, X_train, [0, 1,2,3], feature_names=feature_names, ax=ax,target=0\n)\nplt.show()\n\n# Compute and plot Permutation Feature Importance (PFI)\npfi = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42)\n# Convert PFI results to a DataFrame for easier manipulation\npfi_df = pd.DataFrame({\n    "Feature": np.repeat(feature_names, repeats=pfi.importances.shape[1]),\n    "Importance": pfi.importances.ravel()\n})\n\n# Create boxplots for Permutation Feature Importance\nplt.figure(figsize=(10, 6))\npfi_df.boxplot(by="Feature", column="Importance", grid=False, vert=False, showmeans=False)\nplt.xlabel("Permutation Importance")\nplt.ylabel("Feature")\nplt.title("Permutation Feature Importance (PFI)")\nplt.suptitle("")  # Remove automatic suptitle from boxplot\nplt.show()\n        `.trim()}async visualize(e,t,s,a,i){const n=Object.keys(i.$labels);await this.chartController.plotConfusionMatrix(g.tensorflow.tensor(a),g.tensorflow.tensor(t),n,Object.values(i.$labels),this.id),this.ui.predictions_table(e,i.inverseTransform(t),i.inverseTransform(a),null,this.id),this.tables.push("#predictions_table_"+this.id)}}class ie extends ae{constructor(e){super(),this.options=e,this.model=null,this.summary=null,this.model_stats_matrix=null}async train(e,t,s,a,i,n){this.context={X_train:e,y_train:t,y_test:a,X_test:s,seed:this.seed,regularization_type:"Lasso"===this.options.regularization.value?1:0,labels:i};const r=window.webr;await r.init(),await r.installPackages(["jsonlite","ggplot2","plotly","nnet","purrr","dplyr","ggrepel","glmnet","modelsummary","broom"],{quiet:!0}),await r.objs.globalEnv.bind("xx",e),await r.objs.globalEnv.bind("random_seed",this.seed),await r.objs.globalEnv.bind("x_test",s),await r.objs.globalEnv.bind("y",t),await r.objs.globalEnv.bind("names",i),await r.objs.globalEnv.bind("categorical_columns",0===n?.length?["empty"]:n),await r.objs.globalEnv.bind("is_lasso",this.context.regularization_type);const o=await r.evalR('\n                    library(plotly)\n                    library(ggplot2)\n                    library(purrr)\n                    library(dplyr)\n                    library(ggrepel)\n                    library(modelsummary)\n                    library(jsonlite)\n                    library(glmnet)\n                    library(broom)\n                    set.seed(random_seed)\n                    # Select all columns except the first as predictors. \n                    x <- as.matrix(xx)  \n                    colnames(x) <- names\n                    scale_df <- as.data.frame(x)\n                    cols_to_scale <- setdiff(names, categorical_columns)\n                    scale_df[cols_to_scale] <- scale(scale_df[cols_to_scale])\n                    if(is_lasso){\n                        cvfit = cv.glmnet(as.matrix(scale_df), y, alpha = 1, family = "multinomial", type.measure = "class")\n                    }else{\n                       cvfit = cv.glmnet(as.matrix(scale_df), y, alpha = 0, family = "multinomial", type.measure = "class")\n                    }\n                    betas = as.matrix(cvfit$glmnet.fit$beta)\n                    lambdas = cvfit$lambda\n                    names(lambdas) = colnames(betas)\n                    \n                    df  <- data.frame(\n                        log_lambda = log(cvfit$lambda),       \n                        mean_cv_error = cvfit$cvm,                \n                        lower_error = cvfit$cvup,    \n                        upper_error = cvfit$cvlo    \n                        )\n                    lambda_min <- log(cvfit$lambda.min) \n                    lambda_1se <- log(cvfit$lambda.1se)  \n            \n                    p <-ggplot(df,aes(x=log_lambda,y=mean_cv_error)) + \n                    geom_point(col="#f05454") + \n                    geom_errorbar(aes(ymin = lower_error,ymax=upper_error),col="#30475e") + \n                    geom_vline(xintercept=c(lambda_1se,lambda_min),\n                                linetype="dashed")+\n                    annotate("text", x = lambda_min, y = max(df$mean_cv_error), \n                            label = "Min", color = "black", hjust = -0.1) +\n                    annotate("text", x = lambda_1se, y = max(df$mean_cv_error) - 0.02, \n                            label = "1-SE", color = "black", hjust = -0.1) +\n                    xlab("log lambda") +\n                    ylab("Error")+\n                    theme_bw()\n\n\n                    colnames(x_test) <- names\n                    model <- nnet::multinom(y ~ . , data = as.data.frame(x))\n                    s <- summary(model)\n                    coefs <- s$coefficients\n                    stds <- s$standard.errors\n                    z_scores <- coefs / stds\n                    p_values <- 2 * (1 - pnorm(abs(z_scores)))\n                    preds <- predict(model,newdata=as.data.frame(x_test))\n                    preds_probs <- predict(model,type = \'probs\',newdata=as.data.frame(x_test))\n                    # confidence interval\n                    z <- 1.96  \n                    conf_int <- list()\n\n                    for (class in rownames(coef(model))) {\n                    conf_int[[class]] <- cbind(\n                        class = class,\n                        Estimate = coefs[class, ],\n                        Lower = coefs[class, ] - z * stds[class, ],\n                        Upper = coefs[class, ] + z * stds[class, ]\n                    )\n                    }\n                    conf_int_df <- do.call(rbind, conf_int)\n                    best_model <- glmnet(x, y, alpha =is_lasso,family = "multinomial", type.measure = "class", lambda = cvfit$lambda.min)\n                    coefficients <- coef(best_model)\n\n                    non_zero_features <- list()\n                    for (class_name in names(coefficients)) {\n                    class_coefficients <- coefficients[[class_name]]\n                    dense_coefficients <- as.matrix(class_coefficients)\n                    non_zero_indices <- which(dense_coefficients != 0, arr.ind = TRUE)\n                    non_zero_features <- c(non_zero_features,rownames(dense_coefficients)[non_zero_indices[, 1]])\n                    }\n                    non_zero_features <- unique(non_zero_features)\n                    non_zero_features <- unlist(Filter(function(x) x != "", non_zero_features))\n                    x_filterd <- x[,unlist(non_zero_features)]\n                    x_test_filterd <- x_test[,unlist(non_zero_features)]\n\n\n                    model_lambda_min <- nnet::multinom(y ~ . , data = as.data.frame(x_filterd))\n                    s <- summary(model_lambda_min)\n                    coefs_lambda_min <- s$coefficients\n                    stds_lambda_min <- s$standard.errors\n                    z_scores_lambda_min <- coefs_lambda_min / stds_lambda_min\n                    p_values_lambda_min <- 2 * (1 - pnorm(abs(z_scores_lambda_min)))\n                    preds_lambda_min <- predict(model_lambda_min,newdata=as.data.frame(x_test_filterd))\n                    preds_probs_lambda_min <- predict(model_lambda_min,type = \'probs\',newdata=as.data.frame(x_test_filterd))\n                    # confidence interval\n                    z <- 1.96  \n                    conf_int <- list()\n\n                    for (class in rownames(coef(model_lambda_min))) {\n                    conf_int[[class]] <- cbind(\n                        class = class,\n                        Estimate = coefs_lambda_min[class, ],\n                        Lower = coefs_lambda_min[class, ] - z * stds_lambda_min[class, ],\n                        Upper = coefs_lambda_min[class, ] + z * stds_lambda_min[class, ]\n                    )\n                    }\n\n\n                    \n                    conf_int_lambda_min_df <- do.call(rbind, conf_int)\n\n                    best_model <- glmnet(x, y, alpha =is_lasso,family = "multinomial", type.measure = "class", lambda = cvfit$lambda.1se)\n                    coefficients <- coef(best_model)\n                    print("got here")\n                    non_zero_features <- list()\n                    for (class_name in names(coefficients)) {\n                    class_coefficients <- coefficients[[class_name]]\n                    dense_coefficients <- as.matrix(class_coefficients)\n                    non_zero_indices <- which(dense_coefficients != 0, arr.ind = TRUE)\n                    non_zero_features <- c(non_zero_features,rownames(dense_coefficients)[non_zero_indices[, 1]])\n                    }\n                    non_zero_features <- unique(non_zero_features)\n                    non_zero_features <- unlist(Filter(function(x) x != "", non_zero_features))\n\n                    x_filterd <- x[,unlist(non_zero_features)]\n                    x_test_filterd <- x_test[,unlist(non_zero_features)]\n                    model_lambda_1se <- nnet::multinom(y ~ . , data = as.data.frame(x_filterd))\n                    s <- summary(model_lambda_1se)\n                    coefs_lambda_1se <- s$coefficients\n                    stds_lambda_1se <- s$standard.errors\n                    z_scores_lambda_1se <- coefs_lambda_1se / stds_lambda_1se\n                    p_values_lambda_1se <- 2 * (1 - pnorm(abs(z_scores_lambda_1se)))\n                    preds_lambda_1se <- predict(model_lambda_1se,newdata=as.data.frame(x_test_filterd))\n                    preds_probs_lambda_1se <- predict(model_lambda_1se,type = \'probs\',newdata=as.data.frame(x_test_filterd))\n                    # confidence interval\n                    z <- 1.96  \n                    conf_int <- list()\n\n                    for (class in rownames(coef(model_lambda_1se))) {\n                    conf_int[[class]] <- cbind(\n                        class = class,\n                        Estimate = coefs_lambda_1se[class, ],\n                        Lower = coefs_lambda_1se[class, ] - z * stds_lambda_1se[class, ],\n                        Upper = coefs_lambda_1se[class, ] + z * stds_lambda_1se[class, ]\n                    )\n                    }\n                    conf_int_lambda_1se_df <- do.call(rbind, conf_int)\n\n                    lambda_values <- cvfit$glmnet.fit$lambda\n\n                    coef_list <- coef(cvfit$glmnet.fit)\n\n                    cv_summary <- map_df(names(coef_list), function(class) {\n                    coef_matrix <- as.matrix(coef_list[[class]])[-1, ]  # Remove intercept\n                    data.frame(\n                        lambda = rep(lambda_values, each = nrow(coef_matrix)),\n                        predictor = rep(rownames(coef_matrix), length(lambda_values)),\n                        coefficient = as.vector(coef_matrix),\n                        class = class\n                    )\n                    })\n\n                    list(\n                    plotly_json(p, pretty = FALSE)\n                    ,rownames(coefs)\n                    ,toJSON(coefs,pretty = TRUE)\n                    ,toJSON(stds,pretty = TRUE)\n                    ,toJSON(z_scores,pretty = TRUE)\n                    ,toJSON(p_values,pretty = TRUE)\n                    ,preds_probs\n                    ,preds \n                    ,toJSON(conf_int_df)\n                    ,rownames(conf_int_df)\n\n                    ,rownames(conf_int_lambda_min_df)\n                    ,toJSON(coefs_lambda_min,pretty = TRUE)\n                    ,toJSON(stds_lambda_min,pretty = TRUE)\n                    ,toJSON(p_values_lambda_min,pretty = TRUE)\n\n                    ,rownames(conf_int_lambda_1se_df)\n                    ,toJSON(coefs_lambda_1se,pretty = TRUE)\n                    ,toJSON(stds_lambda_1se,pretty = TRUE)\n                    ,toJSON(p_values_lambda_1se,pretty = TRUE)\n                    ,model[["AIC"]]\n                    ,model_lambda_min[["AIC"]]\n                    ,model_lambda_1se[["AIC"]]\n                    ,toJSON(cv_summary)\n                    ,toJSON(conf_int_lambda_min_df)\n                    ,toJSON(conf_int_lambda_1se_df)\n                    ,lambda_min\n                    ,lambda_1se\n                    )\n\n                    ');let l=await o.toArray();this.summary={regularization_plot:JSON.parse(await l[0].toString()),classes:await l[1].toArray(),coefs:JSON.parse(await l[2].toArray()),stds:JSON.parse(await l[3].toArray()),z_scores:JSON.parse(await l[4].toArray()),p_values:JSON.parse(await l[5].toArray()),probabities:await l[6].toArray(),predictions:(await l[7].toArray()).map((e=>e-1)),confidence_intervals:JSON.parse(await l[8].toString()),confidence_intervals_row_names:await l[9].toArray(),aic:await l[18].toNumber(),best_fit_min:{names:await l[10].toArray(),confidence_intervals:JSON.parse(await l[22].toString()),coefs:JSON.parse(await l[11].toArray()),stds:JSON.parse(await l[12].toArray()),p_values:JSON.parse(await l[13].toArray()),aic:await l[19].toNumber()},best_fit_1se:{names:await l[14].toArray(),confidence_intervals:JSON.parse(await l[23].toString()),coefs:JSON.parse(await l[15].toArray()),stds:JSON.parse(await l[16].toArray()),p_values:JSON.parse(await l[17].toArray()),aic:await l[20].toNumber()},fit:JSON.parse(await l[21].toArray()),lambda_min:await l[24].toNumber(),lambda_1se:await l[25].toNumber()},this.model_stats_matrix=[];let c=[...i];c.unshift("(Intercept)");let d=[...new Set(this.summary["best_fit_min"].names)].map((e=>e.replace(/^`|`$/g,""))),m=[...new Set(this.summary["best_fit_1se"].names)].map((e=>e.replace(/^`|`$/g,"")));this.summary.regularization_plot.layout["showlegend"]=!1,this.summary.regularization_plot.layout["autosize"]=!0,this.summary.regularization_plot.layout.legend={font:{size:8,color:"#000"}};for(let p=0;p<this.summary.classes.length;p++){for(let e=0;e<c.length;e++){let t=[];t.push(c[e]),t.push(isNaN(this.summary["coefs"][p][e])?" ":this.summary["coefs"][p][e].toFixed(2)),t.push(isNaN(this.summary["stds"][p][e])?" ":this.summary["stds"][p][e].toFixed(2)),t.push(isNaN(this.summary["p_values"][p][e])?" ":this.summary["p_values"][p][e].toFixed(2));let s=d.findIndex((t=>t===c[e]));if(-1!==s){let e=this.summary["best_fit_min"]["coefs"][p][s],a=this.summary["best_fit_min"]["stds"][p][s],i=this.summary["best_fit_min"]["p_values"][p][s];t.push(isNaN(e)?0:e.toFixed(2)),t.push(isNaN(a)?0:a.toFixed(2)),t.push(isNaN(i)?0:i.toFixed(2))}else t.push(" "),t.push(" "),t.push(" ");if(s=m.findIndex((t=>t===c[e])),-1!==s){let e=this.summary["best_fit_1se"]["coefs"][p][s],a=this.summary["best_fit_1se"]["stds"][p][s],i=this.summary["best_fit_1se"]["p_values"][p][s];t.push(isNaN(e)?0:e.toFixed(2)),t.push(isNaN(a)?0:a.toFixed(2)),t.push(isNaN(i)?0:i.toFixed(2))}else t.push(" "),t.push(" "),t.push(" ");this.model_stats_matrix.push(t)}if(p<this.summary.classes.length-1){let e=this.model_stats_matrix[0].map((e=>""));this.model_stats_matrix.push(e)}}return this.summary["predictions"]}async visualize(e,t,s,a,i,n,r){await super.visualize(e,t,s,a,i),setTimeout((async()=>{let e=this;new DataTable("#metrics_table_"+e.id,{responsive:!1,footerCallback:function(t,s,a,i,n){var r=this.api();$(r.column(2).footer()).html("AIC : "+e.summary.aic.toFixed(2)),$(r.column(5).footer()).html("AIC : "+e.summary["best_fit_min"].aic.toFixed(2)),$(r.column(8).footer()).html("AIC : "+e.summary["best_fit_1se"].aic.toFixed(2))},data:e.model_stats_matrix,info:!1,search:!1,ordering:!1,searching:!1,paging:!1,bDestroy:!0}),await M().newPlot("regularization_"+e.id,e.summary.regularization_plot,{autosize:!0});let t=this.summary.confidence_intervals_row_names.map(((e,t)=>e+"_"+this.summary.confidence_intervals[t][0])).reverse(),s=this.summary.confidence_intervals.reverse(),a=[],i=t.map(((e,t)=>t));a.push({name:"OLS",x:s.map((e=>e[1])),y:i,error_x:{type:"data",array:s.map((e=>Math.abs(e[3]-e[1])))},type:"scatter",mode:"markers",showlegend:!0});let n=this.summary.best_fit_min.names.map(((e,t)=>e+"_"+this.summary.best_fit_min.confidence_intervals[t][0])).reverse(),r=this.summary.best_fit_min.confidence_intervals.reverse(),o=n.map(((e,t)=>t+.2));a.push({name:"lasso min",x:r.map((e=>e[1])),y:o,error_x:{type:"data",array:r.map((e=>Math.abs(e[3]-e[1])))},type:"scatter",mode:"markers",showlegend:!0});let l=n.map(((e,t)=>t+.4)),c=this.summary.best_fit_1se.names.map(((e,t)=>e+"_"+this.summary.best_fit_1se.confidence_intervals[t][0])).reverse(),d=this.summary.best_fit_1se.confidence_intervals.reverse();a.push({name:"lasso 1se",x:d.map((e=>e[1])),y:l,error_x:{type:"data",array:d.map((e=>Math.abs(e[3]-e[1])))},type:"scatter",mode:"markers",showlegend:!0}),await M().newPlot("parameters_plot_"+e.id,{data:a,layout:{margin:{l:80,r:40,b:40,t:40,pad:10},showlegend:!0,legend:{xanchor:"left",yanchor:"top",x:.02,y:.98,font:{size:8,color:"black"},bgcolor:"rgba(0,0,0,0)"},xaxis:{linecolor:"black",linewidth:1,zeroline:!0,mirror:!0,title:"Confidence interval"},yaxis:{linecolor:"black",linewidth:1,zeroline:!1,mirror:!0,tickvals:o,ticktext:c,tickfont:{size:10}}}}),this.summary.fit.sort(((e,t)=>e.lambda-t.lambda));let m=this.summary.fit.filter((e=>"1"==e.class)),p=new Set(...[m.filter((e=>!!e.predictor)).map((e=>e.predictor))]),u=[],h=[];p.forEach((e=>{let t=m.filter((t=>t.predictor==e)).map((e=>e.coefficient)),s=m.filter((t=>t.predictor==e)).map((e=>Math.log(e.lambda)));u.push({name:e,y:t,x:s,mode:"lines"}),h.push({xref:"paper",x:.01,y:t[0],xanchor:"left",yanchor:"middle",text:e,font:{family:"Arial",size:8,color:"black"},showarrow:!1}),h=h.concat([{x:this.summary.lambda_min,y:.5,xref:"x",yref:"paper",text:"Lambda min",showarrow:!1,font:{size:8,color:"black"},textangle:-90,align:"center"},{x:this.summary.lambda_1se,y:.5,xref:"x",yref:"paper",text:"Lambda 1se",showarrow:!1,font:{size:8,color:"black"},textangle:-90,align:"center"}])})),await M().newPlot("errors_"+e.id,{data:u,layout:{shapes:[{type:"line",x0:this.summary.lambda_min,x1:this.summary.lambda_min,y0:0,y1:1,xref:"x",yref:"paper",line:{color:"black",dash:"dashdot",width:1}},{type:"line",x0:this.summary.lambda_1se,x1:this.summary.lambda_1se,y0:0,y1:1,xref:"x",yref:"paper",line:{color:"black",dash:"dashdot",width:1}}],annotations:h,showlegend:!1,margin:{l:40,r:40,b:40,t:40,pad:10},autosize:!0,xaxis:{linecolor:"black",linewidth:1,zeroline:!1,mirror:!0,title:"log lambda"},yaxis:{linecolor:"black",linewidth:1,zeroline:!1,mirror:!0,title:"coefficient"}}}),window.dispatchEvent(new Event("resize"))}),500)}}class ne{constructor(){this.chartController=new te,this.ui=new se(null,null),this.task=null,this.predictions=[],this.id=null,this.plots=[],this.tables=[],this.helpSectionId="help",this.hasExplaination=!0,this.seed=123}async train(e,t,s,a){throw new Error("Not implemented",e,t,s,a)}async evaluateModel(e,t){return{mse:j(e,t),rsquared:X(e,t)}}async visualize(e,t,s,a){let i=this;return new Promise((s=>{setTimeout((()=>{let n=t,r=[];a.forEach(((e,t)=>{r.push(n[t]-e)})),i.chartController.yhat_plot(n,a,"regression_y_yhat_"+i.id,"Predictions vs y"),i.chartController.residual_plot(a,r,"errors_"+i.id,"Residuals vs y"),this.ui.predictions_table_regression(e,t,a,this.id),this.plots.push("regression_y_yhat_"+i.id),this.plots.push("errors_"+i.id),this.tables.push("#predictions_table_"+this.id),s("resolved")}),500)}))}}class re extends ne{constructor(e){super(),this.options=e,this.model=null,this.summary=null,this.model_stats_matrix=null,this.hasExplaination=!1}async train(e,t,s,a,i,n){this.context={X_train:e,y_train:t,y_test:a,X_test:s,regularization_type:"Lasso"===this.options.regularization.value?1:0,labels:i};const r=window.webr;await r.init(),await r.installPackages(["jsonlite","iml","ggplot2","plotly","tidyr","dplyr","ggrepel","glmnet","modelsummary"],{quiet:!0}),await r.objs.globalEnv.bind("xx",e),await r.objs.globalEnv.bind("x_test",s),await r.objs.globalEnv.bind("random_seed",this.seed),await r.objs.globalEnv.bind("y",t),await r.objs.globalEnv.bind("names",i),await r.objs.globalEnv.bind("categorical_columns",0===n?.length?["empty"]:n),await r.objs.globalEnv.bind("is_lasso",this.context.regularization_type);const o=await r.evalR('\n                    library(plotly)\n                    library(ggplot2)\n                    library(tidyr)\n                    library(iml)\n                    library(dplyr)\n                    library(ggrepel)\n                    library(modelsummary)\n                    library(glmnet)\n                    set.seed(random_seed)\n\n                    # Select all columns except the first as predictors. \n                    x <- as.matrix(xx)  \n                    colnames(x) <- names\n                    scale_df <- as.data.frame(x)\n\n                    cols_to_scale <- setdiff(names, categorical_columns)\n                    scale_df[cols_to_scale] <- scale(scale_df[cols_to_scale])\n                    scaled_y <- scale(y)\n                    base_model = cv.glmnet(as.matrix(scale_df), scaled_y)\n                    weights <- 1 / abs(coef(base_model)[-1])\n                    if(is_lasso){\n                        cvfit = cv.glmnet(as.matrix(scale_df), scaled_y, alpha = 1,penalty.factor = weights)\n                    }else{\n                       cvfit = cv.glmnet(as.matrix(scale_df), scaled_y, alpha = 0)\n                    }\n                    betas = as.matrix(cvfit$glmnet.fit$beta)\n                    lambdas = cvfit$lambda\n                    names(lambdas) = colnames(betas)\n                    \n                    \n                    p <- as.data.frame(betas) %>% \n                      tibble::rownames_to_column("variable") %>% \n                      pivot_longer(-variable) %>% \n                      mutate(lambda=lambdas[name]) %>% \n                    ggplot(aes(x=lambda,y=value,col=variable)) + \n                      geom_line() + \n                      geom_label_repel(data=~subset(.x,lambda==min(lambda)),\n                                       aes(label=variable),nudge_x=-0.5) +\n                      geom_vline(xintercept=c(cvfit$lambda.1se,cvfit$lambda.min),\n                                linetype="dashed")+\n                      scale_x_log10()+ labs(y = "Coefficients") + theme_bw()\n                    df = with(cvfit,\n                            data.frame(lambda = lambdas,MSE = cvm,MSEhi=cvup,MSElow=cvlo))\n\n                    p2<-ggplot(df,aes(x=lambda,y=MSE)) + \n                    geom_point(col="#f05454") + \n                    scale_x_log10("lambda") + \n                    geom_errorbar(aes(ymin = MSElow,ymax=MSEhi),col="#30475e") + \n                    geom_vline(xintercept=c(cvfit$lambda.1se,cvfit$lambda.min),\n                                linetype="dashed")+\n                    theme_bw()\n\n                    # Get lambda.min and lambda.1se\n                    lambda_min = cvfit$lambda.min\n                    lambda_1se = cvfit$lambda.1se\n\n                    # Get the coefficients at lambda.min and lambda.1se\n                    coef_lambda_min = coef(cvfit, s = "lambda.min")\n                    coef_lambda_1se = coef(cvfit, s = "lambda.1se")\n\n                    # Convert the sparse matrix to a regular matrix to make indexing easier\n                    coef_lambda_min_matrix = as.matrix(coef_lambda_min)\n                    coef_lambda_1se_matrix = as.matrix(coef_lambda_1se)\n                    coef_lambda_min_matrix = coef_lambda_min_matrix[-1, , drop = FALSE]\n                    coef_lambda_1se_matrix = coef_lambda_1se_matrix[-1, , drop = FALSE]\n                    # Find the non-zero features at lambda.min and lambda.1se\n                    non_zero_features_min = rownames(coef_lambda_min_matrix)[coef_lambda_min_matrix != 0]\n                    non_zero_features_1se = rownames(coef_lambda_1se_matrix)[coef_lambda_1se_matrix != 0]\n\n                    print(non_zero_features_min)\n                    print(non_zero_features_1se)\n\n                    model <- lm(y ~ ., data = as.data.frame(x))\n                    x <- as.matrix(x_test)  \n                    colnames(x) <- names\n                    predictions <- predict(model, newdata = as.data.frame(x))\n                    # Get coefficients, p-values, and standard errors\n                    coefs <- coef(model)\n                    pvals <- summary(model)$coefficients[,4]\n                    std_error <- summary(model)$coefficients[,2]\n                    aic_value <- AIC(model)\n                    bic_value <- BIC(model)\n                    rsquared <- summary(model)$r.squared\n                    residuals_ols <- resid(model)\n                    fitted_values_ols <- fitted(model)\n\n                    x <- as.matrix(xx)  \n                    colnames(x) <- names\n                    X_reduced <- x[, non_zero_features_min]\n                    linear_model_min_features <- non_zero_features_min\n\n                    # Fit a linear regression model using the non-zero features\n                    linear_model_min <- lm(y ~ ., data = as.data.frame(X_reduced))\n                    coefs_min <- coef(linear_model_min)\n                    pvals_min <- summary(linear_model_min)$coefficients[,4]\n                    std_error_min <- summary(linear_model_min)$coefficients[,2]\n                    aic_min <- AIC(linear_model_min)\n                    rsquared_min <- summary(linear_model_min)$r.squared\n                    best_lambda <- cvfit$lambda.1se\n                    best_model <- glmnet(x, y, alpha =is_lasso, lambda = best_lambda)\n                    coefficients <- as.matrix(coef(best_model))\n                    residuals_min <- resid(linear_model_min)\n                    fitted_values_min <- fitted(linear_model_min)\n\n\n                    x <- as.matrix(x_test)  \n                    colnames(x) <- names\n                    x <- x[, non_zero_features_min]\n                    predictions_min <- predict(linear_model_min, newdata = as.data.frame(x))\n\n\n\n                    x <- as.matrix(xx)  \n                    colnames(x) <- names\n\n                    X_reduced <- x[, non_zero_features_1se]\n                    linear_model_1se_features <- non_zero_features_1se\n                    linear_model_1se <- lm(y ~ ., data = as.data.frame(X_reduced))\n                    coefs_1se <- coef(linear_model_1se)\n                    print(coefs_1se)\n                    pvals_1se <- summary(linear_model_1se)$coefficients[,4]\n                    aic_1se<- AIC(linear_model_1se)\n                    rsquared_1se <- summary(linear_model_1se)$r.squared\n                    std_error_1se <- summary(linear_model_1se)$coefficients[,2]\n                    residuals_1se <- resid(linear_model_1se)\n                    fitted_values_1se <- fitted(linear_model_1se)\n                    \n                    x <- as.matrix(x_test)  \n                    colnames(x) <- names\n                    x <- x[, non_zero_features_1se]\n                    predictions_1se <- predict(linear_model_1se, newdata = as.data.frame(x))\n\n\n                    models <- list(\n                        "OLS" = model,\n                        "Lasso Min " = linear_model_min,\n                        "Lasso 1se " = linear_model_1se\n                        )\n                    z <- modelplot(models =models,coef_omit = \'Interc\')\n                    qqplot_ols <-ggplot(data.frame(residuals = residuals_ols), aes(sample = residuals_ols)) +\n                        stat_qq(color = "blue") +\n                        stat_qq_line(col = "red") +\n                        labs(title = "QQ Plot of Residuals",\n                            x = "Theoretical Quantiles",\n                            y = "Sample Quantiles") +\n                        theme_bw()\n                    qqplot_1se <-ggplot(data.frame(residuals = residuals_1se), aes(sample = residuals_1se)) +\n                        stat_qq(color = "blue") +\n                        stat_qq_line(col = "red") +\n                        labs(title = "QQ Plot of Residuals",\n                            x = "Theoretical Quantiles",\n                            y = "Sample Quantiles") +\n                        theme_bw()\n                    qqplot_min <-ggplot(data.frame(residuals = residuals_min), aes(sample = residuals_min)) +\n                        stat_qq(color = "blue") +\n                        stat_qq_line(col = "red") +\n                        labs(title = "QQ Plot of Residuals",\n                            x = "Theoretical Quantiles",\n                            y = "Sample Quantiles") +\n                        theme_bw()\n                        \n\n\n\n                    list(plotly_json(p, pretty = FALSE),plotly_json(p2, pretty = FALSE),coefs,\n                    pvals,std_error,predictions,aic_value,bic_value,rsquared\n                    ,coefs_min,pvals_min,std_error_min\n                    ,coefs_1se,pvals_1se,std_error_1se,plotly_json(z, pretty = FALSE),linear_model_min_features,linear_model_1se_features\n                    ,residuals_ols,residuals_1se,residuals_min,predictions_1se,predictions_min,rsquared_1se,aic_1se,rsquared_min,aic_min\n                    ,plotly_json(qqplot_ols, pretty = FALSE)\n                    ,plotly_json(qqplot_1se, pretty = FALSE)\n                    ,plotly_json(qqplot_min, pretty = FALSE)\n                    \n                    )\n                    ');let l=await o.toArray();this.summary={params:await l[2].toArray(),bse:await l[4].toArray(),pvalues:await l[3].toArray(),predictions:await l[5].toArray(),predictions1se:await l[21].toArray(),predictionsmin:await l[22].toArray(),residuals_ols:await l[18].toArray(),residuals_1se:await l[19].toArray(),residuals_min:await l[20].toArray(),aic:await l[6].toNumber(),bic:await l[7].toNumber(),r2:await l[8].toNumber(),best_fit_min:{r2:await l[25].toNumber(),aic:await l[26].toNumber(),names:await l[16].toArray(),coefs:await l[9].toArray(),bse:await l[11].toArray(),pvalues:await l[10].toArray()},best_fit_1se:{r2:await l[23].toNumber(),aic:await l[24].toNumber(),names:await l[17].toArray(),coefs:await l[12].toArray(),bse:await l[14].toArray(),pvalues:await l[13].toArray()}},this.model_stats_matrix=[];let c=[...i];c.unshift("intercept");let d=this.summary["best_fit_min"].names;d.unshift("intercept");let m=this.summary["best_fit_1se"].names;m.unshift("intercept");for(let h=0;h<c.length;h++){let e=[];e.push(c[h]),e.push(this.summary["params"][h]?.toFixed(2)??" "),e.push(this.summary["bse"][h]?.toFixed(2)??" "),e.push(this.summary["pvalues"][h]?.toFixed(2)??" ");let t=d.findIndex((e=>e===c[h]));-1!==t?(e.push(this.summary["best_fit_min"]["coefs"][t]?.toFixed(2)??" "),e.push(this.summary["best_fit_min"]["bse"][t]?.toFixed(2)??" "),e.push(this.summary["best_fit_min"]["pvalues"][t]?.toFixed(2)??" ")):(e.push(" "),e.push(" "),e.push(" ")),t=m.findIndex((e=>e===c[h])),-1!==t?(e.push(this.summary["best_fit_1se"]["coefs"][t]?.toFixed(2)??" "),e.push(this.summary["best_fit_1se"]["bse"][t]?.toFixed(2)??" "),e.push(this.summary["best_fit_1se"]["pvalues"][t]?.toFixed(2)??" ")):(e.push(" "),e.push(" "),e.push(" ")),this.model_stats_matrix.push(e)}this.model_stats_matrix.reverse();let p=JSON.parse(await l[0].toString());p.layout["showlegend"]=!1,p.layout.legend={font:{size:8,color:"#000"}};let u=JSON.parse(await l[15].toString());return u.layout.legend={x:0,y:1,traceorder:"normal",font:{size:8,color:"#000"},bgcolor:"rgba(0,0,0,0)"},u.layout.xaxis.title.font={size:10},u.layout.xaxis.linecolor="rgba(235, 235, 235, 1)",u.layout.xaxis.linewidth=3,u.layout.xaxis.mirror=!0,u.layout.xaxis.zeroline=!0,u.layout.yaxis.linecolor="rgba(235, 235, 235, 1)",u.layout.yaxis.linewidth=2,u.layout.yaxis.mirror=!0,u.layout.yaxis.zeroline=!0,this.summary.coefs_plot=u,this.summary.regularization_plot=p,this.summary.errors_plot=JSON.parse(await l[1].toString()),this.summary.qqplot_ols_plot=JSON.parse(await l[27].toString()),this.summary.qqplot_1se_plot=JSON.parse(await l[28].toString()),this.summary.qqplot_min_plot=JSON.parse(await l[29].toString()),this.summary.qqplot_ols_plot.layout.title.font={size:10},this.summary.qqplot_ols_plot.data[0].marker.size=3,this.summary.qqplot_ols_plot.data[0].marker.color="blue",this.summary.qqplot_ols_plot.layout.height=300,this.summary.qqplot_ols_plot.layout.width=300,this.summary.qqplot_ols_plot.layout.xaxis.title.font={size:10},this.summary.qqplot_ols_plot.layout.yaxis.title.font={size:10},this.summary.qqplot_1se_plot.layout.height=300,this.summary.qqplot_1se_plot.layout.width=300,this.summary.qqplot_1se_plot.layout.title.font={size:10},this.summary.qqplot_1se_plot.data[0].marker.size=3,this.summary.qqplot_1se_plot.layout.xaxis.title.font={size:10},this.summary.qqplot_1se_plot.layout.yaxis.title.font={size:10},this.summary.qqplot_min_plot.layout.height=300,this.summary.qqplot_min_plot.layout.width=300,this.summary.qqplot_min_plot.layout.title.font={size:10},this.summary.qqplot_min_plot.layout.xaxis.title.font={size:10},this.summary.qqplot_min_plot.layout.yaxis.title.font={size:10},this.summary.qqplot_min_plot.data[0].marker.size=1,this.summary["predictions"]}async visualize(e,t,s,a,i){await super.visualize(e,t,s,a);let n=this;new DataTable("#metrics_table_"+n.id,{responsive:!1,footerCallback:function(e,t,s,a,i){var r=this.api();$(r.column(2).footer()).html("R2 : "+n.summary.r2.toFixed(2)+" AIC: "+n.summary.aic.toFixed(2)),$(r.column(5).footer()).html("R2 : "+n.summary["best_fit_min"].r2.toFixed(2)+" AIC: "+n.summary["best_fit_min"].aic.toFixed(2)),$(r.column(8).footer()).html("R2 : "+n.summary["best_fit_1se"].r2.toFixed(2)+" AIC: "+n.summary["best_fit_1se"].aic.toFixed(2))},data:n.model_stats_matrix,info:!1,search:!1,ordering:!1,searching:!1,paging:!1,bDestroy:!0,columnDefs:[{targets:3,createdCell:function(e,t,s,a,i){s[3]<=.05&&($(e).css("color","red"),$(e).css("font-weight","700"))}},{targets:6,createdCell:function(e,t,s,a,i){s[6]<=.05&&($(e).css("color","red"),$(e).css("font-weight","700"))}},{targets:9,createdCell:function(e,t,s,a,i){s[9]<=.05&&($(e).css("color","red"),$(e).css("font-weight","700"))}}]}),await M().newPlot("parameters_plot_"+n.id,n.summary.coefs_plot,{autosize:!0,responsive:!0}),await M().newPlot("regularization_"+n.id,n.summary.regularization_plot,{autosize:!0,responsive:!0}),await M().newPlot("errors_"+n.id,n.summary.errors_plot,{autosize:!0,responsive:!0}),await M().newPlot("qqplot_ols_"+n.id,n.summary.qqplot_ols_plot,{autosize:!0,staticPlot:!0}),await M().newPlot("qqplot_min_"+n.id,n.summary.qqplot_min_plot,{autosize:!0,staticPlot:!0}),await M().newPlot("qqplot_1se_"+n.id,n.summary.qqplot_1se_plot,{autosize:!0,staticPlot:!0}),n.chartController.yhat_plot(t,this.summary["predictions"],"regression_y_yhat_"+n.id,"OLS predictions"),n.chartController.yhat_plot(t,this.summary["predictionsmin"],"regression_y_yhat_min_"+n.id,"lasso min predictions"),n.chartController.yhat_plot(t,this.summary["predictions1se"],"regression_y_yhat_1se_"+n.id,"lasso 1se predictions"),n.chartController.residual_plot(t,this.summary["residuals_ols"],"regression_residual_"+n.id,"OLS residuals"),n.chartController.residual_plot(t,this.summary["residuals_min"],"regression_residual_min_"+n.id,"lasso min residuals"),n.chartController.residual_plot(t,this.summary["residuals_1se"],"regression_residual_1se_"+n.id,"lasso 1se residuals"),this.ui.predictions_table_regression(e,t,a,this.id),window.dispatchEvent(new Event("resize"))}}class oe extends ne{constructor(e){super(),this.options=e,this.model=null,this.hasExplaination=!1}async train(e,t,s,a,i){this.context={X_train:e,y_train:t,X_test:s,y_test:a,knots:+this.options.knots.value,explain:this.hasExplaination,degree:+this.options.degree.value,features:[...Array(i.length).keys()]};const n="\n        from sklearn.preprocessing import SplineTransformer\n        from sklearn.inspection import PartialDependenceDisplay\n        from sklearn.inspection import permutation_importance\n        from sklearn.ensemble import GradientBoostingRegressor\n        import pandas as pd\n        import matplotlib\n        matplotlib.use(\"AGG\")\n        from sklearn import linear_model\n        from sklearn.metrics import mean_squared_error\n        from sklearn.pipeline import make_pipeline\n        from js import X_train,y_train,X_test,knots,degree,y_test,features,explain\n\n\n        features_importance = []\n        partial_dependence_plot_grids = []\n        partial_dependence_plot_avgs = []\n        \n        model = make_pipeline(\n            SplineTransformer(n_knots=knots, degree=degree), \n            linear_model.LinearRegression()\n            )\n        model.fit(X_train, y_train)\n        pred_train = model.predict(X_train)\n        rmse_train = mean_squared_error(y_train, pred_train, squared=True)\n        y_pred = model.predict(X_test)\n        if explain:\n            pdp = PartialDependenceDisplay.from_estimator(model, X_train, features,method ='brute')\n            fi = permutation_importance(model,X_test,y_test,n_repeats=10)\n            partial_dependence_plot_avgs = list(map(lambda item:item['average'],pdp.pd_results))\n            grids = list(map(lambda item:item['grid_values'],pdp.pd_results))\n            features_importance = list(fi.importances)\n            partial_dependence_plot_grids = [item[0].tolist() for item in grids ]\n        y_pred,partial_dependence_plot_avgs,partial_dependence_plot_grids, features_importance\n\n        ";try{const{results:e,error:t}=await N(n,this.context);if(e)return this.predictions=Array.from(e[0]),this.pdp_averages=Array.from(e[1]),this.pdp_grid=Array.from(e[2]),this.importances=Array.from(e[3]),Array.from(e[0]);t&&console.log("pyodideWorker error: ",t)}catch(r){throw Error(`Error in pyodideWorker at ${r.filename}, Line: ${r.lineno}, ${r.message}`)}}async visualize(e,t,s,a,i,n,r){await super.visualize(e,t,s,a,i),this.hasExplaination&&(this.chartController.PFIBoxplot(this.id,this.importances,n),this.chartController.plotPDPRegression(this.id,this.pdp_averages,this.pdp_grid,s,n,r))}}class le extends ae{constructor(e){super(),this.options={kernel:e.kernel.value.toLowerCase(),coef:e.bias.value,degree:e.degree.value,c:e.c.value,quiet:!0},this.helpSectionId="svm_help"}async train(e,t,s,a,i,n,r){this.context={X_train:e,y_train:t,X_test:s,y_test:a,pdpIndex:r,explain:this.hasExplaination,kernel:this.options.kernel,coef:this.options.coef,c:+this.options.c,degree:this.options.degree,seed:this.seed,features:[...Array(i.length).keys()]};const o="\n        from sklearn import svm\n        from js import X_train,y_train,X_test,y_test,kernel,coef,degree,features,seed,c,explain\n        import matplotlib\n        matplotlib.use(\"AGG\")\n        from sklearn.inspection import PartialDependenceDisplay\n        from sklearn.inspection import permutation_importance\n        features_importance = []\n        partial_dependence_plot_grids = []\n        partial_dependence_plot_avgs = []\n\n        model = svm.SVC(kernel=kernel,random_state = seed,C=c,degree=degree)\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n\n        if explain:\n            pdp = PartialDependenceDisplay.from_estimator(model, X_train, features,target=0,method ='brute')\n            fi = permutation_importance(model,X_test,y_test,n_repeats=10)\n            partial_dependence_plot_avgs = list(map(lambda item:item['average'],pdp.pd_results))\n            grids = list(map(lambda item:item['grid_values'],pdp.pd_results))\n            features_importance = list(fi.importances)\n            partial_dependence_plot_grids = [item[0].tolist() for item in grids ]\n        y_pred,partial_dependence_plot_avgs,partial_dependence_plot_grids,features_importance\n    ";try{const{results:e,error:t}=await N(o,this.context);if(e)return this.predictions=Array.from(e[0]),this.pdp_averages=Array.from(e[1]),this.pdp_grid=Array.from(e[2]),this.importances=Array.from(e[3]),Array.from(e[0]);t&&console.log("pyodideWorker error: ",t)}catch(l){throw Error(`Error in pyodideWorker at ${l.filename}, Line: ${l.lineno}, ${l.message}`)}}generatePythonCode(){let e="from sklearn import svm",t=`\nmodel = model = svm.SVC(kernel="${this.options.kernel}",random_state = ${this.seed})`;return super.generatePythonCode(e,t)}async visualize(e,t,s,a,i,n,r){await super.visualize(e,t,s,a,i),this.hasExplaination&&(this.chartController.PFIBoxplot(this.id,this.importances,n),this.chartController.plotPDP(this.id,this.pdp_averages,this.pdp_grid,s,n,r))}}class ce extends ne{constructor(e,t){super(t);let s={kernel:e.kernel.value??"linear",gamma:e.gamma.value,degree:e.degree.value};this.options=s,this.helpSectionId="svm_help"}async train(e,t,s,a,i){this.context={X_train:e,y_train:t,X_test:s,y_test:a,kernel:this.options.kernel,gamma:this.options.gamma,degree:this.options.degree,explain:this.hasExplaination,seed:this.seed,features:[...Array(i.length).keys()]};const n="\n        from sklearn import svm\n        import matplotlib\n        matplotlib.use(\"AGG\")\n        from js import X_train,y_train,X_test,y_test,kernel,gamma,degree,seed,features,explain\n        from sklearn.inspection import PartialDependenceDisplay\n        from sklearn.inspection import permutation_importance\n\n        \n        features_importance = []\n        partial_dependence_plot_grids = []\n        partial_dependence_plot_avgs = []\n        model = svm.SVR(kernel=kernel)\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n\n        if explain:\n            pdp = PartialDependenceDisplay.from_estimator(model, X_train, features)\n            fi = permutation_importance(model,X_test,y_test,n_repeats=10)\n            partial_dependence_plot_avgs = list(map(lambda item:item['average'],pdp.pd_results))\n            grids = list(map(lambda item:item['grid_values'],pdp.pd_results))\n            features_importance = list(fi.importances)\n            partial_dependence_plot_grids = [item[0].tolist() for item in grids ]\n        y_pred,partial_dependence_plot_avgs,partial_dependence_plot_grids, features_importance\n    ";try{const{results:e,error:t}=await N(n,this.context);if(e)return this.predictions=Array.from(e[0]),this.pdp_averages=Array.from(e[1]),this.pdp_grid=Array.from(e[2]),this.importances=Array.from(e[3]),Array.from(e[0]);t&&console.log("pyodideWorker error: ",t)}catch(r){throw Error(`Error in pyodideWorker at ${r.filename}, Line: ${r.lineno}, ${r.message}`)}}async visualize(e,t,s,a,i,n,r){await super.visualize(e,t,s,a,i),this.hasExplaination&&(this.chartController.PFIBoxplot(this.id,this.importances,n),this.chartController.plotPDPRegression(this.id,this.pdp_averages,this.pdp_grid,s,n,r))}}class de extends ae{constructor(e){super(),this.options=e,this.model=null,this.helpSectionId="knn_help"}async train(e,t,s,a,i,n,r){this.context={X_train:e,y_train:t,X_test:s,y_test:a,min:+this.options.min.value,max:+this.options.max.value,explain:this.hasExplaination,features:[...Array(i.length).keys()]};const o="\n        import matplotlib\n        matplotlib.use(\"AGG\")\n        from js import X_train,y_train,X_test,y_test,features,min,max,explain\n        from sklearn.inspection import PartialDependenceDisplay\n        from sklearn.inspection import permutation_importance\n        from sklearn.neighbors import KNeighborsClassifier\n        from sklearn.metrics import accuracy_score\n\n        features_importance = []\n        partial_dependence_plot_grids = []\n        partial_dependence_plot_avgs = []\n\n        k_neighbor_results=[]\n        best_model = None\n        best_accuracy = 0\n        best_preds = []\n        for i,metric in enumerate(['manhattan','euclidean']):\n            for n in range(min,max+1):\n                model = KNeighborsClassifier(n_neighbors=n,metric=metric)\n                model.fit(X_train, y_train)\n                preds = model.predict(X_test)\n                accuracy = accuracy_score(y_test,preds)\n                k_neighbor_results.append([metric,n,accuracy])\n                if accuracy > best_accuracy:\n                    best_accuracy = accuracy\n                    best_model = model\n                    best_n = n\n                    best_preds = preds\n        if explain:\n            pdp = PartialDependenceDisplay.from_estimator(best_model, X_train, features,target=0,method ='brute')\n            fi = permutation_importance(best_model,X_test,y_test,n_repeats=10)\n            partial_dependence_plot_avgs = list(map(lambda item:item['average'],pdp.pd_results))\n            grids = list(map(lambda item:item['grid_values'],pdp.pd_results))\n            features_importance = list(fi.importances)\n            partial_dependence_plot_grids = [item[0].tolist() for item in grids ]\n        best_preds,partial_dependence_plot_avgs,partial_dependence_plot_grids, features_importance,k_neighbor_results,best_n\n    ";try{const{results:e,error:t}=await N(o,this.context);if(e)return this.predictions=Array.from(e[0]),this.pdp_averages=Array.from(e[1]),this.pdp_grid=Array.from(e[2]),this.importances=Array.from(e[3]),this.k_neighbor_results=Array.from(e[4]),this.best_n=e[5],Array.from(e[0]);t&&console.log("pyodideWorker error: ",t)}catch(l){throw Error(`Error in pyodideWorker at ${l.filename}, Line: ${l.lineno}, ${l.message}`)}}generatePythonCode(){let e="\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score".trim(),t=`\nbest_model = None\nbest_accuracy = 0\nbest_preds = []\nfor i,metric in enumerate(['manhattan','euclidean']):\n    for n in range(${+this.options.min.value},${+this.options.max.value+1}):\n        model = KNeighborsClassifier(n_neighbors=n,metric=metric)\n        model.fit(X_train, y_train)\n        preds = model.predict(X_test)\n        accuracy = accuracy_score(y_test,preds)\n        if accuracy > best_accuracy:\n            best_accuracy = accuracy\n            best_model = model\n            best_n = n\n            best_preds = preds\nmodel = best_model\n`.trim();return super.generatePythonCode(e,t)}async visualize(e,t,s,a,i,n,r){await super.visualize(e,t,s,a,i),this.chartController.KNNPerformancePlot(this.k_neighbor_results,this.best_n,this.id),this.plots.push("knn_table_"+this.id),this.hasExplaination&&(this.chartController.PFIBoxplot(this.id,this.importances,n),this.chartController.plotPDP(this.id,this.pdp_averages,this.pdp_grid,s,n,r))}}class me extends ne{constructor(e){super(),this.options=e,this.model=null,this.helpSectionId="knn_help"}async train(e,t,s,a,i,n,r){this.context={X_train:e,y_train:t,X_test:s,y_test:a,min:+this.options.min.value,max:+this.options.max.value,explain:this.hasExplaination,features:[...Array(i.length).keys()]};const o="\n        import matplotlib\n        matplotlib.use(\"AGG\")\n        from js import X_train,y_train,X_test,y_test,features,min,max,explain\n        from sklearn.inspection import PartialDependenceDisplay\n        from sklearn.inspection import permutation_importance\n        from sklearn.neighbors import KNeighborsRegressor\n\n        features_importance = []\n        partial_dependence_plot_grids = []\n        partial_dependence_plot_avgs = []\n        k_neighbor_results=[]\n        best_model = None\n        best_r2 = 0\n        best_preds = []\n\n        for i,metric in enumerate(['manhattan','euclidean']):\n            for n in range(min,max+1):\n                model = KNeighborsRegressor(n_neighbors=n,metric=metric)\n                model.fit(X_train, y_train)\n                preds = model.predict(X_test)\n                r2 = model.score(X_test,y_test)\n                k_neighbor_results.append([metric,n,r2])\n                if r2 > best_r2:\n                    best_r2 = r2\n                    best_model = model\n                    best_n = n\n                    best_preds = preds\n\n        if explain:\n            pdp = PartialDependenceDisplay.from_estimator(best_model, X_train, features)\n            fi = permutation_importance(best_model,X_test,y_test,n_repeats=10)\n            partial_dependence_plot_avgs = list(map(lambda item:item['average'],pdp.pd_results))\n            grids = list(map(lambda item:item['grid_values'],pdp.pd_results))\n            features_importance = list(fi.importances)\n            partial_dependence_plot_grids = [item[0].tolist() for item in grids ]\n        best_preds,partial_dependence_plot_avgs,partial_dependence_plot_grids, features_importance,k_neighbor_results,best_n\n    ";try{const{results:e,error:t}=await N(o,this.context);if(e)return this.predictions=Array.from(e[0]),this.pdp_averages=Array.from(e[1]),this.pdp_grid=Array.from(e[2]),this.importances=Array.from(e[3]),this.k_neighbor_results=Array.from(e[4]),this.best_n=e[5],Array.from(e[0]);t&&console.log("pyodideWorker error: ",t)}catch(l){throw Error(`Error in pyodideWorker at ${l.filename}, Line: ${l.lineno}, ${l.message}`)}}async visualize(e,t,s,a,i,n,r){await super.visualize(e,t,s,a,i),this.chartController.KNNPerformancePlot(this.k_neighbor_results,this.best_n,this.id,"MSE"),this.plots.push("knn_table_"+this.id),this.hasExplaination&&(this.chartController.PFIBoxplot(this.id,this.importances,n),this.chartController.plotPDPRegression(this.id,this.pdp_averages,this.pdp_grid,s,n,r))}}class pe extends ae{constructor(e,t){super(t),this.helpSectionId="cart_help",this.options=e,this.model=null,this.predictions=[],this.hasProbability=!0}async train(e,t,s,a,i,n,r){this.context={X_train:e,y_train:t,X_test:s,y_test:a,pdpIndex:r,explain:this.hasExplaination,rf_type:this.options.criteria.value,max_features:this.options.features.value,num_estimators:this.options.estimators.value<=0||!this.options.estimators.value?100:+this.options.estimators.value,max_depth:this.options.depth.value<=0?5:+this.options.depth.value,seed:this.seed,features:[...Array(i.length).keys()],num_classes:[...new Set(t)].length};const o="\n            from sklearn.model_selection import train_test_split\n            from sklearn.ensemble import RandomForestClassifier\n            from sklearn.metrics import accuracy_score\n            import matplotlib\n            matplotlib.use(\"AGG\")\n            from sklearn.inspection import PartialDependenceDisplay\n            from sklearn.inspection import permutation_importance\n            from js import seed,X_train,y_train,X_test,y_test,rf_type,max_features,num_estimators,max_depth, features,explain,num_classes\n            from sklearn.metrics import roc_auc_score\n            from sklearn.metrics import roc_curve\n            from sklearn.preprocessing import LabelBinarizer\n\n\n            features_importance = []\n            partial_dependence_plot_grids = []\n            partial_dependence_plot_avgs = []\n            model = RandomForestClassifier(criterion=rf_type,max_features = max_features,n_estimators=num_estimators,max_depth = max_depth, random_state=seed)\n            model.fit(X_train, y_train)\n            y_pred = model.predict(X_test)\n            \n            probas = model.predict_proba(X_test)\n            tprs=[]\n            fprs=[]\n            aucs=[]\n            label_binrize = LabelBinarizer().fit(y_train)\n            y_test_one_hot = label_binrize.transform(y_test)\n            \n            try:\n                fpr,tpr,_  = roc_curve(y_test,probas[:,1])\n                fprs.append(fpr)\n                tprs.append(tpr)\n                auc = roc_auc_score(y_test,probas[:,1])\n                aucs.append(auc)\n            except Exception as e:\n                auc = roc_auc_score(y_test,probas,multi_class = 'ovr')\n                aucs.append(auc)\n                for i in range(num_classes):\n                    fpr,tpr,_ = roc_curve(y_test_one_hot[:,i],probas[:,i])\n                    fprs.append(fpr)\n                    tprs.append(tpr)\n\n            if explain:\n                pdp = PartialDependenceDisplay.from_estimator(model, X_train, features,target=0,method ='brute')\n                fi = permutation_importance(model,X_test,y_test,n_repeats=10)\n                partial_dependence_plot_avgs = list(map(lambda item:item['average'],pdp.pd_results))\n                grids = list(map(lambda item:item['grid_values'],pdp.pd_results))\n                features_importance = list(fi.importances)\n                partial_dependence_plot_grids = [item[0].tolist() for item in grids ]\n            y_pred,partial_dependence_plot_avgs,partial_dependence_plot_grids,features_importance,fprs,tprs,aucs,probas\n        ";try{const{results:e,error:t}=await N(o,this.context);if(e)this.predictions=Array.from(e[0]),this.pdp_averages=Array.from(e[1]),this.pdp_grid=Array.from(e[2]),this.importances=Array.from(e[3]),this.fpr=Array.from(e[4]),this.tpr=Array.from(e[5]),this.auc=Array.from(e[6]),this.probas=Array.from(e[7]);else if(t)throw Error("Faced errot fitting Random Forest")}catch(l){throw Error(`Error in pyodideWorker at ${l.filename}, Line: ${l.lineno}, ${l.message}`)}return this.predictions}generatePythonCode(){let e="from sklearn.ensemble import RandomForestClassifier",t=`\nmodel = RandomForestClassifier(criterion="${this.options.criteria.value}",max_features = ${this.options.features.value},n_estimators=${this.options.estimators.value},max_depth = ${this.options.depth.value}, random_state=${this.seed})`;return super.generatePythonCode(e,t)}async visualize(e,t,s,a,i,n,r){await super.visualize(e,t,s,a,i),this.hasExplaination&&(this.chartController.PFIBoxplot(this.id,this.importances,n),this.chartController.plotPDP(this.id,this.pdp_averages,this.pdp_grid,s,n,r)),this.chartController.plotROC(this.id,this.fpr,this.tpr,s,this.auc),this.chartController.probabilities_boxplot(this.probas,i.inverseTransform(a),s,this.id)}predict(){return this.predictions}}class ue extends ne{constructor(e){super(),this.options=e,this.model=null,this.helpSectionId="cart_help"}async train(e,t,s,a,i,n,r){this.context={X_train:e,y_train:t,X_test:s,y_test:a,rf_type:this.options.criteria.value,max_features:this.options.features.value,num_estimators:this.options.estimators.value<=0||!this.options.estimators.value?100:+this.options.estimators.value,max_depth:this.options.depth.value<=0?5:+this.options.depth.value,seed:this.seed,explain:this.hasExplaination,features:[...Array(i.length).keys()]};const o="\n            from sklearn.model_selection import train_test_split\n            from sklearn.ensemble import RandomForestRegressor\n            import matplotlib\n            matplotlib.use(\"AGG\")\n            from sklearn.metrics import accuracy_score\n            from js import X_train,y_train,X_test,y_test,rf_type,max_features,num_estimators,max_depth,seed,features,explain\n            from sklearn.inspection import PartialDependenceDisplay\n            from sklearn.inspection import permutation_importance\n\n            features_importance = []\n            partial_dependence_plot_grids = []\n            partial_dependence_plot_avgs = []\n            model = RandomForestRegressor(criterion=rf_type,max_features = max_features,n_estimators=num_estimators,max_depth = max_depth, random_state=seed)\n            model.fit(X_train, y_train)\n            y_pred = model.predict(X_test)\n\n            if explain:\n                pdp = PartialDependenceDisplay.from_estimator(model, X_train, features)\n                fi = permutation_importance(model,X_test,y_test,n_repeats=10)\n                partial_dependence_plot_avgs = list(map(lambda item:item['average'],pdp.pd_results))\n                grids = list(map(lambda item:item['grid_values'],pdp.pd_results))\n                features_importance = list(fi.importances)\n                partial_dependence_plot_grids = [item[0].tolist() for item in grids ]\n            y_pred,partial_dependence_plot_avgs,partial_dependence_plot_grids, features_importance           \n        ";try{const{results:e,error:t}=await N(o,this.context);if(e)return this.predictions=Array.from(e[0]),this.pdp_averages=Array.from(e[1]),this.pdp_grid=Array.from(e[2]),this.importances=Array.from(e[3]),Array.from(e[0]);t&&console.log("pyodideWorker error: ",t)}catch(l){throw Error(`Error in pyodideWorker at ${l.filename}, Line: ${l.lineno}, ${l.message}`)}}predict(e){const t=this.model.predict(e);return t}async visualize(e,t,s,a,i,n,r){await super.visualize(e,t,s,a,i),this.hasExplaination&&(this.chartController.PFIBoxplot(this.id,this.importances,n),this.chartController.plotPDPRegression(this.id,this.pdp_averages,this.pdp_grid,s,n,r))}}class he extends ae{constructor(e){super(),this.options=e,this.model=null,this.helpSectionId="naive_bayes_help",this.hasProbability=!0}async train(e,t,s,a,i,n,r){this.context={nb_type:"Multinomial"===this.options.type.value?0:"Gaussian"===this.options.type.value?1:2,priors:this.options.priors.value,smoothing:+this.options.laplace.value,num_classes:[...new Set(t)].length,X_train:e,y_train:t,y_test:a,explain:this.hasExplaination,X_test:s,pdpIndex:r,features:[...Array(i.length).keys()]};const o="\n            from sklearn.naive_bayes import BernoulliNB\n            from sklearn.naive_bayes import MultinomialNB\n            import matplotlib\n            matplotlib.use(\"AGG\")\n            from js import X_train,y_train,X_test,nb_type,priors,smoothing,y_test,num_classes,features,explain\n            from sklearn.naive_bayes import GaussianNB\n            from sklearn.inspection import PartialDependenceDisplay\n            from sklearn.inspection import permutation_importance\n            from sklearn.metrics import roc_auc_score\n            from sklearn.metrics import roc_curve\n            from sklearn.preprocessing import LabelBinarizer\n\n            features_importance = []\n            partial_dependence_plot_grids = []\n            partial_dependence_plot_avgs = []\n            if priors is not None and priors.strip():\n                priors = [float(x) for x in priors.split(',')]\n            else:\n                priors = None\n            print(\"priors\",priors)\n            if nb_type == 0:\n                model = MultinomialNB(class_prior=priors , alpha = smoothing)\n            if nb_type == 1:\n                model = GaussianNB(priors=priors)\n            else:\n                model = BernoulliNB(class_prior=priors , alpha = smoothing)\n            model.fit(X_train, y_train)\n            y_pred = model.predict(X_test)\n            probas = model.predict_proba(X_test)\n            tprs=[]\n            fprs=[]\n            aucs = []\n\n            label_binrize = LabelBinarizer().fit(y_train)\n            y_test_one_hot = label_binrize.transform(y_test)\n            \n            try:\n                fpr,tpr,_  = roc_curve(y_test,probas[:,1])\n                auc = roc_auc_score(y_test,probas[:,1])\n                aucs.append(auc)\n                fprs.append(fpr)\n                tprs.append(tpr)\n\n            except Exception as e:\n                print(e)\n                auc = roc_auc_score(y_test,probas,multi_class = 'ovr')\n                aucs.append(auc)\n                for i in range(num_classes):\n                    fpr,tpr,_ = roc_curve(y_test_one_hot[:,i],probas[:,i])\n                    fprs.append(fpr)\n                    tprs.append(tpr)\n\n            if explain:\n                pdp = PartialDependenceDisplay.from_estimator(model, X_train, features,target=0,method ='brute')\n                fi = permutation_importance(model,X_test,y_test,n_repeats=10)\n                partial_dependence_plot_avgs = list(map(lambda item:item['average'],pdp.pd_results))\n                grids = list(map(lambda item:item['grid_values'],pdp.pd_results))\n                features_importance = list(fi.importances)\n                partial_dependence_plot_grids = [item[0].tolist() for item in grids ]\n            y_pred,partial_dependence_plot_avgs,partial_dependence_plot_grids, features_importance,fprs,tprs,aucs,probas\n        ";try{const{results:e,error:t}=await N(o,this.context);e?(this.predictions=Array.from(e[0]),this.pdp_averages=Array.from(e[1]),this.pdp_grid=Array.from(e[2]),this.importances=Array.from(e[3]),this.fpr=Array.from(e[4]),this.tpr=Array.from(e[5]),this.auc=Array.from(e[6]),this.probas=Array.from(e[7])):t&&console.log("pyodideWorker error: ",t)}catch(l){throw Error(`Error in pyodideWorker at ${l.filename}, Line: ${l.lineno}, ${l.message}`)}return this.predictions}async visualize(e,t,s,a,i,n,r){await super.visualize(e,t,s,a,i),this.hasExplaination&&(this.chartController.PFIBoxplot(this.id,this.importances,n),this.chartController.plotPDP(this.id,this.pdp_averages,this.pdp_grid,s,n,r)),this.chartController.plotROC(this.id,this.fpr,this.tpr,s,this.auc),this.chartController.probabilities_boxplot(this.probas,i.inverseTransform(a),s,this.id)}}class _e extends ae{constructor(e){super(),this.options=e,this.hasProbability=!0,this.helpSectionId="discriminant_analysis_help"}async train(e,t,s,a,i,n,r){this.context={lda_type:this.options.type.value,priors:this.options.priors.value,X_train:e,y_train:t,X_test:s,y_test:a,pdpIndex:r,explain:this.hasExplaination,features:[...Array(i.length).keys()],num_classes:[...new Set(t)].length};const o="\n        import matplotlib\n        matplotlib.use(\"AGG\")\n        from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n        from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n        from js import X_train,y_train,X_test,lda_type,priors,y_test,features,explain,num_classes\n        from sklearn.inspection import PartialDependenceDisplay\n        from sklearn.inspection import permutation_importance\n        from sklearn.metrics import roc_auc_score\n        from sklearn.metrics import roc_curve\n        from sklearn.preprocessing import LabelBinarizer\n\n\n        features_importance = []\n        partial_dependence_plot_grids = []\n        partial_dependence_plot_avgs = []\n        if priors is not None and priors.strip():\n            priors = [float(x) for x in priors.split(',')]\n        else:\n            priors = None\n        print(\"priors\",priors)\n        if lda_type == 0:\n            model = LinearDiscriminantAnalysis(priors=priors)\n        else:\n            model = QuadraticDiscriminantAnalysis(priors=priors)\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        probas = model.predict_proba(X_test)\n        tprs=[]\n        fprs=[]\n        aucs = []\n        label_binrize = LabelBinarizer().fit(y_train)\n        y_test_one_hot = label_binrize.transform(y_test)\n        \n        try:\n            fpr,tpr,_  = roc_curve(y_test,probas[:,1])\n            auc = roc_auc_score(y_test,probas[:,1])\n            aucs.append(auc)\n            fprs.append(fpr)\n            tprs.append(tpr)\n\n        except Exception as e:\n            auc = roc_auc_score(y_test,probas,multi_class = 'ovr')\n            aucs.append(auc)\n            for i in range(num_classes):\n                fpr,tpr,_ = roc_curve(y_test_one_hot[:,i],probas[:,i])\n                fprs.append(fpr)\n                tprs.append(tpr)\n\n        if explain:\n            pdp = PartialDependenceDisplay.from_estimator(model, X_train, features,target=0,method ='brute')\n            fi = permutation_importance(model,X_test,y_test,n_repeats=10)\n            partial_dependence_plot_avgs = list(map(lambda item:item['average'],pdp.pd_results))\n            grids = list(map(lambda item:item['grid_values'],pdp.pd_results))\n            features_importance = list(fi.importances)\n            partial_dependence_plot_grids = [item[0].tolist() for item in grids ]\n        y_pred,partial_dependence_plot_avgs,partial_dependence_plot_grids, features_importance,fprs,tprs,aucs,probas\n    ";try{const{results:e,error:t}=await N(o,this.context);if(e)return this.predictions=Array.from(e[0]),this.pdp_averages=Array.from(e[1]),this.pdp_grid=Array.from(e[2]),this.importances=Array.from(e[3]),this.fpr=Array.from(e[4]),this.tpr=Array.from(e[5]),this.auc=Array.from(e[6]),this.probas=Array.from(e[7]),Array.from(e[0]);t&&console.log("pyodideWorker error: ",t)}catch(l){throw Error(`Error in pyodideWorker at ${l.filename}, Line: ${l.lineno}, ${l.message}`)}}async visualize(e,t,s,a,i,n,r){await super.visualize(e,t,s,a,i),this.hasExplaination&&(this.chartController.PFIBoxplot(this.id,this.importances,n),this.chartController.plotPDP(this.id,this.pdp_averages,this.pdp_grid,s,n,r)),this.chartController.plotROC(this.id,this.fpr,this.tpr,s,this.auc),this.chartController.probabilities_boxplot(this.probas,i.inverseTransform(a),s,this.id)}}class fe extends ne{constructor(e){super(),this.options=e,this.model=null,this.hasExplaination=!1,this.summary=null,this.model_stats_matrix=null}async train(e,t,s,a,i,n){let r="Lasso"===this.options?.regularization?.value?1:0,o=+this.options?.degree?.value;const l=window.webr;await l.init(),await l.installPackages(["jsonlite","ggplot2","plotly","tidyr","broom","dplyr","ggrepel","glmnet","modelsummary"],{quiet:!0}),await l.objs.globalEnv.bind("xx",e),await l.objs.globalEnv.bind("x_test",s),await l.objs.globalEnv.bind("random_seed",this.seed),await l.objs.globalEnv.bind("y",t),await l.objs.globalEnv.bind("degree",o),await l.objs.globalEnv.bind("names",i),await l.objs.globalEnv.bind("categorical_columns",0===n?.length?["empty"]:n),await l.objs.globalEnv.bind("is_lasso",r);const c=await l.evalR('\n                    library(plotly)\n                    library(ggplot2)\n                    library(tidyr)\n                    library(dplyr)\n                    library(broom)\n\n                    library(ggrepel)\n                    library(modelsummary)\n                    library(glmnet)\n                    set.seed(random_seed)\n\n                    # Select all columns except the first as predictors. \n                    add_powers <- function(df, degree,columns) {\n                            new_df <- df  # Copy the original data frame\n                            for (col in columns) {\n                                for (d in 2:degree){\n                                    new_col_name <- paste0(col, "_", d)\n                                    new_df[[new_col_name]] <- df[[col]]^d\n                                }\n                            }\n                            return(new_df)\n                        }\n                        \n                    x <- as.matrix(xx)  \n                    colnames(x) <- names\n                    cols_numerical <- setdiff(names, categorical_columns)\n                    df_main <- add_powers(as.data.frame(x), degree,cols_numerical)\n                    scale_df <- add_powers(as.data.frame(x), degree,cols_numerical)\n                    all_column_names <- colnames(scale_df)\n                    cols_to_scale <- setdiff(all_column_names, categorical_columns)\n                    scale_df[cols_to_scale] <- scale(scale_df[cols_to_scale])\n                    \n                    x <- as.matrix(x_test)  \n                    colnames(x) <- names\n                    df_test <- add_powers(as.data.frame(x), degree,cols_numerical)\n                    base_model = cv.glmnet(as.matrix(scale_df), y)\n                    weights <- 1 / abs(coef(base_model)[-1])\n\n                    if(is_lasso){\n                        cvfit = cv.glmnet(as.matrix(scale_df), y, alpha = 1)\n                    }else{\n                       cvfit = cv.glmnet(as.matrix(scale_df), y, alpha = 0)\n                    }\n                    betas = as.matrix(cvfit$glmnet.fit$beta)\n                    lambdas = cvfit$lambda\n                    names(lambdas) = colnames(betas)\n                    \n                    p <- as.data.frame(betas) %>% \n                      tibble::rownames_to_column("variable") %>% \n                      pivot_longer(-variable) %>% \n                      mutate(lambda=lambdas[name]) %>% \n                      mutate(variable = factor(variable, levels = sort(unique(variable)))) %>%\n\n                    ggplot(aes(x=lambda,y=value,col=variable)) + \n                      geom_line() + \n                      geom_label_repel(data=~subset(.x,lambda==min(lambda)),\n                                       aes(label=variable),nudge_x=-0.5) +\n                      geom_vline(xintercept=c(cvfit$lambda.1se,cvfit$lambda.min),\n                                linetype="dashed")+\n                      scale_x_log10() +\n                      labs(y = "Coefficient") +\n                    theme_bw()\n                    \n                    df = with(cvfit,\n                            data.frame(lambda = lambdas,MSE = cvm,MSEhi=cvup,MSElow=cvlo))\n\n                    p2<-ggplot(df,aes(x=lambda,y=MSE)) + \n                    geom_point(col="#f05454") + \n                    scale_x_log10("lambda") + \n                    geom_errorbar(aes(ymin = MSElow,ymax=MSEhi),col="#30475e") + \n                    geom_vline(xintercept=c(cvfit$lambda.1se,cvfit$lambda.min),\n                                linetype="dashed")+\n                    theme_bw()\n\n                     # Get lambda.min and lambda.1se\n                    lambda_min = cvfit$lambda.min\n                    lambda_1se = cvfit$lambda.1se\n\n                    # Get the coefficients at lambda.min and lambda.1se\n                    coef_lambda_min = coef(cvfit, s = "lambda.min")\n                    coef_lambda_1se = coef(cvfit, s = "lambda.1se")\n\n                    # Convert the sparse matrix to a regular matrix to make indexing easier\n                    coef_lambda_min_matrix = as.matrix(coef_lambda_min)\n                    coef_lambda_1se_matrix = as.matrix(coef_lambda_1se)\n                    coef_lambda_min_matrix = coef_lambda_min_matrix[-1, , drop = FALSE]\n                    coef_lambda_1se_matrix = coef_lambda_1se_matrix[-1, , drop = FALSE]\n                    # Find the non-zero features at lambda.min and lambda.1se\n                    non_zero_features_min = rownames(coef_lambda_min_matrix)[coef_lambda_min_matrix != 0]\n                    non_zero_features_1se = rownames(coef_lambda_1se_matrix)[coef_lambda_1se_matrix != 0]\n                    print(non_zero_features_min)\n                    print(non_zero_features_1se)\n                    x <- as.matrix(df_main)\n                    colnames(x) <- all_column_names\n\n                    model <- lm(y ~ ., data = as.data.frame(x))\n\n                    x <- as.matrix(df_test)  \n                    colnames(x) <- all_column_names\n\n                    predictions <- predict(model, newdata = as.data.frame(x))\n                    # Get coefficients, p-values, and standard errors\n                    coefs <- coef(model)\n                    pvals <- summary(model)$coefficients[,4]\n                    std_error <- summary(model)$coefficients[,2]\n                    aic_value <- AIC(model)\n                    bic_value <- BIC(model)\n                    rsquared <- summary(model)$r.squared\n                    residuals_ols <- resid(model)\n                    fitted_values_ols <- fitted(model)\n\n                    x <- as.matrix(df_main)  \n                    colnames(x) <- all_column_names\n                    X_reduced <- x[, non_zero_features_min]\n                    linear_model_min_features <- non_zero_features_min\n                    # Fit a linear regression model using the non-zero features\n                    print(colnames(X_reduced))\n                    linear_model_min <- lm(y ~ ., data = as.data.frame(X_reduced))\n                    coefs_min <- coef(linear_model_min)\n                    pvals_min <- summary(linear_model_min)$coefficients[,4]\n                    std_error_min <- summary(linear_model_min)$coefficients[,2]\n                    aic_min <- AIC(linear_model_min)\n                    rsquared_min <- summary(linear_model_min)$r.squared\n                    best_lambda <- cvfit$lambda.1se\n                    best_model <- glmnet(x, y, alpha =is_lasso, lambda = best_lambda)\n                    coefficients <- as.matrix(coef(best_model))\n                    residuals_min <- resid(linear_model_min)\n                    fitted_values_min <- fitted(linear_model_min)\n                    x <- as.matrix(df_test)  \n                    colnames(x) <- all_column_names\n                    predictions_min <- predict(linear_model_min, newdata = as.data.frame(x))\n\n\n\n\n\n                    x <- as.matrix(df_main)  \n                    colnames(x) <- all_column_names\n                    \n                    X_reduced <- x[, non_zero_features_1se]\n                    linear_model_1se_features <- non_zero_features_1se\n                    print(colnames(X_reduced))\n                    linear_model_1se <- lm(y ~ ., data = as.data.frame(X_reduced))\n                    coefs_1se <- coef(linear_model_1se)\n                    print(coefs_1se)\n                    pvals_1se <- summary(linear_model_1se)$coefficients[,4]\n                    aic_1se<- AIC(linear_model_1se)\n                    rsquared_1se <- summary(linear_model_1se)$r.squared\n                    std_error_1se <- summary(linear_model_1se)$coefficients[,2]\n                    residuals_1se <- resid(linear_model_1se)\n                    fitted_values_1se <- fitted(linear_model_1se)\n                    x <- as.matrix(df_test) \n                    colnames(x) <- all_column_names \n                    x <- x[, linear_model_1se_features]\n                    predictions_1se <- predict(linear_model_1se, newdata = as.data.frame(x))\n                    models <- list(\n                        "OLS" = model,\n                        "Lasso Min " = linear_model_min,\n                        "Lasso 1se " = linear_model_1se\n                        )\n\n                    z <- modelplot(models =models,coef_omit = \'Interc\')\n                    qqplot_ols <-ggplot(data.frame(residuals = residuals_ols), aes(sample = residuals_ols)) +\n                        stat_qq(color = "blue") +\n                        stat_qq_line(col = "red") +\n                        labs(title = "QQ Plot of Residuals",\n                            x = "Theoretical Quantiles",\n                            y = "Sample Quantiles") +\n                        theme_bw()\n                    qqplot_1se <-ggplot(data.frame(residuals = residuals_1se), aes(sample = residuals_1se)) +\n                        stat_qq(color = "blue") +\n                        stat_qq_line(col = "red") +\n                        labs(title = "QQ Plot of Residuals",\n                            x = "Theoretical Quantiles",\n                            y = "Sample Quantiles") +\n                        theme_bw()\n                    qqplot_min <-ggplot(data.frame(residuals = residuals_min), aes(sample = residuals_min)) +\n                        stat_qq(color = "blue") +\n                        stat_qq_line(col = "red") +\n                        labs(title = "QQ Plot of Residuals",\n                            x = "Theoretical Quantiles",\n                            y = "Sample Quantiles") +\n                        theme_bw()\n                    list(plotly_json(p, pretty = FALSE),plotly_json(p2, pretty = FALSE),coefs,\n                    pvals,std_error,predictions,aic_value,bic_value,rsquared\n                    ,coefs_min,pvals_min,std_error_min\n                    ,coefs_1se,pvals_1se,std_error_1se,plotly_json(z, pretty = FALSE),linear_model_min_features,linear_model_1se_features\n                    ,residuals_ols,residuals_1se,residuals_min,predictions_1se,predictions_min,rsquared_1se,aic_1se,rsquared_min,aic_min\n                    ,plotly_json(qqplot_ols, pretty = FALSE)\n                    ,plotly_json(qqplot_1se, pretty = FALSE)\n                    ,plotly_json(qqplot_min, pretty = FALSE)\n                    ,all_column_names\n                    )\n                    ');let d=await c.toArray();this.summary={params:await d[2].toArray(),bse:await d[4].toArray(),pvalues:await d[3].toArray(),predictions:await d[5].toArray(),predictions1se:await d[21].toArray(),predictionsmin:await d[22].toArray(),residuals_ols:await d[18].toArray(),residuals_1se:await d[19].toArray(),residuals_min:await d[20].toArray(),aic:await d[6].toNumber(),bic:await d[7].toNumber(),r2:await d[8].toNumber(),best_fit_min:{r2:await d[25].toNumber(),aic:await d[26].toNumber(),names:await d[16].toArray(),coefs:await d[9].toArray(),bse:await d[11].toArray(),pvalues:await d[10].toArray()},best_fit_1se:{r2:await d[23].toNumber(),aic:await d[24].toNumber(),names:await d[17].toArray(),coefs:await d[12].toArray(),bse:await d[14].toArray(),pvalues:await d[13].toArray()},columnNames:await d[30].toArray()},this.model_stats_matrix=[];let m=this.summary.columnNames;m.unshift("intercept");let p=this.summary["best_fit_min"].names;p.unshift("intercept");let u=this.summary["best_fit_1se"].names;u.unshift("intercept");for(let f=0;f<m.length;f++){let e=[];e.push(m[f]),e.push(this.summary["params"][f]?.toFixed(2)??" "),e.push(this.summary["bse"][f]?.toFixed(2)??" "),e.push(this.summary["pvalues"][f]?.toFixed(2)??" ");let t=p.findIndex((e=>e===m[f]));-1!==t?(e.push(this.summary["best_fit_min"]["coefs"][t]?.toFixed(2)??" "),e.push(this.summary["best_fit_min"]["bse"][t]?.toFixed(2)??" "),e.push(this.summary["best_fit_min"]["pvalues"][t]?.toFixed(2)??" ")):(e.push(" "),e.push(" "),e.push(" ")),t=u.findIndex((e=>e===m[f])),-1!==t?(e.push(this.summary["best_fit_1se"]["coefs"][t]?.toFixed(2)??" "),e.push(this.summary["best_fit_1se"]["bse"][t]?.toFixed(2)??" "),e.push(this.summary["best_fit_1se"]["pvalues"][t]?.toFixed(2)??" ")):(e.push(" "),e.push(" "),e.push(" ")),this.model_stats_matrix.push(e)}this.model_stats_matrix=this.model_stats_matrix.sort((function(e,t){return e[0]>t[0]?1:e[0]<t[0]?-1:0})),this.model_stats_matrix.reverse();let h=JSON.parse(await d[0].toString());h.layout["showlegend"]=!0,h.layout["autosize"]=!0,h.layout["responsive"]=!0,h.layout.xaxis["side"]="top",h.layout.legend={orientation:"h",font:{size:8,color:"#000"}};let _=JSON.parse(await d[15].toString());return _.layout.legend={x:0,y:1,traceorder:"normal",font:{size:8,color:"#000"}},this.summary.coefs_plot=_,this.summary.coefs_plot.layout["autosize"]=!0,this.summary.coefs_plot.layout["responsive"]=!0,this.summary.coefs_plot.layout.xaxis.title.font={size:10},this.summary.regularization_plot=h,this.summary.errors_plot=JSON.parse(await d[1].toString()),this.summary.qqplot_ols_plot=JSON.parse(await d[27].toString()),this.summary.qqplot_1se_plot=JSON.parse(await d[28].toString()),this.summary.qqplot_min_plot=JSON.parse(await d[29].toString()),this.summary.qqplot_ols_plot.layout.height=300,this.summary.qqplot_ols_plot.layout.width=300,this.summary.qqplot_ols_plot.layout.title.font={size:10},this.summary.qqplot_ols_plot.data[0].marker.size=3,this.summary.qqplot_ols_plot.layout.xaxis.title.font={size:10},this.summary.qqplot_ols_plot.layout.yaxis.title.font={size:10},this.summary.qqplot_1se_plot.layout.height=300,this.summary.qqplot_1se_plot.layout.width=300,this.summary.qqplot_1se_plot.layout.title.font={size:10},this.summary.qqplot_1se_plot.data[0].marker.size=3,this.summary.qqplot_1se_plot.layout.xaxis.title.font={size:10},this.summary.qqplot_1se_plot.layout.yaxis.title.font={size:10},this.summary.qqplot_min_plot.layout.height=300,this.summary.qqplot_min_plot.layout.width=300,this.summary.qqplot_min_plot.layout.title.font={size:10},this.summary.qqplot_min_plot.layout.xaxis.title.font={size:10},this.summary.qqplot_min_plot.layout.yaxis.title.font={size:10},this.summary.qqplot_min_plot.data[0].marker.size=3,this.summary["predictions"]}async visualize(e,t,s,a,i){await super.visualize(e,t,s,a);let n=this;new DataTable("#metrics_table_"+n.id,{responsive:!1,footerCallback:function(e,t,s,a,i){var r=this.api();$(r.column(2).footer()).html("R2 : "+n.summary.r2.toFixed(2)+" AIC: "+n.summary.aic.toFixed(2)),$(r.column(5).footer()).html("R2 : "+n.summary["best_fit_min"].r2.toFixed(2)+" AIC: "+n.summary["best_fit_min"].aic.toFixed(2)),$(r.column(8).footer()).html("R2 : "+n.summary["best_fit_1se"].r2.toFixed(2)+" AIC: "+n.summary["best_fit_1se"].aic.toFixed(2))},data:n.model_stats_matrix,info:!1,search:!1,ordering:!1,searching:!1,paging:!1,bDestroy:!0,columnDefs:[{targets:3,createdCell:function(e,t,s,a,i){s[3]<=.05&&$(e).css("color","red")}},{targets:6,createdCell:function(e,t,s,a,i){s[6]<=.05&&$(e).css("color","red")}},{targets:9,createdCell:function(e,t,s,a,i){s[9]<=.05&&$(e).css("color","red")}}]}),M().newPlot("regularization_"+n.id,n.summary.regularization_plot,{autosize:!0,responsive:!0}),M().newPlot("parameters_plot_"+n.id,n.summary.coefs_plot,{autosize:!0,responsive:!0}),M().newPlot("errors_"+n.id,n.summary.errors_plot,{autosize:!0,responsive:!0}),M().newPlot("qqplot_ols_"+n.id,n.summary.qqplot_ols_plot),M().newPlot("qqplot_min_"+n.id,n.summary.qqplot_min_plot),M().newPlot("qqplot_1se_"+n.id,n.summary.qqplot_1se_plot),n.chartController.yhat_plot(t,this.summary["predictions"],"regression_y_yhat_"+ +n.id,"OLS predictions"),n.chartController.yhat_plot(t,this.summary["predictionsmin"],"regression_y_yhat_min_"+ +n.id,"lasso min predictions"),n.chartController.yhat_plot(t,this.summary["predictions1se"],"regression_y_yhat_1se_"+ +n.id,"lasso 1se predictions"),n.chartController.residual_plot(t,this.summary["residuals_ols"],"regression_residual_"+ +n.id,"OLS residuals"),n.chartController.residual_plot(t,this.summary["residuals_min"],"regression_residual_min_"+ +n.id,"lasso min residuals"),n.chartController.residual_plot(t,this.summary["residuals_1se"],"regression_residual_1se_"+ +n.id,"lasso 1se residuals"),this.ui.predictions_table_regression(e,t,a,this.id)}}class ge{constructor(e){this.options=e,this.model=null,this.hasExplaination=!1}async train(e,t,s,a,i){this.context={X_train:e,y_train:t,X_test:s,types:this.options.types,labels:i};const n="\n        import numpy as np\n        import statsmodels.api as sm\n        from js import X_train,y_train,X_test,labels,types\n        from statsmodels.nonparametric.kernel_regression import KernelReg\n        import pandas as pd\n\n        df_test = pd.DataFrame(X_test,columns=labels)\n        x_test = df_test.iloc[:,:]\n\n        df_train = pd.DataFrame(X_train,columns=labels)\n        x_train = df_train.iloc[:,:]\n\n        model = KernelReg(endog=np.array(y_train), exog=x_train, var_type=types)\n        \n        preds = model.fit(x_test)\n\n        \n        preds\n        ";try{const{results:e,error:t}=await N(n,this.context);if(e)return e;t&&console.log("pyodideWorker error: ",t)}catch(r){throw Error(`Error in pyodideWorker at ${r.filename}, Line: ${r.lineno}, ${r.message}`)}}predict(e){const t=this.model.predict(e);return t}}class be extends ae{constructor(e,t){super(t);let s={booster:e.booster.value??"gbtree",objective:"multi:softmax",max_depth:+e.depth.value,eta:+e.eta.value,estimators:e.estimators.value??200};this.options=s,this.helpSectionId="cart_help"}async train(e,t,s,a,i,n,r){this.context={X_train:e,y_train:t,X_test:s,y_test:a,objective:this.options.objective,max_depth:this.options.max_depth,eta:this.options.eta,estimators:this.options.estimators,seed:this.seed,pdpIndex:r,features:[...Array(i.length).keys()],explain:this.hasExplaination};const o="\n        import matplotlib\n        matplotlib.use(\"AGG\")\n        from js import X_train,y_train,X_test,y_test,objective,max_depth,eta,estimators,seed,features,explain\n        from sklearn.inspection import PartialDependenceDisplay\n        from sklearn.inspection import permutation_importance\n        from sklearn.ensemble import GradientBoostingClassifier\n\n        features_importance = []\n        partial_dependence_plot_grids = []\n        partial_dependence_plot_avgs = []\n\n        model = GradientBoostingClassifier(learning_rate = eta,n_estimators = estimators,max_depth =max_depth,random_state = seed )\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        if explain:\n            pdp = PartialDependenceDisplay.from_estimator(model, X_train, features,target=0,method ='brute')\n            fi = permutation_importance(model,X_test,y_test,n_repeats=10)\n            partial_dependence_plot_avgs = list(map(lambda item:item['average'],pdp.pd_results))\n            grids = list(map(lambda item:item['grid_values'],pdp.pd_results))\n            features_importance = list(fi.importances)\n            partial_dependence_plot_grids = [item[0].tolist() for item in grids ]\n        y_pred,partial_dependence_plot_avgs,partial_dependence_plot_grids, features_importance\n    ";try{const{results:e,error:t}=await N(o,this.context);if(e)return this.predictions=Array.from(e[0]),this.pdp_averages=Array.from(e[1]),this.pdp_grid=Array.from(e[2]),this.importances=Array.from(e[3]),Array.from(e[0]);t&&console.log("pyodideWorker error: ",t)}catch(l){throw Error(`Error in pyodideWorker at ${l.filename}, Line: ${l.lineno}, ${l.message}`)}}generatePythonCode(){let e="from sklearn.ensemble import GradientBoostingClassifier",t=`model = GradientBoostingClassifier(learning_rate = ${this.options.eta} ,n_estimators = ${this.options.estimators} ,max_depth =${this.options.max_depth} ,random_state = ${this.seed} )`;return super.generatePythonCode(e,t)}async visualize(e,t,s,a,i,n,r){await super.visualize(e,t,s,a,i),this.hasExplaination&&(this.chartController.PFIBoxplot(this.id,this.importances,n),this.chartController.plotPDP(this.id,this.pdp_averages,this.pdp_grid,s,n,r))}}class ye extends ne{constructor(e,t){super(t);let s={booster:e.booster.value??"gbtree",objective:"multi:softmax",max_depth:+e.depth.value,eta:+e.eta.value,estimators:e.estimators.value??200};this.options=s,this.helpSectionId="cart_help"}async train(e,t,s,a,i){this.context={X_train:e,y_train:t,X_test:s,y_test:a,objective:this.options.objective,max_depth:this.options.max_depth,eta:this.options.eta,estimators:this.options.estimators,seed:this.seed,explain:this.hasExplaination,features:[...Array(i.length).keys()]};const n="\n\n        from js import X_train,y_train,X_test,y_test,objective,max_depth,eta,estimators,seed,features,explain\n        from sklearn.inspection import PartialDependenceDisplay\n        from sklearn.inspection import permutation_importance\n        from sklearn.ensemble import GradientBoostingRegressor\n        import pandas as pd\n        import matplotlib\n        matplotlib.use(\"AGG\")\n\n        features_importance = []\n        partial_dependence_plot_grids = []\n        partial_dependence_plot_avgs = []\n        model = GradientBoostingRegressor(learning_rate = eta,n_estimators = estimators,max_depth =max_depth,random_state = seed)\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n\n\n\n        if explain:\n            pdp = PartialDependenceDisplay.from_estimator(model, X_train, features,method ='brute')\n            fi = permutation_importance(model,X_test,y_test,n_repeats=10)\n            partial_dependence_plot_avgs = list(map(lambda item:item['average'],pdp.pd_results))\n            grids = list(map(lambda item:item['grid_values'],pdp.pd_results))\n            features_importance = list(fi.importances)\n            partial_dependence_plot_grids = [item[0].tolist() for item in grids ]\n        y_pred,partial_dependence_plot_avgs,partial_dependence_plot_grids, features_importance\n\n    ";try{const{results:e,error:t}=await N(n,this.context);if(e)return this.predictions=Array.from(e[0]),this.pdp_averages=Array.from(e[1]),this.pdp_grid=Array.from(e[2]),this.importances=Array.from(e[3]),Array.from(e[0]);t&&console.log("pyodideWorker error: ",t)}catch(r){throw Error(`Error in pyodideWorker at ${r.filename}, Line: ${r.lineno}, ${r.message}`)}}async visualize(e,t,s,a,i,n,r){await super.visualize(e,t,s,a,i),this.hasExplaination&&(this.chartController.PFIBoxplot(this.id,this.importances,n),this.chartController.plotPDPRegression(this.id,this.pdp_averages,this.pdp_grid,s,n,r))}}var ve=function(){this.createModel=(e,t)=>{switch(e){case E.classification.logistic_regression.value:return new ie(t);case E.classification.k_nearest_neighbour.value:return new de(t);case E.classification.random_forest.value:return new pe(t);case E.classification.support_vector_machine.value:return new le(t);case E.classification.boosting.value:return new be(t);case E.regression.boosting.value:return new ye(t);case E.classification.discriminant_analysis.value:return new _e(t);case E.classification.naive_bayes.value:return new he(t);case E.regression.linear_regression.value:return new re(t);case E.regression.k_nearest_neighbour.value:return new me(t);case E.regression.support_vector_machine.value:return new ce(t);case E.regression.random_forest.value:return new ue(t);case E.regression.polynomial_regression.value:return new fe(t);case E.regression.kernel_regression.value:return new ge(t);case E.regression.bspline_regression.value:return new oe(t);default:throw new Error("Model not supported.")}}},xe=s(67822),we=s(94373),Ce={name:"SidebarComponent",setup(){const e=y();return{settings:e}},components:{UploadComponent:S},props:{msg:String},data(){return{dataScalingBehavior:!1,explainModel:!0,training:!1,tuneModel:!1,numberOfComponents:0,usePCAs:!1,useHPC:!1,seed:123,dataframe:null,configureFeatures:!1,modelOptions:E.classification,imputationOption:1,modelOption:1,featureTypeOptions:z,crossValidationOption:1,columns:[],modelTarget:null,modelConfigurations:null,imputationOptions:[{id:1,label:"Delete rows"},{id:2,label:"Mean and Mode"},{id:3,label:"Linear regression"},{id:4,label:"random forest"}],crossValidationOptions:[{id:A.SPLIT,label:"70 % training - 30 % test"},{id:A.NO,label:"No"},{id:A.KFOLD,label:"k-fold"}],featureSettings:[],modelSettings:[],modelName:"",file:null}},methods:{setFile(e){this.file=e},upload(){let e=new FormData;this.settings.rawData,e.append("file",this.file),console.log(this.file),we.A.post("http://127.0.0.1:5000/upload",e,{headers:{"Content-Type":"multipart/form-data"}}).then((function(){console.log("SUCCESS!!")})).catch((function(){console.log("FAILURE!!")}))},updateFeatures(){this.configureFeatures=!1,this.$emit("updateFeatures",!0)},toggleTraining(){this.training=!this.training;let e=this.training?"started training "+this.modelName:"Successully fitted "+this.modelName;this.$buefy.toast.open({duration:5e3,message:this.training?"started training "+this.modelName:"Successully fitted "+this.modelName,type:this.training?"is-info":"is-success"}),this.settings.addMessage({message:e,type:"info"})},getDefaultModelConfiguration(){for(const e in this.modelOptions){const t=this.modelOptions[e];if(t.id===this.modelOption){for(const e in t.options)t.options[e].value=t.options[e]?.default;this.modelConfigurations=t.options,this.modelName=t.title}}},configureModel(){this.tuneModel=!this.tuneModel,this.getDefaultModelConfiguration()},generateTargetDropdown(){this.dataframe=this.settings.getDataset,this.columns=this.dataframe.columns,this.featureSettings=this.columns.map(((e,t)=>({name:e,selected:!0,type:"string"===this.dataframe.dtypes[t]?z.Nominal.id:z.Numerical.id}))),this.modelTarget=this.dataframe.columns[this.dataframe.columns.length-1],this.settings.setTarget(this.modelTarget);let e=this.featureSettings.filter((e=>e.selected));for(let t=0;t<e.length;t++)this.settings.addFeature(e[t]);this.$emit("updateFeatures",!0)},checkmodelTask(){console.log(this.modelTarget),this.settings.setTarget(this.modelTarget);let e=this.settings.items.find((e=>e.name==this.modelTarget));if(!e.selected){let e="Target is not selected";return this.$buefy.toast.open({duration:3e3,message:e,type:"is-warning"}),void this.settings.addMessage({message:e,type:"warning"})}this.settings.setmodelTask(e.type!==z.Numerical.id),this.modelOptions=e.type===z.Numerical.id?E.regression:E.classification},async train(){try{this.modelConfigurations||this.getDefaultModelConfiguration();let e=+this.seed;this.settings.setSeed(e);let t=[],s=null;this.dataframe=new xe.DataFrame(this.settings.rawData),s=await this.dataframe.sample(this.dataframe.$data.length,{seed:e});let a=this.settings.items.filter((e=>e.selected&&e.type===z.Numerical.id)).map((e=>e.name));const i=this.settings.modelTarget;if(s=J(s),s=U(s,a,this.settings.transformationsList),this.dataScalingBehavior){let e=[];for(let t=0;t<a.length;t++)e.push({name:a[t],scaler:"1"});s=U(s,a,e)}let n=this.settings.items.filter((e=>e.selected)).map((e=>e.name));const r=n.findIndex((e=>e===i));-1===r&&n.push(i);let o=s.loc({columns:n});if(this.settings.isClassification){let e=this.settings.mergedClasses;e?.length>0&&this.settings.mergedClasses.forEach((e=>{let t=e.map((e=>e.class)).join("_");e.forEach((e=>{o.replace(e.class,t,{columns:[this.settings.modelTarget],inplace:!0})}))}))}const l=o.column(i);o.drop({columns:i,inplace:!0});const c=this.crossValidationOption;let d,m,p,u;if([o,t]=V(o,this.settings.items.filter((e=>e.selected)).filter((e=>e.name!==this.settings.modelTarget)).map((e=>({name:e.name,type:e.type})))),c!==A.KFOLD||this.modelName==E.classification.logistic_regression.title&&this.modelName==E.regression.linear_regression.title)[d,m,p,u]=this.splitData(c,o,l);else{let e=[];for(let s=1;s<6;s++){[d,m,p,u]=this.kfoldSplit(o,l,s);let a,i,n,r=[...new Set(m.values)];this.settings.classificationTask?[a,i,n]=this.encodeTarget(m.values,u.values):(i=m.values,n=u.values);let c=new ve,h=c.createModel(this.modelOption,this.modelConfigurations);h.hasExplaination=!1,h.id=this.settings.getCounter,this.toggleTraining();let _=await h.train(d.values,i,p.values,n,d.columns,t,0),f=await h.evaluateModel(n,_,r);f=this.settings.classificationTask?f[4]:f[0],this.training=!1,e.push(f)}}let h,_,f,g=[...new Set(m.values)];this.settings.classificationTask?[h,_,f]=this.encodeTarget(m.values,u.values):(_=m.values,f=u.values);let b=new ve,y=b.createModel(this.modelOption,this.modelConfigurations);if(y.seed=e,y.id=this.settings.getCounter,this.toggleTraining(),y.hasExplaination=this.explainModel,this.usePCAs){const e=new D;let t=this.settings.items.filter((e=>e.selected&&1===e.type&&e.name!=this.modelTarget)).map((e=>e.name)),[s,a,i,n,r,o]=await e.predict(d.loc({columns:t}).values,this.numberOfComponents,p.loc({columns:t}).values);s=s.map((e=>[].slice.call(e))),o=o.map((e=>[].slice.call(e)));let l=s[0].map(((e,t)=>"PC_"+(t+1)));d=new xe.DataFrame(s,{columns:l}),p=new xe.DataFrame(o,{columns:l})}console.log(new Set(_));let v=this.useHPC?[]:await y.train(d.values,_,p.values,f,d.columns,t,0),x=this.useHPC?[]:await y.evaluateModel(f,v,g);(v?.length>0||this.useHPC)&&(this.settings.addResult({id:y.id,useHPC:this.useHPC?Math.random().toString(16).slice(2):0,showProbas:y.hasProbability,helpSectionId:y.helpSectionId,hasExplaination:y.hasExplaination,snapshot:{x:d,y:_,xt:p,yt:f,xFeatures:d.columns,categoricals:t,id:this.modelOption,labels:g},seed:e,encoder:h,name:this.usePCAs?"PC."+this.modelName:this.modelName,datasetName:this.settings.getDatasetName,modelTask:this.settings.classificationTask,metrics:x,options:JSON.parse(JSON.stringify(this.modelConfigurations)),target:i,categoricalFeatures:this.settings.items.filter((e=>e.selected&&e.type!==z.Numerical.id)).map((e=>e.name)),numericColumns:a,transformations:[...this.settings.transformationsList.filter((e=>0!=e.type))],tables:y.tables,plots:y.plots,predictions:v,model:y}),this.settings.setActiveTab(2),setTimeout((async()=>{this.settings.setResultActiveTab(y.id+1),window.dispatchEvent(new Event("resize"))}),100),this.useHPC||await y.visualize(p,f,g,v,h,d.columns,t),this.settings.increaseCounter(),this.toggleTraining())}catch(e){this.training=!1;let t="Failed to fit the "+this.modelName;throw this.$buefy.toast.open({duration:3e3,message:t,type:"is-warning"}),this.settings.addMessage({message:t,type:"warning"}),e}},impute(){this.training=!0,we.A.post("http://127.0.0.1:5000/missforest",{data:(0,xe.toJSON)(this.dataframe),categoricalFeatures:this.settings.items.filter((e=>e.selected&&e.type!==z.Numerical.id)).map((e=>e.name))}).then((e=>{let t=new xe.DataFrame(e.data);this.dataframe=t,this.settings.setDataframe(t),this.training=!1}))}},created:function(){this.splitData=function(e,t,s,a=.7){let i,n,r,o,l=t.$data.length;if(e===A.SPLIT){const e=Math.ceil(l*a),c=`0:${e}`,d=`${e}:${l}`;i=t.iloc({rows:[c]}),n=s.iloc([c]),r=t.iloc({rows:[d]}),o=s.iloc([d])}else e===A.NO&&(i=t,n=s,r=t,o=s);return[i,n,r,o]},this.kfoldSplit=function(e,t,s=1){let a,i,n,r,o=e.$data.length;const l=Math.ceil(o*(.2*(s-1))),c=Math.ceil(o*(.2*s)),d=0!=l?`:${l}`:null,m=c!=o?`${c}:`:null,p=`${l}:${c}`;let u=null!=m?e.iloc({rows:[m]}):null,h=null!=m?t.iloc([m]):null;n=e.iloc({rows:[p]}),r=t.iloc([p]);let _=null!=d?e.iloc({rows:[d]}):null,f=null!=d?t.iloc([d]):null;return _&&u?(a=(0,g.concat)({dfList:[_,u],axis:0}),i=(0,g.concat)({dfList:[f,h],axis:0})):(a=null==_?u:_,i=null==_?h:f),[a,i,n,r]},this.encodeTarget=function(e,t){let s=new g.LabelEncoder;s.fit(e),s.transform(e);let a=s.transform(e),i=s.transform(t);return[s,a,i]}},watch:{modelOption:function(){this.modelConfigurations=null}}},ke=Ce,Se=(0,C.A)(ke,r,o,!1,null,null,null),ze=Se.exports,Ae=function(){var e=this,t=e._self._c;return t("div",{staticClass:"column is-10"},[t("section",[t("b-tabs",{attrs:{position:"is-centered",animated:!1,type:"success"},on:{input:function(t){return e.resize()}},model:{value:e.settings.activeTab,callback:function(t){e.$set(e.settings,"activeTab",t)},expression:"settings.activeTab"}},[t("b-tab-item",{attrs:{label:"Data Analysis",icon:"search","icon-pack":"fas"}},[this.settings.datasetShape?.count>0?t("section",[e.isActive?t("div",{staticClass:"message is-info",attrs:{closable:!1}},[t("div",{staticClass:"message-header p-2"},[e._v("Data summary")]),t("div",{staticClass:"message-body"},[t("div",{staticClass:"columns is-multiline"},[t("div",{staticClass:"column is-12 has-text-left"},[t("p",{staticClass:"title is-6 m-0 mb-1"},[e._v(" Data Shape: ("+e._s(this.settings.datasetShape.count)+","+e._s(this.settings.datasetShape.columns)+")")])]),t("div",{staticClass:"column is-6"},[t("h5",{staticClass:"title is-6 has-text-left m-0 mb-1"},[e._v("Numerical Features: ")]),t("div",{staticClass:"table-container"},[t("table",{staticClass:"table is-size-7"},[t("thead",[t("tr",[t("th",{staticClass:"is-success"}),t("th",{staticClass:"is-success"},[e._v("Name")]),t("th",{staticClass:"is-success"},[e._v("Min")]),t("th",{staticClass:"is-success"},[e._v("Max")]),t("th",{staticClass:"is-success"},[e._v("Mean")]),t("th",{staticClass:"is-success"},[e._v("Median")]),t("th",{staticClass:"is-success"},[e._v("st.d")]),t("th",{staticClass:"is-success"},[e._v("#NAs")]),t("th",{staticClass:"is-success"},[e._v("Type")])])]),t("tbody",e._l(e.continuousFeaturesStats,(function(s){return t("tr",{key:s.name},[t("td",[t("b-checkbox",{model:{value:s.selected,callback:function(t){e.$set(s,"selected",t)},expression:"feature.selected"}})],1),t("td",[e._v(e._s(s.name))]),t("td",[e._v(e._s(s.min))]),t("td",[e._v(e._s(s.max))]),t("td",[e._v(e._s(s.median))]),t("td",[e._v(e._s(s.mean))]),t("td",[e._v(e._s(s.std))]),t("td",[e._v(e._s(s.missingValuesCount))]),t("td",[t("b-select",{attrs:{expanded:!0,size:"is-small"},model:{value:s.type,callback:function(t){e.$set(s,"type",t)},expression:"feature.type"}},e._l(e.featureTypeOptions,(function(s){return t("option",{key:s.id,domProps:{value:s.id}},[e._v(" "+e._s(s.name)+" ")])})),0)],1)])})),0)])]),t("button",{staticClass:"button is-small is-info",on:{click:function(t){return e.applyChanges()}}},[e._v("Apply changes")])]),t("div",{staticClass:"column is-6"},[t("h5",{staticClass:"title is-6 has-text-left m-0 mb-1"},[e._v("Categorical Features(Nominal/Ordinal):")]),t("div",{staticClass:"table-container"},[t("table",{staticClass:"table is-size-7 mb-1"},[t("thead",[t("tr",[t("th",{staticClass:"is-success"}),t("th",{staticClass:"is-success"},[e._v("Name")]),t("th",{staticClass:"is-success"},[e._v("Shape")]),t("th",{staticClass:"is-success"},[e._v("Mode")]),t("th",{staticClass:"is-success"},[e._v("Mode percentage")]),t("th",{staticClass:"is-success"},[e._v("#NAs")]),t("th",{staticClass:"is-success"},[e._v("Type")])])]),t("tbody",e._l(e.categoricalFeaturesStats,(function(s){return t("tr",{key:s.name},[t("td",[t("b-checkbox",{model:{value:s.selected,callback:function(t){e.$set(s,"selected",t)},expression:"feature.selected"}})],1),t("td",[e._v(e._s(s.name))]),t("td",[e._v(e._s(s.shape))]),t("td",[e._v(e._s(s.mode))]),t("td",[e._v(e._s(s.percentage))]),t("td",[e._v(e._s(s.missingValuesCount))]),t("td",[t("b-select",{attrs:{expanded:!0,size:"is-small"},model:{value:s.type,callback:function(t){e.$set(s,"type",t)},expression:"feature.type"}},e._l(e.featureTypeOptions,(function(s){return t("option",{key:s.id,domProps:{value:s.id}},[e._v(" "+e._s(s.name)+" ")])})),0)],1)])})),0)]),t("p",{staticClass:"subtitle is-7 m-0 p-0"},[e._v(" Nominal features are one hot encoded and ordinal features are encoded in one column.")])])]),t("div",{staticClass:"column is-6"},[t("h5",{staticClass:"title is-6 has-text-left"},[e._v("Sample Data :")]),t("b-table",{staticClass:"is-size-7 m-0 mb-1",attrs:{data:e.sampleData,columns:e.datasetColumns,narrowed:!0,bordered:!0,striped:!0,hoverable:!0}})],1)])])]):e._e(),t("section",[t("scatterplot-matrix-component",{ref:"splom"})],1),t("section",[t("article",{staticClass:"message is-info mt-2"},[t("div",{staticClass:"message-header p-2"},[e._v("Correlation Matrix and Dendrogram "),t("b-tooltip",{attrs:{"append-to-body":"",label:"Ward method requires euclidean distance",multilined:""}},[t("b-button",{attrs:{"icon-left":"info","icon-pack":"fas",size:"is-small",type:"is-dark"}})],1)],1),t("div",{staticClass:"message-body"},[t("div",{staticClass:"columns is-gapless"},[t("div",{staticClass:"column is-6 mx-1"}),t("div",{staticClass:"column is-6 mx-1"},[t("b-field",{attrs:{label:"Linkage method, Distance Metric","custom-class":"is-small"}},[t("b-select",{attrs:{size:"is-small",placeholder:"Method"},model:{value:e.method,callback:function(t){e.method=t},expression:"method"}},[t("option",{attrs:{value:"single"}},[e._v("single")]),t("option",{attrs:{value:"complete"}},[e._v("complete")]),t("option",{attrs:{value:"average"}},[e._v("average")]),t("option",{attrs:{value:"weighted"}},[e._v("weighted")]),t("option",{attrs:{value:"centroid"}},[e._v("centroid")]),t("option",{attrs:{value:"median"}},[e._v("median")]),t("option",{attrs:{value:"ward"}},[e._v("ward")])]),t("b-select",{attrs:{size:"is-small",placeholder:"Metric"},model:{value:e.metric,callback:function(t){e.metric=t},expression:"metric"}},[t("option",{attrs:{value:"euclidean"}},[e._v("euclidean")]),t("option",{attrs:{value:"correlation"}},[e._v("correlation")]),t("option",{attrs:{value:"mahalanobis"}},[e._v("mahalanobis")]),t("option",{attrs:{value:"cosine"}},[e._v("cosine")])]),t("p",{staticClass:"control"},[t("b-button",{staticClass:"is-success is-small",attrs:{disabled:e.loading,loading:e.loading},on:{click:e.correlationMatrix}},[e._v("Correlation Cluster Diagram")])],1)],1)],1)]),t("div",{staticClass:"columns is-multiline is-centered mb-2 p-0 is-gapless"},[t("div",{staticClass:"column is-6",staticStyle:{height:"400px"},attrs:{id:"correlation_matrix"}}),t("div",{staticClass:"column is-6",staticStyle:{height:"400px"},attrs:{id:"correlation_matrix_ordered"}})])])])])]):t("section",[t("b-message",{attrs:{type:"is-danger","has-icon":"","icon-pack":"fas"}},[e._v(" Upload a dataset or select a sample from sidebar. ")])],1)]),t("b-tab-item",{attrs:{label:"Dimensionality Reduction",icon:"compress-arrows-alt","icon-pack":"fas"}},[t("dmensionality-reduction-component",{attrs:{dataframe:this.settings.df,columns:e.selectedFeatures}})],1),t("b-tab-item",{attrs:{label:"Results Analysis",icon:"chart-pie","icon-pack":"fas"}},[t("results-component",{ref:"results"})],1),t("b-tab-item",{attrs:{label:"Methods Details",icon:"list","icon-pack":"fas"}},[t("methods-tab-component")],1),t("b-tab-item",{attrs:{label:"Help",icon:"question","icon-pack":"fas"}},[t("div",{staticClass:"content has-text-left"},[t("h4",[e._v("1. Dataset Selection")]),t("p",[e._v(" To begin, you can either select a sample dataset provided by the system or upload your own dataset. The supported file formats for datasets include .xlsx (Excel files), .csv (Comma Separated Values files), and .txt (plain text files). Ensure that your file is in one of these formats to avoid any issues during the upload process. ")]),t("figure",[t("img",{attrs:{src:"/upload.png"}}),t("figcaption",[e._v("Figure 1: Dataset Selection")])]),t("h4",[e._v("2. Data Analysis")]),t("figure",[t("img",{attrs:{src:"/stats_categorical.jpg"}}),t("figcaption",[e._v("Figure 2: Categorical features stats")])]),t("p",[e._v(" After uploading the dataset an overview of the dataset would be shhown in the Data Analysis tab. In the first window we provide you witth statistical metrics of the dataset. for canotinious features we show the mean, std, min, max, and etc. In case of categorical features information such as shape, mode and percentages of smaples with modes option, and number of missing values. ")]),t("figure",[t("img",{attrs:{src:"/stats_continious.jpg"}}),t("figcaption",[e._v("Figure 3: Categorical features stats")])]),t("p",[e._v(" In case of categorical features information such as shape, mode and percentages of smaples with modes option, and number of missing values. ")]),t("h4",[e._v("3. Feature selection")]),t("p",[e._v(" After uploading the dataset, you can customize the data by selecting specific features based on your requirements. To do this, click on the 'Select Features' button, which will open a new menu. This menu allows you to choose the features that will be used in the training process. If there is an issue with the automatic detection of feature data types, you can manually adjust the data types to ensure they are correctly categorized as ordinal, categorical, or continuous. ")]),t("h4",[e._v("3. Model Selection")]),t("figure",[t("img",{attrs:{src:"/model_selection.jpg"}}),t("figcaption",[e._v("Figure 4: Model selection and setting for knn")])]),t("p",[e._v(" Once you have selected all the required features and resolved any issues with feature data types, you can proceed to the model selection step. Use the 'Model' dropdown to choose the model for training. The options in this dropdown will be dynamically populated based on the type of data in your features: regression models will be available for continuous data, while classification models will be shown for categorical data. Additionally, you can further customize the selected model by clicking the gear icon, which allows you to adjust common settings and parameters specific to each model. ")])])]),t("b-tab-item",{attrs:{label:"Messages Log",icon:"history","icon-pack":"fas"}},e._l(this.settings.getMessages,(function(s,a){return t("b-notification",{key:a,attrs:{"aria-close-label":"Close notification","icon-pack":"fas",type:"warning"==s.type?"is-warning":"danger"==s.type?"is-danger":"is-info","has-icon":"",closable:!1}},[e._v(" "+e._s(s.message?.toLowerCase())+" "),t("br"),e._v(" "+e._s(s.date)+" ")])})),1)],1)],1)])},Pe=[],Ee=function(){var e=this,t=e._self._c;return this.settings?.items.length>2?t("section",[t("div",{staticClass:"message is-info"},[t("div",{staticClass:"message-header p-2"},[e._v("Principle Component Analysis")]),t("div",{staticClass:"message-body"},[t("b-field",[t("p",{staticClass:"control"},[t("b-button",{attrs:{disabled:e.numberOfComponents<2||e.numberOfComponents>this.settings.items.filter((e=>e.selected&&1===e.type))?.length,size:"is-small",type:"is-info",loading:e.loadingPCA,label:"Fit PCA"},on:{click:function(t){return e.drawPCA()}}})],1)]),t("div",{staticClass:"columns is-multiline",attrs:{id:"pca_container"}},[e._m(0),e._m(1),this.pcaVarianceData?t("button",{staticClass:"button is-small mt-1",on:{click:function(t){return e.downloadExplainedVariance()}}},[e._v("Download PCA variance data")]):e._e(),e.hasPCA?t("div",{staticClass:"column is-12"},[t("b-field",{attrs:{label:"Number of Components","label-position":"on-border"}},[t("b-input",{attrs:{size:"is-small",type:"number",min:"2",placeholder:"Number of Components"},model:{value:e.numberOfComponents,callback:function(t){e.numberOfComponents=t},expression:"numberOfComponents"}}),t("p",{staticClass:"control"},[t("b-button",{attrs:{disabled:e.numberOfComponents<2||e.x==e.y||e.numberOfComponents>this.settings.items.filter((e=>e.selected&&1===e.type))?.length,size:"is-small",type:"is-info",loading:e.loadingPCA,label:"Draw PCA"},on:{click:function(t){return e.findPCA()}}})],1)],1)],1):e._e(),t("div",{staticClass:"column is-12"},[t("div",{attrs:{id:"pca_matrix"}}),this.pcaData?t("button",{staticClass:"button is-small mt-1",on:{click:function(t){return e.downloadPCA()}}},[e._v("Download PCA data")]):e._e(),this.pcaData?t("button",{staticClass:"button is-small mt-1",on:{click:function(t){return e.downloadPCAPlot()}}},[e._v("Download plot")]):e._e()])])],1)]),t("div",{staticClass:"message is-info"},[t("div",{staticClass:"message-header p-2"},[e._v("t-distributed stochastic neighbor embedding")]),t("div",{staticClass:"message-body"},[t("b-field",{attrs:{grouped:""}},[t("b-field",{attrs:{label:"Number of Components","label-position":"on-border"}},[t("b-input",{attrs:{size:"is-small",type:"number",placeholder:"Components"},model:{value:e.componentsTSNE,callback:function(t){e.componentsTSNE=t},expression:"componentsTSNE"}})],1),t("b-field",{attrs:{label:"Seed","label-position":"on-border"}},[t("b-input",{attrs:{size:"is-small",type:"number",placeholder:"Seed"},model:{value:e.seedTSNE,callback:function(t){e.seedTSNE=t},expression:"seedTSNE"}}),t("p",{staticClass:"control"},[t("b-button",{attrs:{size:"is-small",type:"is-info",loading:e.loadingTSNE,label:"Fit t-SNE"},on:{click:e.findTSNE}})],1)],1)],1),e._m(2)],1)]),t("div",{staticClass:"message is-info"},[t("div",{staticClass:"message-header p-2"},[e._v("Autoencoder")]),t("div",{staticClass:"message-body"},[t("b-field",{attrs:{grouped:""}},[t("b-field",{attrs:{expanded:""}},[t("b-field",{attrs:{label:"Hidden layers size","label-position":"on-border"}},[t("b-input",{attrs:{size:"is-small",type:"number",placeholder:"Hidden layer size"},model:{value:e.hiddenLayerSize,callback:function(t){e.hiddenLayerSize=t},expression:"hiddenLayerSize"}})],1),t("b-field",{attrs:{label:"x axis","label-position":"on-border"}},[t("b-input",{attrs:{size:"is-small",type:"number",placeholder:"x axis"},model:{value:e.autoEncoderX,callback:function(t){e.autoEncoderX=t},expression:"autoEncoderX"}})],1),t("b-field",{attrs:{label:"y axis","label-position":"on-border"}},[t("b-input",{attrs:{size:"is-small",type:"number",placeholder:"y axis"},model:{value:e.autoEncoderY,callback:function(t){e.autoEncoderY=t},expression:"autoEncoderY"}})],1),t("b-field",{attrs:{label:"iterations","label-position":"on-border"}},[t("b-input",{attrs:{size:"is-small",type:"number",placeholder:"iterations"},model:{value:e.iterations,callback:function(t){e.iterations=t},expression:"iterations"}})],1),t("b-field",{attrs:{label:"encoder","label-position":"on-border"}},[t("b-select",{attrs:{size:"is-small",placeholder:"Encoder Activation Function"},model:{value:e.encoderActivationFunction,callback:function(t){e.encoderActivationFunction=t},expression:"encoderActivationFunction"}},[t("option",{attrs:{value:"linear",id:"linear"}},[e._v(" linear ")]),t("option",{attrs:{value:"sigmoid",id:"sigmoid"}},[e._v(" sigmoid ")]),t("option",{attrs:{value:"relu",id:"relu"}},[e._v(" RELU ")])])],1),t("b-field",{attrs:{label:"decoder","label-position":"on-border"}},[t("b-select",{attrs:{size:"is-small",placeholder:"Decoder Activation Function"},model:{value:e.decoderActivationFunction,callback:function(t){e.decoderActivationFunction=t},expression:"decoderActivationFunction"}},[t("option",{attrs:{value:"linear",id:"linear"}},[e._v(" linear ")]),t("option",{attrs:{value:"sigmoid",id:"sigmoid"}},[e._v(" sigmoid ")]),t("option",{attrs:{value:"relu",id:"relu"}},[e._v(" RELU ")])])],1),t("b-field",{attrs:{"label-position":"on-border"}},[t("p",{staticClass:"control"},[t("b-button",{attrs:{size:"is-small",type:"is-info",loading:e.loadingAutoEncoder,label:"Fit Autoencoder"},on:{click:e.autoEncoder}})],1)])],1)],1),e._m(3)],1)])]):t("section",[t("b-message",{attrs:{type:"is-danger","has-icon":"","icon-pack":"fas"}},[e._v(" There is no data to show. ")])],1)},Fe=[function(){var e=this,t=e._self._c;return t("div",{staticClass:"column is-6"},[t("div",{staticStyle:{height:"300px"},attrs:{id:"scree_plot"}})])},function(){var e=this,t=e._self._c;return t("div",{staticClass:"column is-6"},[t("div",{staticStyle:{height:"300px"},attrs:{id:"correlation_circle"}})])},function(){var e=this,t=e._self._c;return t("div",{staticClass:"column is-6",attrs:{id:"dimensionality_reduction_panel_tsne"}},[t("div",{attrs:{id:"tsne"}})])},function(){var e=this,t=e._self._c;return t("div",{staticClass:"column is-6",attrs:{id:"dimensionality_reduction_panel_tsne"}},[t("div",{staticStyle:{height:"300px"},attrs:{id:"autoencoder"}})])}],Te=s(52494);let $e=new te;var Ne={name:"dmensionality-reduction-component",setup(){const e=y();return{settings:e}},props:{msg:String,dataframe:Object,columns:[]},data(){return{numberOfComponents:2,loadingPCA:!1,loadingTSNE:!1,x:1,y:2,loadingAutoEncoder:!1,hiddenLayerSize:2,componentsTSNE:2,seedTSNE:123,pcaData:null,pcaVarianceData:null,iterations:200,encoderActivationFunction:"linear",decoderActivationFunction:"linear",autoEncoderX:1,autoEncoderY:2,hasPCA:!1,pcaContainers:[],df:null}},methods:{prepareData(){this.df=new g.DataFrame(this.settings.rawData),this.df.dropNa({axis:1,inplace:!0}),this.settings.isClassification&&this.settings.mergedClasses?.length>0&&this.settings.mergedClasses.forEach((e=>{let t=e.map((e=>e.class)).join("_");e.forEach((e=>{this.df.replace(e.class,t,{columns:[this.settings.modelTarget],inplace:!0})}))}))},async drawPCA(){try{this.numberOfComponents=null,await this.findPCA(!0)}catch(e){throw this.loadingPCA=!1,e}},async findPCA(e=!1){try{this.prepareData(),this.loadingPCA=!0,this.pcaContainers=[];let t=this.settings.items.filter((e=>e.selected&&1===e.type)).map((e=>e.name));if(0==e){if(2==this.numberOfComponents)this.pcaContainers.push([1,2]);else if(3==this.numberOfComponents)this.pcaContainers.push([1,2],[1,3],[2,3]);else if(this.numberOfComponents>3){this.pcaContainers.push([1,2],[1,3],[2,3]);for(let e=4;e<=this.numberOfComponents;e++){let t=1;while(t<=e-1)this.pcaContainers.push([t,e]),t++}}}else this.numberOfComponents=t.length;let s=this.df.loc({columns:t}).values,a=await $e.draw_pca(s,this.settings.isClassification,this.df.loc({columns:[this.settings.modelTarget]}).values,this.numberOfComponents,this.pcaContainers,t,e);this.pcaData=a[0],this.pcaVarianceData=a[1],this.hasPCA=!0,this.loadingPCA=!1}catch(t){throw this.loadingPCA=!1,t}},downloadPCAPlot(){$e.downloadPlot("pca_matrix")},downloadPCA(){let e=new g.DataFrame(this.pcaData);(0,Te.$toCSV)(e,{filePath:"pca_data.csv",download:!0})},downloadExplainedVariance(){let e=[];for(let s=1;s<=this.pcaVarianceData.length;s++){const t=this.pcaVarianceData[s-1];e.push({Components:s,ExplainedVariace:t})}let t=new g.DataFrame(e);(0,Te.$toCSV)(t,{filePath:"variance_data.csv",download:!0})},async findTSNE(){try{this.prepareData(),this.loadingTSNE=!0;let e=this.settings.items.filter((e=>e.selected&&1===e.type)).map((e=>e.name));await $e.plot_tsne(this.df.loc({columns:e}).values,this.settings.isClassification,this.df.loc({columns:[this.settings.modelTarget]}).values,this.seedTSNE,this.componentsTSNE),this.loadingTSNE=!1}catch(e){throw this.loadingTSNE=!1,e}},async autoEncoder(){this.prepareData(),this.loadingAutoEncoder=!0;const e=g.tensorflow.sequential();let t=this.settings.items.filter((e=>e.type===z.Numerical.id)).map((e=>e.name)),s=t.length,a=this.settings.df.loc({columns:t}).values;const i=g.tensorflow.layers.dense({units:+this.hiddenLayerSize,batchInputShape:[null,s],activation:this.encoderActivationFunction,kernelInitializer:"glorotNormal",biasInitializer:"zeros"}),n=g.tensorflow.layers.dense({units:s,activation:this.decoderActivationFunction});e.add(i),e.add(n),await e.compile({optimizer:"adam",loss:"meanSquaredError"});const r=g.tensorflow.tensor2d(a);await e.fit(r,r,{epochs:+this.iterations,batchSize:64,shuffle:!1,validationSplit:.1});r.dispose();const o=g.tensorflow.tidy((()=>{const e=g.tensorflow.sequential();e.add(i);let t=g.tensorflow.tensor2d(a),s=e.predict(t);return t.dispose(),s.arraySync()}));let l=await o;$e.drawAutoencoder(l,this.autoEncoderX-1,this.autoEncoderY-1,this.df.loc({columns:[this.settings.modelTarget]}).values,this.settings.isClassification),this.loadingAutoEncoder=!1}},errorCaptured(){}},De=Ne,qe=(0,C.A)(De,Ee,Fe,!1,null,null,null),Me=qe.exports,Ie=function(){var e=this,t=e._self._c;return t("div",[this.settings.results?.length>0?t("b-tabs",{on:{input:e.resize},model:{value:e.activeResult,callback:function(t){e.activeResult=t},expression:"activeResult"}},[t("b-tab-item",{attrs:{label:"Comparison"},on:{click:function(t){return e.compareResultsDraw()}}},[e._l(e.metricsCollection,(function(s,a){return t("button",{key:a,staticClass:"button is-small ml-1 is-success my-2",on:{click:function(t){return e.compareResultsDraw(s)}}},[e._v(e._s(s.name+"-"+(s.task?"cls":"reg")))])})),t("div",{staticClass:"message is-info"},[t("div",{staticClass:"message-header p-2"},[e._v(" Methods Comparison ")]),t("div",{staticClass:"message-body"},[t("div",{staticClass:"columns is-multiline is-gapless"},e._l(e.metrics,(function(e,s){return t("div",{key:s,staticClass:"column is-4"},[t("div",{staticClass:"column is-4"},[t("div",{attrs:{id:s}})])])})),0)])]),t("div",{directives:[{name:"show",rawName:"v-show",value:e.compare,expression:"compare"}],staticClass:"column is-12",staticStyle:{height:"400px"},attrs:{id:"comaprison_plot"}})],2),e._l(this.settings.results,(function(s){return[t("b-tab-item",{key:s.id,attrs:{label:s.id+"."+s.name.toString()}},[s.modelTask?t("classification-view-component",{attrs:{result:s},on:{"delete-result":e.deleteResult}}):t("regression-view-component",{attrs:{result:s},on:{"delete-result":e.deleteResult}}),t("div",{staticClass:"column is-12"},[s.useHPC?e._e():t("div",{staticClass:"table-container"},[t("table",{staticClass:"table is-bordered is-hoverable is-narrow display is-size-7",attrs:{id:"predictions_table_"+s.id,width:"100%"}})])])],1)]}))],2):t("b-message",{attrs:{type:"is-danger","has-icon":"","icon-pack":"fas"}},[e._v(" No result to show. ")])],1)},Re=[],Oe=function(){var e=this,t=e._self._c;return t("article",{staticClass:"columns is-multiline"},[t("div",{staticClass:"column is-12 mb-1"},[t("b-message",{staticClass:"has-text-left",attrs:{type:"is-info ","has-icon":"","icon-pack":"fas"}},[t("p",{staticClass:"my-1 is-size-7"},[t("span",[e._v("Dataset Name : "+e._s(e.result.datasetName)+" , ")]),t("span",[e._v(" Target variable : "+e._s(e.result.target))])]),t("p",{staticClass:"subtitle is-6 my-1 is-size-7"},[e._v("Features :")]),t("p",{staticClass:"ml-2 my-1 subtitle is-6 is-size-7"},[e._v("Categorical Features : "),e._l(e.result.categoricalFeatures,(function(s){return t("span",{key:s},[e._v(" "+e._s(s+", ")+" ")])}))],2),t("p",{staticClass:"ml-2 my-1 subtitle is-6 is-size-7"},[e._v("Numerical Features : "),e._l(e.result.numericColumns,(function(s){return t("span",{key:s},[e._v(" "+e._s(s+", ")+" ")])}))],2),t("p",{directives:[{name:"show",rawName:"v-show",value:e.result.transformations?.length>0,expression:"result.transformations?.length > 0"}],staticClass:"ml-2 my-1 subtitle is-6 is-size-7"},[e._v("Transformations : "),e._l(e.result.transformations,(function(s){return t("span",{key:s.name},[e._v(" "+e._s(s.name+": "+s.scalerLabel+",")+" ")])}))],2),e._l(e.result.options,(function(s,a){return t("p",{key:a,staticClass:"is-size-7"},[e._v(" "+e._s(a)+": "+e._s(s["value"])+" ")])})),t("p",{staticClass:"subtitle my-1 is-size-7"},[e._v("Goodness of Fit :")]),t("p",{staticClass:"ml-2 my-1 subtitle is-size-7"},[e._v("Accuracy : "+e._s(e.result.metrics?.accuracy?.toFixed(2)))]),t("p",{staticClass:"ml-2 my-1 subtitle is-size-7"},[e._v("f1 micro : "+e._s(e.result.metrics?.f1_micro?.toFixed(2)))]),t("p",{staticClass:"ml-2 my-1 subtitle is-size-7"},[e._v(" f1 macro :"+e._s(e.result.metrics?.f1_macro?.toFixed(2)))]),t("button",{staticClass:"button is-danger has-text-white is-small",staticStyle:{color:"#fff !important"},on:{click:function(t){return e.deleteTab()}}},[e._v("Delete ")]),t("button",{staticClass:"button is-success is-small",on:{click:function(t){return e.toggleHelp(e.result.helpSectionId)}}},[e._v("Method description ")]),t("button",{staticClass:"button is-info is-small",on:{click:function(t){return e.downloadPythonCode()}}},[e._v("Download the code")])],2)],1),e.hide?[e._v(" In progress... ")]:[t("div",{staticClass:"column is-12"},[t("article",{staticClass:"message is-info"},[t("div",{staticClass:"message-header p-2"},[e._v(" Confusion Matrix and PCA of predictions")]),t("div",{staticClass:"message-body mx-1"},[t("div",{staticClass:"columns is-multiline is-gapless"},[t("div",{staticClass:"column is-6 my-1",staticStyle:{height:"400px"},attrs:{id:"confusion_matrix_"+e.result.id}}),t("div",{directives:[{name:"show",rawName:"v-show",value:e.result.showProbas,expression:"result.showProbas"}],staticClass:"column is-6 my-1",staticStyle:{height:"400px"},attrs:{id:"proba_plot_"+e.result.id}}),t("br"),t("div",{directives:[{name:"show",rawName:"v-show",value:e.result.showProbas,expression:"result.showProbas"}],staticClass:"column is-6 my-1",staticStyle:{height:"400px"},attrs:{id:"roc_plot_"+e.result.id}}),t("div",{directives:[{name:"show",rawName:"v-show",value:e.result.hasExplaination&&1!==e.result.if,expression:"result.hasExplaination && result.if !== 1"}],staticClass:"column is-6 my-1",staticStyle:{height:"400px"},attrs:{id:"pfi_boxplot_"+e.result.id}})])])])]),e.result.name.includes("Logi.Reg")?t("div",{staticClass:"column is-12"},[t("div",{staticClass:"columns is-multiline"},[t("div",{staticClass:"column is-7"},[t("div",{staticClass:"table-container"},[t("table",{staticClass:"table has-text-centered nowrap is-striped is-bordered is-narrow is-hoverable is-size-7",attrs:{id:"metrics_table_"+e.result.id}},[e._m(0),e._m(1)])])]),t("div",{staticClass:"column is-5",attrs:{id:"parameters_plot_"+e.result.id}}),t("div",{staticClass:"column is-6",staticStyle:{height:"250px"},attrs:{id:"errors_"+e.result.id}}),t("div",{staticClass:"column is-6",staticStyle:{height:"250px"},attrs:{id:"regularization_"+e.result.id}})])]):e._e(),t("div",{directives:[{name:"show",rawName:"v-show",value:e.result.hasExplaination&&!e.result.name.includes("Logi.Reg"),expression:"result.hasExplaination && !result.name.includes('Logi.Reg')"}],staticClass:"column is-12"},[t("article",{staticClass:"message is-info"},[t("div",{staticClass:"message-header p-2"},[e._v(" Partial Dependence Plot")]),t("div",{staticClass:"message-body mx-1"},[t("div",{staticClass:"columns is-multiline is-gapless"},[e.result.name.toString().toLowerCase().includes("knn")?t("div",{staticClass:"column is-6",staticStyle:{height:"400px"},attrs:{id:"knn_table_"+e.result.id}}):e._e(),t("div",{attrs:{id:"pdp_containers_"+e.result.id}})]),t("br")])])])]],2)},Le=[function(){var e=this,t=e._self._c;return t("thead",[t("tr",[t("th",{attrs:{colspan:"1"}}),t("th",{staticClass:"has-text-centered",attrs:{colspan:"3"}},[e._v("OLS")]),t("th",{staticClass:"has-text-centered",attrs:{colspan:"3"}},[e._v("lambda min")]),t("th",{staticClass:"has-text-centered",attrs:{colspan:"3"}},[e._v("lambda 1se")])]),t("tr",[t("th",{staticClass:"has-text-centered"},[e._v("name")]),t("th",[e._v("coef")]),t("th",[e._v("st.d.")]),t("th",[t("i",[e._v("p")]),e._v("-value")]),t("th",[e._v("coef")]),t("th",[e._v("st.d.")]),t("th",[t("i",[e._v("p")]),e._v("-value")]),t("th",[e._v("coef")]),t("th",[e._v("st.d.")]),t("th",[t("i",[e._v("p")]),e._v("-value")])])])},function(){var e=this,t=e._self._c;return t("tfoot",{staticClass:"has-text-centered",staticStyle:{"font-weight":"normal"}},[t("tr",[t("th"),t("th",{staticClass:"has-text-centered",attrs:{colspan:"3"}}),t("th",{staticClass:"has-text-centered",attrs:{colspan:"3"}}),t("th",{staticClass:"has-text-centered",attrs:{colspan:"3"}})])])}],Xe={setup(){const e=y();return{settings:e}},created(){this.pdpFeature=this.settings.features[0].name},data(){return{pdpFeature:null,hide:!1,fileName:null,showResult:!0,intervalId:null,jobProgressTries:0}},name:"ClassificationViewComponent",methods:{upload(){let e=this,t=new FormData,s=(0,g.concat)({dfList:[this.result.snapshot.x,this.result.snapshot.xt],axis:0}),a=this.result.snapshot.y.concat(this.result.snapshot.yt);s.addColumn(this.result.target,a,{inplace:!0});let i=(0,Te.$toCSV)(s,{filePath:"pca_data.csv"});const n=new Blob([i],{type:"text/csv"});return t.append("file",n,"main.csv"),we.A.post("http://127.0.0.1:5000/upload",t,{headers:{"Content-Type":"multipart/form-data"}}).then((function(t){e.fileName=t.data,console.log("SUCCESS!!",e.fileName),we.A.get(`http://127.0.0.1:5000/run?file_name=${e.fileName}&job_id=${e.result.useHPC}&target=${e.result.target}&seed=${e.result.seed}`).then((()=>{e.intervalId=setInterval((()=>{we.A.get(`http://127.0.0.1:5000/progress?job_id=${e.result.useHPC}`).then((t=>{e.jobProgressTries+=1,"ongoing"!=t.data?(e.hide=!1,e.result.model.predictions=t.data.predictions,e.result.model.pdp_averages=t.data.pdp_avgs,e.result.model.pdp_grid=t.data.pdp_grid,e.result.model.importances=t.data.pfi,e.result.model.fpr=t.data.fprs,e.result.model.tpr=t.data.tprs,e.result.model.auc=t.data.auc,e.result.model.probas=t.data.probas,e.result.model.visualize(e.result.snapshot.xt,e.result.snapshot.yt,e.result.snapshot.labels,t.data.predictions,e.result.encoder,e.result.snapshot.x.columns,e.result.snapshot.categoricals),clearInterval(e.intervalId)):e.jobProgressTries>100&&clearInterval(e.intervalId)}))}),3e3)})).catch((function(e){console.log("FAILURE!!",e.data)}))})).catch((function(){console.log("FAILURE!!")}))},toggleHelp(e){this.settings.setActiveTab(3),setTimeout((()=>{let t=document.getElementById(e);t.scrollIntoView({behavior:"smooth"})}),500)},deleteTab(){this.$emit("delete-result",this.result.id)},downloadPythonCode(){let e=new ve,t=e.createModel(this.result.snapshot.id,this.result.options),s=t.generatePythonCode();const a=new Blob([s],{type:"text/plain"}),i=URL.createObjectURL(a),n=document.createElement("a");n.href=i,n.download="example.py",document.body.appendChild(n),n.click(),document.body.removeChild(n),URL.revokeObjectURL(i)},async updatePartialDependencePlot(){let e=new ve,t=e.createModel(this.result.snapshot.id,this.result.options);await t.train(this.result.snapshot.x,this.result.snapshot.y,this.result.snapshot.xt,this.result.snapshot.yt,this.result.snapshot.xFeatures,this.result.snapshot.categoricals,this.result.snapshot.xFeatures.findIndex((e=>e==this.pdpFeature))),t.chartController.plotPDP(this.result.id,t.pdp_averages,t.pdp_grid,this.result.snapshot.labels,this.pdpFeature)}},props:{result:{}},watch:{result:{handler(){this.result.useHPC&&(this.hide=!0,this.upload())},immediate:!0}},errorCaptured(e,t,s){return console.log(`cat EC: ${e.toString()}\ninfo: ${s}`),!1},unmounted(){clearInterval(this.intervalId)}},je=Xe,Be=(0,C.A)(je,Oe,Le,!1,null,"623b210b",null),Ge=Be.exports,Ue=function(){var e=this,t=e._self._c;return t("div",{staticClass:"columns is-multiline"},[t("div",{staticClass:"column is-12"},[t("b-message",{staticClass:"has-text-left",attrs:{type:"is-info is-size-7\t","has-icon":"","icon-pack":"fas"}},[t("p",{staticClass:"my-1"},[t("span",[e._v("Dataset Name : "+e._s(e.result.datasetName)+" , ")]),t("span",[e._v(" Target variable : "+e._s(e.result.target))])]),t("p",{staticClass:"subtitle is-size-7 my-1"},[e._v("Features :")]),t("p",{staticClass:"ml-2 my-1 subtitle is-size-7"},[e._v("Categorical Features : "),e._l(e.result.categoricalFeatures,(function(s){return t("span",{key:s},[e._v(" "+e._s(s+", ")+" ")])}))],2),t("p",{staticClass:"ml-2 my-1 subtitle is-size-7"},[e._v("Numerical Features : "),e._l(e.result.numericColumns,(function(s){return t("span",{key:s},[e._v(" "+e._s(s+", ")+" ")])}))],2),t("p",{staticClass:"ml-2 my-1 subtitle is-size-7"},[e._v("Transformations : "),e._l(e.result.transformations,(function(s){return t("span",{key:s.name},[e._v(" "+e._s(s.name+": "+s.scaler+",")+" ")])}))],2),e._l(e.result.options,(function(s,a){return t("p",{key:a},[e._v(" "+e._s(a)+": "+e._s(s["value"])+" ")])})),t("p",{staticClass:"subtitle is-size-7 my-1"},[e._v("Goodness of Fit :")]),t("p",{staticClass:"ml-2 my-1 subtitle is-size-7"},[e._v("MSE : "+e._s(e.result.metrics.mse.toFixed(2)))]),t("p",{staticClass:"ml-2 my-1 subtitle is-size-7"},[e._v("R2 : "+e._s(e.result.metrics.rsquared.toFixed(2)))]),t("button",{staticClass:"button is-danger has-text-white is-small",on:{click:function(t){return e.deleteTab()}}},[e._v("Delete ")]),t("button",{staticClass:"button is-success is-small",on:{click:function(t){return e.toggleHelp(e.result.helpSectionId)}}},[e._v("Help")])],2)],1),e.result.name.includes("Lin.Reg")||e.result.name.includes("Poly.Reg")?t("div",{staticClass:"column is-12"},[t("div",{staticClass:"columns is-multiline is-gapless"},[t("div",{staticClass:"column is-7"},[t("div",{staticClass:"table-container"},[t("table",{staticClass:"table has-text-centered nowrap is-striped is-bordered is-narrow is-hoverable is-size-7",attrs:{id:"metrics_table_"+e.result.id}},[e._m(0),e._m(1)])])]),t("div",{staticClass:"column is-5",attrs:{id:"parameters_plot_"+e.result.id,width:"100%"}}),t("div",{staticClass:"column is-12 mb-2"},[t("div",{staticClass:"message is-info"},[t("div",{staticClass:"message-header p-2"},[e._v(" Regularization Plots ")]),t("div",{staticClass:"message-body"},[t("div",{staticClass:"columns is-multiline is-gapless"},[t("div",{staticClass:"column is-6",staticStyle:{height:"250px"},attrs:{id:"errors_"+e.result.id,width:"100%"}}),t("div",{staticClass:"column is-6",staticStyle:{height:"250px"},attrs:{id:"regularization_"+e.result.id,width:"100%"}})])])])]),t("div",{staticClass:"message is-info"},[t("div",{staticClass:"message-header p-2"},[e._v(" Residuals Plots ")]),t("div",{staticClass:"message-body"},[t("div",{staticClass:"columns is-multiline is-gapless"},[t("div",{staticClass:"column is-4"},[t("div",{staticStyle:{height:"300px"},attrs:{id:"regression_y_yhat_"+e.result.id,width:"100%"}})]),t("div",{staticClass:"column is-4"},[t("div",{staticStyle:{height:"300px"},attrs:{id:"regression_y_yhat_min_"+e.result.id,width:"100%"}})]),t("div",{staticClass:"column is-4"},[t("div",{staticStyle:{height:"300px"},attrs:{id:"regression_y_yhat_1se_"+e.result.id,width:"100%"}})]),t("div",{staticClass:"column is-4"},[t("div",{staticStyle:{height:"300px"},attrs:{id:"regression_residual_"+e.result.id,width:"100%"}})]),t("div",{staticClass:"column is-4"},[t("div",{staticStyle:{height:"300px"},attrs:{id:"regression_residual_min_"+e.result.id,width:"100%"}})]),t("div",{staticClass:"column is-4"},[t("div",{staticStyle:{height:"300px"},attrs:{id:"regression_residual_1se_"+e.result.id,width:"100%"}})]),t("div",{staticClass:"column is-4"},[t("div",{staticStyle:{height:"300px"},attrs:{id:"qqplot_ols_"+e.result.id,width:"100%"}})]),t("div",{staticClass:"column is-4"},[t("div",{staticStyle:{height:"300px"},attrs:{id:"qqplot_min_"+e.result.id,width:"100%"}})]),t("div",{staticClass:"column is-4"},[t("div",{staticStyle:{height:"300px"},attrs:{id:"qqplot_1se_"+e.result.id,width:"100%"}})])])])])])]):t("div",{staticClass:"column is-12"},[t("div",{staticClass:"columns is-multiline is-gapless"},[t("div",{staticClass:"column is-12"},[t("article",{staticClass:"message is-info"},[t("div",{staticClass:"message-header p-2"},[e._v(" Predictions and Residuals Plot ")]),t("div",{staticClass:"message-body"},[t("div",{staticClass:"columns is-multiline is-gapless"},[t("div",{staticClass:"column is-6"},[t("div",{staticStyle:{height:"300px"},attrs:{id:"regression_y_yhat_"+e.result.id,width:"100%"}})]),t("div",{staticClass:"column is-6"},[t("div",{staticStyle:{height:"300px"},attrs:{id:"errors_"+e.result.id,width:"100%"}})]),e.result.name.toString().toLowerCase().includes("knn")?t("div",{staticClass:"column is-6",staticStyle:{height:"350px"},attrs:{id:"knn_table_"+e.result.id}}):e._e()])])])]),t("div",{staticClass:"column is-12"},[t("article",{staticClass:"message is-info"},[t("div",{staticClass:"message-header p-2"},[e._v(" Partial Dependence Plot and Permutation Feature Importance ")]),t("div",{staticClass:"message-body"},[t("div",{staticClass:"columns is-multiline is-gapless"},[t("div",{directives:[{name:"show",rawName:"v-show",value:e.result.hasExplaination,expression:"result.hasExplaination"}],staticClass:"column is-6",staticStyle:{height:"400px"},attrs:{id:"pfi_boxplot_"+e.result.id}})])])])])])])])},Je=[function(){var e=this,t=e._self._c;return t("thead",[t("tr",[t("th",{attrs:{colspan:"1"}}),t("th",{staticClass:"has-text-centered",attrs:{colspan:"3"}},[e._v("OLS")]),t("th",{staticClass:"has-text-centered",attrs:{colspan:"3"}},[e._v("lasso min")]),t("th",{staticClass:"has-text-centered",attrs:{colspan:"3"}},[e._v("lasso 1se")])]),t("tr",[t("th",{staticClass:"has-text-centered"},[e._v("names")]),t("th",[e._v("coef")]),t("th",[e._v("st.d.")]),t("th",[t("i",[e._v("p")]),e._v("-value")]),t("th",[e._v("coef")]),t("th",[e._v("st.d.")]),t("th",[t("i",[e._v("p")]),e._v("-value")]),t("th",[e._v("coef")]),t("th",[e._v("st.d.")]),t("th",[t("i",[e._v("p")]),e._v("-value")])])])},function(){var e=this,t=e._self._c;return t("tfoot",{staticStyle:{"font-weight":"normal"}},[t("tr",[t("th"),t("th",{staticClass:"has-text-centered",attrs:{colspan:"3"}}),t("th",{staticClass:"has-text-centered",attrs:{colspan:"3"}}),t("th",{staticClass:"has-text-centered",attrs:{colspan:"3"}})])])}],He={setup(){const e=y();return{settings:e}},name:"regression-view-component",methods:{toggleHelp(e){this.settings.setActiveTab(3),setTimeout((()=>{let t=document.getElementById(e);t.scrollIntoView({behavior:"smooth"})}),500)},deleteTab(){this.$emit("delete-result",this.result.id)},async updatePartialDependencePlot(){let e=new ve,t=e.createModel(this.result.snapshot.id,this.result.options);await t.train(this.result.snapshot.x,this.result.snapshot.y,this.result.snapshot.xt,this.result.snapshot.yt,this.result.snapshot.xFeatures,this.result.snapshot.categoricals,[0,1,2]),t.chartController.plotPDPRegression(this.result.id,t.pdp_averages,t.pdp_grid,this.result.snapshot.labels,this.result.snapshot.xFeatures,this.result.snapshot.categoricals)}},created(){this.pdpFeature=this.settings.features.filter((e=>e.name!=this.settings.target))[0].name},data(){return{pdpFeature:null,showResult:!0}},props:{result:{}}},Ve=He,We=(0,C.A)(Ve,Ue,Je,!1,null,"2946f9e4",null),Qe=We.exports;let Ke=new te(null,null),Ye=new se(null,null);var Ze={components:{"classification-view-component":Ge,"regression-view-component":Qe},setup(){const e=y(),t=(0,a.EW)({get:()=>e.getResultTab,set:t=>e.setResultActiveTab(t)});return{settings:e,activeResult:t}},name:"ResultsComponent",props:{},data(){return{metricsCollection:[],compare:!1,datasetName:"",isClassication:-1,comparisonMetric:"",baseMetrics:[],activeTab:null,visitedTabs:[],metrics:{},xTicks:{}}},methods:{fillMetrics(){1==this.isClassication?this.baseMetrics=[{name:"accuracy",id:1},{name:"f1 micro",id:2},{name:"f1 macro",id:3}]:0==this.isClassication&&(this.baseMetrics=[{name:"R2",id:1},{name:"MSE",id:0}])},compareResults(e){let t=this.settings.datasetName,s=this.settings.classificationTask;try{M().purge("comaprison_plot")}catch(r){console.log("no plot to remove")}e&&(t=e.name,s=e.task);let a=this.settings.getMethodResults.filter((e=>e.datasetName==t&&s==e.modelTask));this.compare=!0;let i=[],n={};a.forEach(((e,t)=>{let s=e.metrics;0===t&&i.push("Theoretical best"),i.push(e.id+"."+e.name);for(const a in e.metrics)if("precision"!=a&&"recall"!=a){const e=s[a];a in n||(n[a]=[],n[a].push(1)),n[a].push(e)}})),this.metrics=n,this.xTicks=i},draw(){for(const e in this.metrics)Ke.comparison(this.xTicks,this.metrics[e],e,e)},compareResultsDraw(e){let t=[];this.compareResults(e);for(let s=0;s<this.settings.getMethodResults.length;s++){const e=this.settings.getMethodResults[s];let a=t.findIndex((t=>t.task===e.modelTask&&t.name===e.datasetName));-1==a&&t.push({name:e.datasetName,task:e.modelTask})}this.metricsCollection=t,setTimeout((()=>{this.draw()}),500)},resize(e){0===e&&this.compareResultsDraw(),window.dispatchEvent(new Event("resize"))},deleteResult(e){let[t,s]=this.settings.getResultVisualizations(e);t.forEach((e=>{Ye.removeTable(e)})),s.forEach((e=>{M().purge(e)})),this.settings.removeResult(e)},showMethodDetails(e){alert(e)}}},et=Ze,tt=(0,C.A)(et,Ie,Re,!1,null,"0517c548",null),st=tt.exports,at=function(){var e=this,t=e._self._c;return t("section",{staticStyle:{"overflow-y":"auto","overflow-x":"auto"}},[t("article",{staticClass:"message is-info"},[t("div",{staticClass:"message-header p-2"},[e._v("Scatterplot Matrix "),t("b-tooltip",{attrs:{"append-to-body":"",label:"nrd method and guassian kernel is used for kernel density estimation.",multilined:""}},[t("b-button",{attrs:{"icon-left":"info","icon-pack":"fas",size:"is-small",type:"is-dark"}})],1)],1),t("div",{staticClass:"message-body"},[t("div",{attrs:{id:"scatterplot_mtx"}}),t("button",{staticClass:"button is-small",on:{click:function(t){return e.downlaodSPLOM()}}},[e._v("Download plot")]),t("div",{staticClass:"columns my-1 ml-5 mt-5 is-multiline",style:{width:100*e.features.length+"px"}},[e._l(this.settings.items.filter((e=>e.selected)),(function(s){return t("div",{key:s.id,style:{width:e.column_width+"%"}},[1==s.type?t("b-field",{staticClass:"ml-1",attrs:{label:s.name,"label-position":"on-border"}},[t("b-select",{attrs:{size:"is-small"},on:{input:function(t){return e.scaleData()}},model:{value:s.scaler,callback:function(t){e.$set(s,"scaler",t)},expression:"feature.scaler"}},e._l(e.ScaleOptions,(function(s){return t("option",{key:s.id,domProps:{value:s.id}},[e._v(" "+e._s(s.name)+" ")])})),0)],1):t("p",{staticClass:"title is-size-7 mt-1"},[e._v(e._s(s.name))])],1)})),t("br")],2),t("div",{staticClass:"column is-12"},[t("parallel-coordinate-plot-component",{ref:"coordinate_plot"})],1),this.settings.isClassification?t("div",{staticClass:"column is-12"},[t("h5",{staticClass:"title is-7 has-text-left"},[e._v("Merge classes ")]),t("b-table",{staticClass:"is-size-7",attrs:{data:e.classesInfo,columns:e.classesInfoColumns,checkable:"","row-class":(e,t)=>e.mode<=.1&&"has-text-danger",narrowed:!0,"checked-rows":e.selectedClasses},on:{"update:checkedRows":function(t){e.selectedClasses=t},"update:checked-rows":function(t){e.selectedClasses=t}}}),t("button",{staticClass:"button mt-2 is-info is-small",attrs:{disabled:e.selectedClasses?.length>=e.classesInfo?.length},on:{click:function(t){return e.scaleData()}}},[e._v("Merge Classes")]),t("button",{staticClass:"button mt-2 mx-1 is-success is-small",on:{click:function(t){return e.scaleData(!0)}}},[e._v("reset")])],1):e._e(),t("b-loading",{attrs:{"is-full-page":!1},model:{value:e.isLoading,callback:function(t){e.isLoading=t},expression:"isLoading"}})],1)])])},it=[],nt=function(){var e=this;e._self._c;return e._m(0)},rt=[function(){var e=this,t=e._self._c;return t("section",{staticClass:"my-1"},[t("article",{staticClass:"message"},[t("div",{staticClass:"message-header p-2"},[e._v("Parallel Coordinate Plot")]),t("div",{staticClass:"message-body"},[t("div",{attrs:{id:"parallel_coordinate_plot"}})])])])}];let ot=new te;var lt={setup(){const e=y();return{settings:e}},name:"ParallelCoordinatePlotComponent",props:{msg:String,update:{}},data(){return{isLoading:!1,ScaleOptions:P,features:[],df:null,rawData:null}},methods:{ParallelCoordinatePlot(){this.isLoading=!0;const e=new g.DataFrame(this.settings.rawData);this.settings.isClassification&&this.settings.classTransformations.length>0&&this.settings.mergedClasses.forEach((t=>{let s=t.map((e=>e.class)).join("_");t.forEach((t=>{e.replace(t.class,s,{columns:[this.settings.modelTarget],inplace:!0})}))}));let t=this.settings.items.filter((e=>e.selected&&1===e.type));M().purge("parallel_coordinate_plot"),U(e,t.map((e=>e.name)),t);let s=this.settings.items.filter((e=>e.selected&&1===e.type)).map((e=>e.name));ot.parallelCoordinatePlot(e.loc({columns:s}).values,e.column(this.settings.modelTarget).values,s,this.settings.isClassification),this.isLoading=!1}}},ct=lt,dt=(0,C.A)(ct,nt,rt,!1,null,"6a472437",null),mt=dt.exports;let pt=new te;var ut={components:{"parallel-coordinate-plot-component":mt},setup(){const e=y();return{settings:e}},name:"ScatterplotMatrixComponent",props:{msg:String,update:{}},data(){return{isLoading:!1,ScaleOptions:P,features:[],df:null,rawData:null,classesInfo:[],selectedClasses:[],classesInfoColumns:[]}},methods:{downlaodSPLOM(){pt.downloadPlot("scatterplot_mtx")},updateClassesInfo(){this.df=new g.DataFrame(this.settings.rawData),this.settings.mergedClasses.forEach((e=>{let t=e.map((e=>e.class)).join("_");e.forEach((e=>{this.df.replace(e.class,t,{columns:[this.settings.modelTarget],inplace:!0})}))}));let e=this.df.column(this.settings.modelTarget).values,t=e.length,s=new Set(...[e]),a=[];s.forEach((s=>{a.push({class:s,mode:+(e.filter((e=>e===s)).length/t).toFixed(2)})})),this.classesInfo=a.concat(),this.classesInfoColumns=[{field:"class",label:" class"},{field:"mode",label:"Samples in each class (%)"}]},async dispalySPLOM(e){try{this.isLoading=!0;let t=this.settings.items.filter((e=>e.selected&&1===e.type)).map((e=>e.name)),s=this.settings.items.filter((e=>e.selected&&1!==e.type)).map((e=>e.name)),a=t.concat(s);e.dropNa({axis:1,inplace:!0}),console.log(new Set(e.column(this.settings.modelTarget).values)),await pt.ScatterplotMatrix(e.loc({columns:a}).values,a,e.column(this.settings.modelTarget).values,s.length,this.settings.isClassification,t,s,this.dataframe),this.settings.isClassification&&this.updateClassesInfo(),this.$refs.coordinate_plot?.ParallelCoordinatePlot(),this.isLoading=!1}catch(t){let e="Something went wrong drawing data analysis plots";this.$buefy.toast.open(e),this.settings.addMessage({message:e,type:"warning"})}},async scaleData(e=!1){if(this.df=new g.DataFrame(this.settings.rawData),e&&(this.settings.resetClassTransformations([]),this.updateClassesInfo(),console.log(this.settings.mergedClasses)),this.settings.isClassification&&this.selectedClasses?.length>0){let e=this.selectedClasses.map((e=>e.class)).join("_");this.selectedClasses.forEach((t=>{this.df.replace(t.class,e,{columns:[this.settings.modelTarget],inplace:!0})})),this.settings.setClassTransformation(this.selectedClasses);let t={message:"merged classes: "+e,type:"info"};this.$buefy.toast.open("merged classes: "+e),this.settings.addMessage(t)}let t=this.settings.items.filter((e=>e.selected&&1===e.type&&0!=e.scaler));if(this.isLoading=!0,M().purge("scatterplot_mtx"),this.updateClassesInfo(),U(this.df,t.map((e=>e.name)),t),await this.dispalySPLOM(this.df),this.isLoading=!1,this.selectedClasses=[],t.length>0){let e=[];t.forEach((t=>{let s=Object.keys(P).find((e=>P[e].id==t.scaler));t.scalerLabel=s,this.settings.addTransformation(t),e.push(`feature: ${t["name"]} ,scaler: ${t["scalerLabel"]} `)}));let s={message:"scaled fetures: <br> "+e.join("_"),type:"info"};this.$buefy.toast.open("scaled fetures: "+e),this.settings.addMessage(s)}else this.settings.resetTransformations();this.$emit("coordinate-plot",!0)},async initSPLOM(){this.df=new g.DataFrame(this.settings.rawData),this.df=await this.df.sample(this.df.$data.length,{seed:this.settings.getSeed}),this.df.dropNa({axis:1,inplace:!0});let e=this.settings.items.filter((e=>e.selected&&1===e.type)).map((function(e){return{name:e.name,type:e.type}})),t=this.settings.items.filter((e=>e.selected&&1!==e.type)).map((function(e){return{name:e.name,type:e.type}})),s=e.concat(t);this.features=s.map(((e,t)=>({id:t,name:e.name,type:e.type,scaler:0}))),this.dispalySPLOM(this.df)}},created:async function(){await this.initSPLOM()},computed:{column_width:{get(){return 0===this.features.length?0:100/this.features.length}}}},ht=ut,_t=(0,C.A)(ht,at,it,!1,null,"35ba048a",null),ft=_t.exports,gt=function(){var e=this,t=e._self._c;return t("section",{staticClass:"has-text-left content"},[t("h4",{staticClass:"title is-medium is-5",attrs:{id:"help"}},[e._v("Classification metrics ")]),t("p",[e._v(" In a context of a binary classification, here are the main metrics that are important to track in order to assess the performance of the model. ")]),e._m(0),t("h4",{staticClass:"title is-medium is-5"},[e._v("Regression metrics ")]),t("ul",[t("li",[e._v(" Basic metricsGiven a regression model "),t("i",[e._v("f")]),e._v(", the following metrics are commonly used to assess the performance of the model: "),t("table",{staticClass:"table is-bordered"},[e._m(1),t("tbody",[t("tr",[t("td",[t("vue-mathjax",{attrs:{formula:"$$ SS_{tot}= \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2$$"}})],1),t("td",[t("vue-mathjax",{attrs:{formula:"$$ SS_{reg}= \\sum_{i=1}^{m} (f (x_i) - \\hat{y}_i)^2$$"}})],1),t("td",[t("vue-mathjax",{attrs:{formula:"$$ SS_{res}= \\sum_{i=1}^{m} (y_i - f (x_i))^2$$"}})],1)])])])]),t("li",[e._v(" Coefficient of determination: The coefficient of determination, often noted "),t("i",[e._v("R")]),t("sup",[e._v("2")]),e._v(" , provides a measure of how well the observed outcomes are replicated by the model and is defined as follows: "),t("vue-mathjax",{attrs:{formula:"$$ R^2 = 1 - \\frac{SS_{res}}{SS_{tot}}$$"}})],1),t("li",[e._v(" Main metrics: The following metrics are commonly used to assess the performance of regression models, by taking into account the number of variables n that they take into consideration: "),t("table",{staticClass:"table is-bordered"},[e._m(2),t("tbody",[t("tr",[t("td",[t("vue-mathjax",{attrs:{formula:"$$ 2[n + 2 - \\log (L)]$$"}})],1),t("td",[t("vue-mathjax",{attrs:{formula:"$$ \\log (m)(n + 2) - 2 \\log (L)$$"}})],1),t("td",[t("vue-mathjax",{attrs:{formula:"$$ 1 - \\frac{(1-R^2)(m-1)}{m-n-1}$$"}})],1)])])])])]),t("h4",{staticClass:"title is-medium is-5",attrs:{id:"1_help"}},[e._v("Model Selection ")]),t("h5",[e._v(" When selecting a model, we distinguish 3 different parts of the data that we have as follows: ")]),e._m(3),t("p",[e._v(" Once the model has been chosen, it is trained on the entire dataset and tested on the unseen test set. These are represented in the figure below:")]),t("p",[e._v(" Cross-validation, also noted CV, is a method that is used to select a model that does not rely too much on the initial training set. The different types are summed up in the table below: ")]),e._m(4),e._m(5),t("p",[e._v(" regularization: The regularization procedure aims at avoiding the model to overfit the data and thus deals with high variance issues. The following table sums up the different types of commonly used regularization techniques: ")]),t("h4",{staticClass:"title is-medium is-5"},[e._v("Supervised Learning ")]),e._m(6),t("h4",{staticClass:"title is-medium is-5",attrs:{id:"svm_help"}},[e._v("Support Vector Machine")]),t("p",[e._v(" The goal of support vector machines is to find the line that maximizes the minimum distance to the line. ")]),e._v(" Optimal margin classifier: The optimal margin classifier (h) is such that: "),t("vue-mathjax",{attrs:{formula:"$$ h(x) = sign(w^T x - b) $$"}}),e._v(" where (w,b \\in R^2) is the solution of the following optimization problem: "),t("img",{attrs:{src:"/svm-en.png",height:"150px",width:"70%"}}),t("h4",{staticClass:"title is-medium is-5",attrs:{id:"naive_bayes_help"}},[e._v("Naive Bayes")]),t("ul",[t("li",[e._v(" Assumption: The Naive Bayes model supposes that the features of each data point are all independent: "),t("vue-mathjax",{attrs:{formula:"$$ P(x | y) = P(x_1,x_2,...|y) = P(x_1 |y )  P(x_2 |y ) $$"}})],1)]),t("h4",{staticClass:"title is-medium",attrs:{id:"linear_regression_help"}},[e._v("Linear Regression")]),t("p",[e._v(" Linear regression is a statistical method used to predict a continuous numeric value based on one or more input features. It assumes a linear relationship between the inputs (independent variables) and the output (dependent variable). The model fits a straight line through the data by minimizing the difference between predicted and actual values, often using a method called least squares. The equation of a linear regression model looks like: "),t("vue-mathjax",{attrs:{formula:"$$ y = \\beta_0 x_0+  \\beta_1 x_1 + \\beta_2 x_2+ ...+\\beta_n x_n+ intercept $$"}}),e._v(" Here, y is the predicted value,(x_i) are the input features, and(_i) are the learned coefficients. Linear regression is commonly used in scenarios like predicting house prices, exam scores, or sales revenue. It is evaluated using metrics such as Mean Squared Error (MSE) and R score, and assumes things like normally distributed errors and consistent variance across predictions. ")],1),t("h4",{staticClass:"title is-medium",attrs:{id:"logistic_regression_help"}},[e._v("Logistic Regression")]),t("p",[e._v(" Logistic Regression is used when the output is categorical, especially for binary classification (e.g., yes/no, 0/1). Instead of predicting a continuous value, it predicts the probability that an input belongs to a certain class. To do this, it uses the sigmoid function, which squashes any real number output into a range between 0 and 1: "),t("vue-mathjax",{attrs:{formula:"$$ y= \\frac{1}{1 + e^{-z}} $$"}}),e._v(" where z is the linear combination of inputs (same as in linear regression). If the resulting probability is greater than 0.5, the output is classified as 1; otherwise, it's classified as 0. If the probability is above a certain threshold (usually 0.5), the model classifies the input as one class; otherwise, it classifies it as the other. The output of the model represents the log-odds of the outcome, and logistic regression is evaluated using classification metrics like accuracy, precision, recall, F1 score, and ROC-AUC. Though it shares structural similarity with linear regression, its purpose and behavior are quite different. ")],1),t("h4",{staticClass:"title is-medium",attrs:{id:"polynomial_regression_help"}},[e._v("Polynomial Regression")]),t("p",[e._v(" Polynomial regression is an extension of linear regression that models the relationship between the input variable  x and the output variable  y as an nth-degree polynomial. While linear regression fits a straight line, polynomial regression fits a curved line, which allows it to capture more complex, non-linear patterns in the data. The general form of the equation is: "),t("vue-mathjax",{attrs:{formula:"$$ y = \\beta_0 +  \\beta_1 x + \\beta_2 x^2+ ...+\\beta_n x^n $$"}}),e._v(" Here, the model includes powers of the input variable (like ^2, ^3, etc.) as additional features. For example, a second-degree polynomial (quadratic regression) can model U-shaped or inverted U-shaped curves. Polynomial regression is still considered a linear model in terms of the coefficients, but it allows for non-linear relationships between x and y. It can be very effective for modeling curved trends, but if the degree of the polynomial is too high, it can lead to overfitting, where the model fits the training data too closely and performs poorly on new data. ")],1),t("h4",{staticClass:"title is-medium is-5",attrs:{id:"cart_help"}},[e._v("Tree-based and ensemble methods")]),t("p",[e._v(" These methods can be used for both regression and classification problems. ")]),e._m(7),t("h4",{staticClass:"title is-medium",attrs:{id:"knn_help"}},[e._v("(k)-nearest neighbors")]),t("p",[e._v(" (k)-nearest neighbors: The (k)-nearest neighbors algorithm, commonly known as (k)-NN, is a non-parametric approach where the response of a data point is determined by the nature of its (k) neighbors from the training set. It can be used in both classification and regression settings. ")]),t("img",{staticClass:"image",attrs:{src:"/knn.png"}}),t("h4",{staticClass:"title is-medium",attrs:{id:"discriminant_analysis_help"}},[e._v(" Gaussian Discriminant Anallysis ")]),t("p",[e._v(" Gaussian Discriminant Analysis SettingThe Gaussian Discriminant Analysis assumes that (y) and (x  y = 0) and (x|y = 1) are such that: "),t("vue-mathjax",{attrs:{formula:"$$ y \\sim Bernoulli(\\phi)   ,   x|y = 0 \\sim \\mathcal{N(\\mu_0,\\Sigma)}$$"}})],1),t("h4",[e._v("Partial Dependence Plot")]),t("p",[e._v(" The partial dependence plot (short PDP or PD plot) shows the marginal effect one or two features have on the predicted outcome of a machine learning model. A partial dependence plot can show whether the relationship between the target and a feature is linear, monotonic or more complex. For example, when applied to a linear regression model, partial dependence plots always show a linear relationship. The partial dependence function for regression is defined as: "),t("vue-mathjax",{attrs:{formula:"$$ f_s(x_s) = \\int{f(x_s,x_c)dP(x_c)}$$"}}),e._v(" The x"),t("sub",[e._v("s")]),e._v(" are the features for which the partial dependence function should be plotted and X"),t("sub",[e._v("c")]),e._v(" are the other features used in the machine learning model ^ f , which are here treated as random variables. Usually, there are only one or two features in the set S. The feature(s) in S are those for which we want to know the effect on the prediction. The feature vectors X"),t("sub",[e._v("s")]),e._v(" and X"),t("sub",[e._v("c")]),e._v(" combined make up the total feature space x. Partial dependence works by marginalizing the machine learning model output over the distribution of the features in set C, so that the function shows the relationship between the features in set S we are interested in and the predicted outcome. By marginalizing over the other features, we get a function that depends only on features in S, interactions with other features included. The partial function ^ f S is estimated by calculating averages in the training data, also known as Monte Carlo method: "),t("vue-mathjax",{attrs:{formula:"$$ f_s(x_s) = \\frac{1}{n} \\sum_{n = 1}^{n} f(x_s,x_c)$$"}}),e._v(" The partial function tells us for given value(s) of features S what the average marginal effect on the prediction is. In this formula, x ( i ) C are actual feature values from the dataset for the features in which we are not interested, and n is the number of instances in the dataset. An assumption of the PDP is that the features in C are not correlated with the features in S. If this assumption is violated, the averages calculated for the partial dependence plot will include data points that are very unlikely or even impossible (see disadvantages). For classification where the machine learning model outputs probabilities, the partial dependence plot displays the probability for a certain class given different values for feature(s) in S. An easy way to deal with multiple classes is to draw one line or plot per class. The partial dependence plot is a global method: The method considers all instances and gives a statement about the global relationship of a feature with the predicted outcome. ")],1),t("h4",[e._v("Categorical features")]),t("p",[e._v(" So far, we have only considered numerical features. For categorical features, the partial dependence is very easy to calculate. For each of the categories, we get a PDP estimate by forcing all data instances to have the same category. For example, if we look at the bike rental dataset and are interested in the partial dependence plot for the season, we get four numbers, one for each season. To compute the value for summer, we replace the season of all data instances with summer and average the predictions. ")]),t("h4",[e._v("Permutation Feature Importance")]),t("p",[e._v(" Permutation feature importance is a powerful and intuitive method used to evaluate the impact of each feature on a machine learning models performance. After a model has been trained, this technique works by randomly shuffling the values of one feature at a time in the validation or test dataset. By doing so, the relationship between that feature and the target variable is disrupted, while all other features remain unchanged. The model is then used to make predictions on this altered dataset, and the drop in performance (measured by accuracy, F1 score, RMSE, or any other metric) is recorded. A large drop indicates that the feature was important to the models predictions, while a small or no change suggests that the feature had little influence. This method is model-agnostic, meaning it can be used with any type of machine learning algorithm, from decision trees to neural networks. However, one limitation is that it can be misleading when features are highly correlated, as the importance may be shared among multiple features, making individual effects harder to isolate. ")])],1)},bt=[function(){var e=this,t=e._self._c;return t("ul",[t("li",[e._v(" Confusion matrix: The confusion matrix is used to have a more complete picture when assessing the performance of a model. It is defined as follows: ")]),t("li",[e._v(" Main metrics: The following metrics are commonly used to assess the performance of classification models: ")]),t("li",[e._v(" The receiver operating curve, also noted ROC, is the plot of TPR versus FPR by varying the threshold. These metrics are are summed up in the table below: ")]),t("li",[e._v(" The area under the receiving operating curve, also noted AUC or AUROC, is the area below the ROC as shown in the following figure: ")])])},function(){var e=this,t=e._self._c;return t("thead",[t("tr",[t("th",{staticClass:"is-success"},[e._v("Total sum of squares")]),t("th",{staticClass:"is-success"},[e._v("Explained sum of squares ")]),t("th",{staticClass:"is-success"},[e._v("Residual sum of squares ")])])])},function(){var e=this,t=e._self._c;return t("thead",[t("tr",[t("th",{staticClass:"is-success"},[e._v("AIC")]),t("th",{staticClass:"is-success"},[e._v("BIC")]),t("th",{staticClass:"is-success"},[e._v("Adjusted R2 ")])])])},function(){var e=this,t=e._self._c;return t("table",{staticClass:"table is-bordered"},[t("thead",[t("tr",[t("th",{staticClass:"is-success"},[e._v("Training set")]),t("th",{staticClass:"is-success"},[e._v("Validation set ")]),t("th",{staticClass:"is-success"},[e._v("Testing set ")])])]),t("tbody",[t("tr",[t("td",[t("ul",[t("li",[e._v(" Model is trained")]),t("li",[e._v(" Usually 80% of the dataset")])])]),t("td",[t("ul",[t("li",[e._v("Model is assessed")]),t("li",[e._v("Usually 20% of the dataset")]),t("li",[e._v("Also called hold-out or development set")])])]),t("td",[t("ul",[t("li",[e._v(" Model gives predictions")]),t("li",[e._v("Unseen data")])])])])])])},function(){var e=this,t=e._self._c;return t("table",{staticClass:"table is-bordered"},[t("thead",[t("tr",[t("th",{staticClass:"is-success"},[e._v("k-fold")]),t("th",{staticClass:"is-success"},[e._v("Leave-p-out")])])]),t("tbody",[t("tr",[t("td",[t("ul",[t("li",[e._v(" Model is trained")]),t("li",[e._v(" Usually 80% of the dataset")])])]),t("td",[t("ul",[t("li",[e._v("Model is assessed")]),t("li",[e._v("Usually 20% of the dataset")]),t("li",[e._v("Also called hold-out or development set")])])])])])])},function(){var e=this,t=e._self._c;return t("p",[e._v(" The most commonly used method is called k-fold cross-validation and splits the training data into k folds to validate the model on one fold while training the model on the k1 other folds, all of this k times. The error is then averaged over the k folds and is named cross-validation error. "),t("img",{staticClass:"image",attrs:{src:"/cross-validation-en.png",alt:""}})])},function(){var e=this,t=e._self._c;return t("ul",[t("li",[e._v("Type of prediction: The different types of predictive models are summed up in the table below: "),t("table",{staticClass:"table is-bordered"},[t("thead",[t("tr",[t("th",{staticClass:"is-success"}),t("th",{staticClass:"is-success"},[e._v("Regression")]),t("th",{staticClass:"is-success"},[e._v("Classification")])])]),t("tbody",[t("tr",[t("td",[e._v("Outcome")]),t("td",[e._v("Continuous")]),t("td",[e._v("Class")])]),t("tr",[t("td",[e._v("Examples")]),t("td",[e._v("Linear regression ")]),t("td",[e._v("Logistic regression, SVM, Naive Bayes ")])])])])])])},function(){var e=this,t=e._self._c;return t("ul",[t("li",[e._v(" Classification and Regression Trees (CART), commonly known as decision trees, can be represented as binary trees. They have the advantage to be very interpretable. ")]),t("li",[e._v(" Random forestIt is a tree-based technique that uses a high number of decision trees built out of randomly selected sets of features. Contrary to the simple decision tree, it is highly uninterpretable but its generally good performance makes it a popular algorithm. ")]),t("li",[e._v(" BoostingThe idea of boosting methods is to combine several weak learners to form a stronger one. The main ones are summed up in the table below: ")]),t("li",[e._v(" Adaptive boosting Gradient boosting  High weights are put on errors to improve at the next boosting step  Known as Adaboost  Weak learners are trained on residuals  Examples include XGBoost ")])])}],yt={name:"MethodsTabComponent",data(){return{formula:"$$x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}.$$",sserror:"$$ SS_{tot}= \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2$$"}}},vt=yt,xt=(0,C.A)(vt,gt,bt,!1,null,null,null),wt=xt.exports,Ct=s(42004);const kt=new Worker(new URL(s.p+s.u(167),s.b)),St={};kt.onmessage=e=>{const{id:t,...s}=e.data,a=St[t];delete St[t],a(s)};const zt=(()=>{let e=0;return(t,s)=>(e=(e+1)%Number.MAX_SAFE_INTEGER,new Promise((a=>{St[e]=a,kt.postMessage({...s,python:t,id:e})})))})();class At{constructor(){this.model=null}async train(e,t,s,a){this.context={X_train:e,columns:t,metric:s,method:a};const i='\n        import matplotlib\n        matplotlib.use("AGG")\n        import matplotlib.pyplot as plt\n        from js import X_train,columns,method,metric\n        import seaborn as sns\n        import pandas as pd\n\n        sns.set(font_scale=1.5)\n        df = pd.DataFrame(X_train,columns = columns)\n        plt.figure(figsize=(12, 8))\n        plot = sns.clustermap(df.corr(),cmap="YlGnBu_r",annot = True, fmt=".2f",method=method,metric=metric)\n        reordered_index = plot.dendrogram_row.reordered_ind\n        reordered_columns = plot.dendrogram_col.reordered_ind\n        clustered_corr = df.corr().iloc[reordered_index, :].iloc[:, reordered_columns]\n\n        Z = plot.dendrogram_col.linkage  \n        Z,clustered_corr.values,clustered_corr.columns.tolist()\n        ';try{const{results:e,error:t}=await zt(i,this.context);if(e)return e;t&&console.log("pyodideWorker error: ",t)}catch(n){throw Error(`Error in pyodideWorker at ${n.filename}, Line: ${n.lineno}, ${n.message}`)}}}let Pt=new se(null,null),Et=new te(null,null);var Ft={name:"MainComponent",components:{"dmensionality-reduction-component":Me,"results-component":st,"scatterplot-matrix-component":ft,"methods-tab-component":wt},setup(){const e=y();return{settings:e}},props:{msg:String,selectedFeatures:[]},errorCaptured(e,t,s){console.log(`cat EC: ${e.toString()}\ninfo: ${s}`);let a={message:"Encountered unexpected error",type:"warning"};return this.$buefy.toast.open({message:"Encountered unexpected error",type:"is-warning"}),this.settings.addMessage(a),!1},data(){return{featureTypeOptions:z,checkedRows:[],metric:"euclidean",method:"ward",img:null,continuousFeaturesStats:[],continuousFeaturesColumns:[],categoricalFeaturesStats:[],categoricalFeaturesColumns:[],sampleData:[],datasetColumns:[],isActive:!0,hasCorrelationMatrix:!1,loading:!1}},methods:{resize(){window.dispatchEvent(new Event("resize"))},async correlationMatrix(){this.loading=!0;try{let e=this.settings.items.filter((e=>e.selected&&e.type===z.Numerical.id)).map((e=>e.name)),t=this.settings.df.loc({columns:e});t=t.dropNa({axis:1}).values;let s=new Ct.uq(t),a=(0,Ct.BR)(s);this.hasCorrelationMatrix=!0,await Et.correlationHeatmap("correlation_matrix",a.data,e);let i=new At,[n,r,o]=await i.train(t,e,this.metric,this.method);await Et.dendogramPlot("correlation_matrix_ordered",r,n,o,e),this.loading=!1,setTimeout((()=>{window.dispatchEvent(new Event("resize"))}),500)}catch(e){throw this.loading=!1,e}},applyChanges(){this.renderStats(!0)},renderStats(e=!1){if(this.settings.df?.columns?.length>0){let t,s;if(e){console.log(this.continuousFeaturesStats);let e=this.continuousFeaturesStats.concat(this.categoricalFeaturesStats);t=e.filter((e=>e?.type===z.Numerical.id)).map((function(e){return{name:e.name,selected:e.selected,scaler:e.sclaer??0}})),s=e.filter((e=>e?.type===z.Nominal.id||e?.type===z.Ordinal.id)).map((function(e){return{name:e.name,selected:e.selected}}));let a=e;for(let t=0;t<a.length;t++)this.settings.addFeature(a[t]);this.$emit("check-target")}else t=this.settings.items.filter((e=>e?.type===z.Numerical.id)).map((function(e){return{name:e.name,selected:!0}})),s=this.settings.items.filter((e=>e?.type!==z.Numerical.id)).map((function(e){return{name:e.name,selected:!0}}));let a=new g.DataFrame(this.settings.rawData),i=Pt.renderDatasetStats(a,t,s);this.continuousFeaturesColumns=i[0],this.continuousFeaturesStats=i[1],this.categoricalFeaturesColumns=i[2],this.categoricalFeaturesStats=i[3],this.datasetColumns=this.settings.df.columns.map((e=>({field:e,label:e}))),this.sampleData=(0,xe.toJSON)(this.settings.df.head(5)),this.$refs.splom?.initSPLOM(),setTimeout((()=>{this.correlationMatrix()}),500)}}}},Tt=Ft,$t=(0,C.A)(Tt,Ae,Pe,!1,null,null,null),Nt=$t.exports,Dt={name:"App",components:{SidebarComponent:ze,MainComponent:Nt},setup(){const e=y();return{settings:e}},errorCaptured(e,t,s){return console.log(`cat EC: ${e.toString()}\ninfo: ${s} + ${e.stack}`),this.$buefy.toast.open({duration:3e3,message:"Something went wrong",type:"is-danger"}),this.settings.addMessage({message:e.toString(),type:"danger"}),!1},data(){return{dataframe:null,selectedFeatures:[]}},methods:{checkTarget(){this.$refs.sidebar.checkmodelTask()},reset(){this.settings.resetDF()},updateFeatureStats(){this.$refs.main.renderStats()},setSelectedFeatures(e){this.selectedFeatures=e}}},qt=Dt,Mt=(0,C.A)(qt,i,n,!1,null,null,null),It=Mt.exports,Rt=s(60523),Ot=(s(41203),s(2232)),Lt=s.n(Ot);M().setPlotConfig({autosize:!0,displaylogo:!1,modeBarButtonsToRemove:["resetScale2d","zoom2d","pan","select2d","resetViews","sendDataToCloud","hoverCompareCartesian","lasso2d","drawopenpath "]}),a.Ay.config.productionTip=!1,a.Ay.prototype.window=window,a.Ay.use(Lt()),a.Ay.use(Rt.Ay),a.Ay.use(b.R2);const Xt=(0,b.Ey)();new a.Ay({render:e=>e(It),pinia:Xt}).$mount("#app")},85817:function(){},18590:function(){},70324:function(){},9807:function(){},5863:function(){},86997:function(){},50716:function(){},41234:function(){},16251:function(){},67233:function(){},29800:function(){}},t={};function s(a){var i=t[a];if(void 0!==i)return i.exports;var n=t[a]={id:a,loaded:!1,exports:{}};return e[a].call(n.exports,n,n.exports,s),n.loaded=!0,n.exports}s.m=e,function(){s.amdD=function(){throw new Error("define cannot be used indirect")}}(),function(){s.amdO={}}(),function(){var e=[];s.O=function(t,a,i,n){if(!a){var r=1/0;for(d=0;d<e.length;d++){a=e[d][0],i=e[d][1],n=e[d][2];for(var o=!0,l=0;l<a.length;l++)(!1&n||r>=n)&&Object.keys(s.O).every((function(e){return s.O[e](a[l])}))?a.splice(l--,1):(o=!1,n<r&&(r=n));if(o){e.splice(d--,1);var c=i();void 0!==c&&(t=c)}}return t}n=n||0;for(var d=e.length;d>0&&e[d-1][2]>n;d--)e[d]=e[d-1];e[d]=[a,i,n]}}(),function(){s.n=function(e){var t=e&&e.__esModule?function(){return e["default"]}:function(){return e};return s.d(t,{a:t}),t}}(),function(){s.d=function(e,t){for(var a in t)s.o(t,a)&&!s.o(e,a)&&Object.defineProperty(e,a,{enumerable:!0,get:t[a]})}}(),function(){s.u=function(e){return"js/"+e+"."+{167:"c5d69706",221:"4a6f9d73"}[e]+".js"}}(),function(){s.g=function(){if("object"===typeof globalThis)return globalThis;try{return this||new Function("return this")()}catch(e){if("object"===typeof window)return window}}()}(),function(){s.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)}}(),function(){s.r=function(e){"undefined"!==typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})}}(),function(){s.nmd=function(e){return e.paths=[],e.children||(e.children=[]),e}}(),function(){s.p="/"}(),function(){s.b=document.baseURI||self.location.href;var e={524:0};s.O.j=function(t){return 0===e[t]};var t=function(t,a){var i,n,r=a[0],o=a[1],l=a[2],c=0;if(r.some((function(t){return 0!==e[t]}))){for(i in o)s.o(o,i)&&(s.m[i]=o[i]);if(l)var d=l(s)}for(t&&t(a);c<r.length;c++)n=r[c],s.o(e,n)&&e[n]&&e[n][0](),e[n]=0;return s.O(d)},a=self["webpackChunkmlfit"]=self["webpackChunkmlfit"]||[];a.forEach(t.bind(null,0)),a.push=t.bind(null,a.push.bind(a))}();var a=s.O(void 0,[504],(function(){return s(4631)}));a=s.O(a)})();
//# sourceMappingURL=app.4ef56171.js.map